<!doctype html>
<html lang="zh-CN">
 <head> 
  <meta charset="utf-8"> 
  <link rel="canonical" href="https://blog.csdn.net/weixin_43334693/article/details/129854764"> 
  <meta http-equiv="content-type" content="text/html; charset=utf-8"> 
  <meta name="renderer" content="webkit"> 
  <meta name="force-rendering" content="webkit"> 
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no"> 
  <meta name="report" content="{&quot;pid&quot;: &quot;blog&quot;, &quot;spm&quot;:&quot;1001.2101&quot;}"> 
  <meta name="referrer" content="always"> 
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <link rel="alternate" media="handheld" href="#"> 
  <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848"> 
  <meta name="applicable-device" content="pc"> 
  <link href="https://g.csdnimg.cn/static/logo/favicon32.ico" rel="shortcut icon" type="image/x-icon"> 
  <title>YOLOv5源码逐行超详细注释与解读（7）——网络结构（2）common.py_yolov7缺少common.py-CSDN博客</title>  
  <meta name="keywords" content="yolov7缺少common.py"> 
  <meta name="csdn-baidu-search" content="{&quot;autorun&quot;:true,&quot;install&quot;:true,&quot;keyword&quot;:&quot;yolov7缺少common.py&quot;}"> 
  <meta name="description" content="文章浏览阅读9.8k次，点赞39次，收藏72次。本文详细解读YOLOv5网络结构中的common.py文件，涵盖了基础组件、注意力模块、幻象模块和模型扩展模块。介绍了 autopad、Conv、DWConv、Bottleneck、BottleneckCSP、C3、SPP等关键组件的功能和实现，以及它们在目标检测网络中的作用。此外，还讨论了TransformerLayer和GhostConv等创新模块。
"> 
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/css/detail_enter-af0ead44cd.min.css"> 
  <style>
        #content_views{
            -webkit-touch-callout: none;
            -webkit-user-select: none;
            -khtml-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none; 
            user-select: none; 
        }
    </style>  
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/themesSkin/skin-finalboss/skin-finalboss-b2ba816980.min.css">    
  <meta name="toolbar" content="{&quot;type&quot;:&quot;0&quot;,&quot;fixModel&quot;:&quot;1&quot;}">    
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/public/sandalstrap/1.4/css/sandalstrap.min.css"> 
  <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>    
 	<style>
	main div.blog-content-box pre {
		max-height: 100%;
		overflow-y: hidden;
	}
	</style>
 </head>  
 <body class="nodata  " style=""> 
  <div id="toolbarBox" style="min-height: 48px;"></div>    
  <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/pc/css/blog_code-01256533b5.min.css"> 
  <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/chart-3456820cac.css"> 
  <link rel="stylesheet" href="https://g.csdnimg.cn/lib/swiper/6.0.4/css/swiper.css">   
  <div class="main_father clearfix d-flex justify-content-center mainfather-concision" style="height:100%;"> 
   <div class="container clearfix container-concision" id="mainBox">  
    <main>  
     <div class="blog-content-box"> 
      <div class="article-header-box"> 
       <div class="article-header"> 
        <div class="article-title-box"> 
         <h1 class="title-article" id="articleContentId">YOLOv5源码逐行超详细注释与解读（7）——网络结构（2）common.py</h1> 
        </div> 
        <div class="article-info-box"> 
         <div class="article-bar-top"> 
          <img class="article-type-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png" alt=""> 
          <div class="bar-content"> 
           <a class="follow-nickName vip-name" href="https://jrs0511.blog.csdn.net" target="_blank" rel="noopener" title="路人贾'ω'">路人贾'ω'</a> 
           <img class="article-time-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUpTime2.png" alt=""> 
           <span class="time">已于&nbsp;2023-05-28 10:00:58&nbsp;修改</span> 
           <div class="read-count-box"> 
            <img class="article-read-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/articleReadEyes2.png" alt=""> 
            <span class="read-count">阅读量9.8k</span> 
            <a id="blog_detail_zk_collection" class="un-collection" data-report-click="{&quot;mod&quot;:&quot;popu_823&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4232&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img class="article-collect-img article-heard-img un-collect-status isdefault" style="display:inline-block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollect2.png" alt=""> <img class="article-collect-img article-heard-img collect-status isactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive2.png" alt=""> <span class="name">收藏</span> <span class="get-collection"> 72 </span> </a> 
            <div class="read-count-box is-like"> 
             <img class="article-read-img article-heard-img" style="display:none" id="is-like-imgactive-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Active.png" alt=""> 
             <img class="article-read-img article-heard-img" style="display:block" id="is-like-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Black.png" alt=""> 
             <span class="read-count" id="blog-digg-num">点赞数 39 </span> 
            </div> 
           </div> 
          </div> 
         </div> 
         <div class="blog-tags-box"> 
          <div class="tags-box artic-tag-box"> 
           <span class="label">分类专栏：</span> 
           <a class="tag-link" href="https://blog.csdn.net/weixin_43334693/category_12233704.html" target="_blank" rel="noopener">YOLOv5入门＋实践＋改进</a> 
           <span class="label">文章标签：</span> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;python&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;python\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;python&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;python\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=python&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">python</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;YOLO&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;YOLO\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;YOLO&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;YOLO\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=YOLO&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">YOLO</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;目标检测&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;目标检测\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;目标检测&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;目标检测\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">目标检测</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;计算机视觉&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;计算机视觉\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;计算机视觉&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;计算机视觉\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">计算机视觉</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;人工智能&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;人工智能\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;人工智能&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;人工智能\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">人工智能</a> 
          </div> 
         </div> 
         <div class="up-time">
          <span>于&nbsp;2023-03-30 19:32:22&nbsp;首次发布</span>
         </div> 
         <div class="slide-content-box"> 
          <div class="article-copyright"> 
           <div class="creativecommons">
             版权声明：本文为博主原创文章，遵循
            <a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。 
           </div> 
           <div class="article-source-link">
             本文链接：
            <a href="https://blog.csdn.net/weixin_43334693/article/details/129854764" target="_blank">https://blog.csdn.net/weixin_43334693/article/details/129854764</a> 
           </div> 
          </div> 
         </div> 
         <div class="operating"> 
          <a class="href-article-edit slide-toggle">版权</a> 
         </div> 
        </div> 
       </div> 
      </div> 
      <div id="blogHuaweiyunAdvert"></div> 
      <div id="blogColumnPayAdvert"> 
       <div class="column-group"> 
        <div class="column-group-item column-group0 column-group-item-one"> 
         <div class="item-l"> 
          <a class="item-target" href="https://blog.csdn.net/weixin_43334693/category_12233704.html" target="_blank" title="YOLOv5入门＋实践＋改进" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.6332&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.6332&quot;}"> <img class="item-target" src="https://i-blog.csdnimg.cn/blog_column_migrate/2d39764ecc8e8d41d72673a523e05b4b.png?x-oss-process=image/resize,m_fixed,h_224,w_224" alt=""> <span class="title item-target"> <span> <span class="tit">YOLOv5入门＋实践＋改进</span> <span class="dec">专栏收录该内容</span> </span> <span class="rank"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/columnHotIcon2.png" alt="">该专栏为热销专栏榜&nbsp;第76名</span> </span> </a> 
         </div> 
         <div class="item-m"> 
          <span>47 篇文章</span> 
          <span class="old-add-new-box"> <span class="price">¥99.90</span> <span class="oldprice">¥299.90</span> </span> 
         </div> 
         <div class="item-r"> 
          <a class="item-target article-column-subscribe">已订阅 </a> 
          <a class="item-target column-studyvip-discount column-studyvip-pass" data-report-view="{&quot;spm&quot;:&quot;1001.2015.3001.8590&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2015.3001.8590&quot;}">8折续费 </a> 
         </div> 
        </div> 
       </div> 
      </div> 
      <div class="learning_the_member_box"> 
       <a href="https://www.csdn.net/vip?utm_source=bkzl_cjhy_ckqy" target="_blank"> 
        <div class="left">
         <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/iconVIpCrown.png" alt="">
         <span>您已是超级会员，正在免费阅读会员专享内容</span>
        </div> 
        <div class="right">
         <span>查看更多超级会员权益</span>
         <img src="https://csdnimg.cn/release/blogv2/dist/components/img/vipIconArrowLeftWhite.png" alt="">
        </div> </a> 
      </div> 
      <div class="ai-abstract-box"> 
       <div class="ai-abstract"> 
        <div class="abstract-content"> 
         <img class="lock-img" src="https://img-home.csdnimg.cn/images/20240711042549.png" alt=""> 本文详细解读YOLOv5网络结构中的common.py文件，涵盖了基础组件、注意力模块、幻象模块和模型扩展模块。介绍了 autopad、Conv、DWConv、Bottleneck、BottleneckCSP、C3、SPP等关键组件的功能和实现，以及它们在目标检测网络中的作用。此外，还讨论了TransformerLayer和GhostConv等创新模块。 
        </div> 
        <p> 摘要生成于 <a href="https://ai.csdn.net?utm_source=cknow_pc_ai_abstract" data-report-query="spm=3001.10128" data-report-view="{&quot;spm&quot;:&quot;3001.10128&quot;,&quot;extra&quot;:{&quot;location&quot;:&quot;ai_abstract&quot;}}" data-report-click="{&quot;spm&quot;:&quot;3001.10128&quot;,&quot;extra&quot;:{&quot;location&quot;:&quot;ai_abstract&quot;,&quot;text&quot;:&quot;C知道&quot;}}" target="_blank"> C知道</a> ，由 DeepSeek-R1 满血版支持， <a href="https://ai.csdn.net?utm_source=cknow_pc_ai_abstract" data-report-query="spm=3001.10128" data-report-click="{&quot;spm&quot;:&quot;3001.10128&quot;,&quot;extra&quot;:{&quot;location&quot;:&quot;ai_abstract&quot;,&quot;text&quot;:&quot;前往体验&quot;}}" target="_blank"> 前往体验 &gt;</a></p> 
       </div> 
      </div> 
      <article class="baidu_pl"> 
       <div id="article_content" class="article_content clearfix"> 
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css"> 
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-704d5b9767.css"> 
        <div id="content_views" class="htmledit_views"> 
         <h4 id="%F0%9F%8C%9F%E6%9C%AC%E4%BA%BAYOLOv5%E7%B3%BB%E5%88%97%E5%AF%BC%E8%88%AA"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/9641664c516c3d9de3a26ade4d4ceae0.gif"></h4> 
         <p><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/f0c3a8db06862e212db222bde7a6ed54.jpeg"></p> 
         <h2 id="%C2%A0%E5%89%8D%E8%A8%80%C2%A0">前言&nbsp;</h2> 
         <p>上一篇我们一起学习了YOLOv5的网络模型之一<span style="color:#4da8ee;"><strong>yolo.py</strong></span>，它这是YOLO的特定模块，而今天要学习另一个和网络搭建有关的文件——<span style="color:#fe2c24;"><strong>common.py</strong></span>，这个文件存放着YOLOv5网络搭建常见的通用模块。如果我们需要修改某一模块，那么就需要修改这个文件中对应模块的定义。</p> 
         <p>学这篇的同时，搭配<a href="https://blog.csdn.net/weixin_43334693/article/details/129312409?spm=1001.2014.3001.5502" title="【YOLO系列】YOLOv5超详细解读（网络详解）">【YOLO系列】YOLOv5超详细解读（网络详解）</a>这篇算法详解效果更好噢~</p> 
         <p><strong>common.py文件位置在./models/common.py</strong></p> 
         <p><img alt="" height="331" src="https://i-blog.csdnimg.cn/blog_migrate/35f034771047fad9cc13f708216fed30.png" width="310">​</p> 
         <p>文章代码逐行手打注释，每个模块都有对应讲解，一文帮你梳理整个代码逻辑！&nbsp;</p> 
         <p><strong>友情提示：</strong>全文<span style="color:#fe2c24;">5万</span>多字，可以先点<img alt="" height="66" src="https://i-blog.csdnimg.cn/blog_migrate/ea5f7225888a49f6a6827b9ae71e856f.gif" width="66">​再慢慢看哦~</p> 
         <p><strong>源码下载地址：</strong><a href="https://gitcode.net/mirrors/ultralytics/yolov5?utm_source=csdn_github_accelerator" rel="nofollow" title="mirrors / ultralytics / yolov5 · GitCode">mirrors / ultralytics / yolov5 · GitCode</a></p> 
         <p>&nbsp;<img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/4cb78898ea57a142a8ca74a0be342898.gif">​</p> 
         <p><img alt="" height="87" src="https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif" width="87">​&nbsp; &nbsp;🍀本人<a href="https://so.csdn.net/so/search?q=YOLOv5%E6%BA%90%E7%A0%81&amp;spm=1001.2101.3001.7020" title="YOLOv5源码">YOLOv5源码</a>详解系列：&nbsp;&nbsp;</p> 
         <p><a href="https://blog.csdn.net/weixin_43334693/article/details/129356033?spm=1001.2014.3001.5501" title="YOLOv5源码逐行超详细注释与解读（1）——项目目录结构解析">YOLOv5源码逐行超详细注释与解读（1）——项目目录结构解析</a></p> 
         <p><a href="https://blog.csdn.net/weixin_43334693/article/details/129349094?spm=1001.2014.3001.5501" title="​​​​​​YOLOv5源码逐行超详细注释与解读（2）——推理部分detect.py">​​​​​​YOLOv5源码逐行超详细注释与解读（2）——推理部分detect.py</a></p> 
         <p><a href="https://blog.csdn.net/weixin_43334693/article/details/129460666?spm=1001.2014.3001.5501" title="YOLOv5源码逐行超详细注释与解读（3）——训练部分train.py">YOLOv5源码逐行超详细注释与解读（3）——训练部分train.py</a></p> 
         <p><a href="https://blog.csdn.net/weixin_43334693/article/details/129649553?spm=1001.2014.3001.5501" title="YOLOv5源码逐行超详细注释与解读（4）——验证部分val（test）.py">YOLOv5源码逐行超详细注释与解读（4）——验证部分val（test）.py</a></p> 
         <p><a href="https://blog.csdn.net/weixin_43334693/article/details/129697521?spm=1001.2014.3001.5501" title="YOLOv5源码逐行超详细注释与解读（5）——配置文件yolov5s.yaml">YOLOv5源码逐行超详细注释与解读（5）——配置文件yolov5s.yaml</a></p> 
         <p><a href="https://blog.csdn.net/weixin_43334693/article/details/129803802?spm=1001.2014.3001.5501" title="YOLOv5源码逐行超详细注释与解读（6）——网络结构（1）yolo.py">YOLOv5源码逐行超详细注释与解读（6）——网络结构（1）yolo.py</a></p> 
         <hr> 
         <h2 id="%E7%9B%AE%E5%BD%95">目录</h2> 
         <p id="%C2%A0%E5%89%8D%E8%A8%80%C2%A0-toc" style="margin-left:0px;"><a href="#%C2%A0%E5%89%8D%E8%A8%80%C2%A0" rel="nofollow">前言&nbsp;</a></p> 
         <p id="%E7%9B%AE%E5%BD%95-toc" style="margin-left:0px;"><a href="#%E7%9B%AE%E5%BD%95" rel="nofollow">目录</a></p> 
         <p id="%F0%9F%9A%80%E4%B8%80%E3%80%81%20%E5%AF%BC%E5%8C%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%C2%A0-toc" style="margin-left:0px;"><a href="#%F0%9F%9A%80%E4%B8%80%E3%80%81%20%E5%AF%BC%E5%8C%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%C2%A0" rel="nofollow">🚀一、 导包和基本配置&nbsp;</a></p> 
         <p id="1.1%20%E5%AF%BC%E5%85%A5%E5%AE%89%E8%A3%85%E5%A5%BD%E7%9A%84python%E5%BA%93%C2%A0-toc" style="margin-left:40px;"><a href="#1.1%20%E5%AF%BC%E5%85%A5%E5%AE%89%E8%A3%85%E5%A5%BD%E7%9A%84python%E5%BA%93%C2%A0" rel="nofollow">1.1 导入安装好的python库</a></p> 
         <p id="1.2%20%E5%8A%A0%E8%BD%BD%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9D%97-toc" style="margin-left:40px;"><a href="#1.2%20%E5%8A%A0%E8%BD%BD%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9D%97" rel="nofollow">1.2 加载自定义模块</a></p> 
         <p id="%F0%9F%9A%80%E4%BA%8C%E3%80%81%20%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6-toc" style="margin-left:0px;"><a href="#%F0%9F%9A%80%E4%BA%8C%E3%80%81%20%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6" rel="nofollow">🚀二、 基础组件</a></p> 
         <p id="2.1%C2%A0autopad-toc" style="margin-left:40px;"><a href="#2.1%C2%A0autopad" rel="nofollow">2.1&nbsp;autopad</a></p> 
         <p id="2.2%C2%A0Conv-toc" style="margin-left:40px;"><a href="#2.2%C2%A0Conv" rel="nofollow">2.2&nbsp;Conv</a></p> 
         <p id="2.3%C2%A0DWConv-toc" style="margin-left:40px;"><a href="#2.3%C2%A0DWConv" rel="nofollow">2.3&nbsp;DWConv</a></p> 
         <p id="2.4%C2%A0Bottleneck-toc" style="margin-left:40px;"><a href="#2.4%C2%A0Bottleneck" rel="nofollow">2.4&nbsp;Bottleneck</a></p> 
         <p id="2.5%C2%A0BottleneckCSP-toc" style="margin-left:40px;"><a href="#2.5%C2%A0BottleneckCSP" rel="nofollow">2.5&nbsp;BottleneckCSP</a></p> 
         <p id="2.6%C2%A0C3-toc" style="margin-left:40px;"><a href="#2.6%C2%A0C3" rel="nofollow">2.6&nbsp;C3</a></p> 
         <p id="2.6.1%20C3-toc" style="margin-left:80px;"><a href="#2.6.1%20C3" rel="nofollow">2.6.1 C3</a></p> 
         <p id="2.6.2%20C3SPP(C3)-toc" style="margin-left:80px;"><a href="#2.6.2%20C3SPP%28C3%29" rel="nofollow">2.6.2 C3SPP(C3)</a></p> 
         <p id="2.6.3%20C3Ghost(C3)-toc" style="margin-left:80px;"><a href="#2.6.3%20C3Ghost%28C3%29" rel="nofollow">2.6.3 C3Ghost(C3)</a></p> 
         <p id="2.7%C2%A0SPP-toc" style="margin-left:40px;"><a href="#2.7%C2%A0SPP" rel="nofollow">2.7&nbsp;SPP</a></p> 
         <p id="2.7.1%20SPP-toc" style="margin-left:80px;"><a href="#2.7.1%20SPP" rel="nofollow">2.7.1 SPP</a></p> 
         <p id="%C2%A02.7.2%20SPPF-toc" style="margin-left:80px;"><a href="#%C2%A02.7.2%20SPPF" rel="nofollow">2.7.2 SPPF</a></p> 
         <p id="2.8%C2%A0Focus-toc" style="margin-left:40px;"><a href="#2.8%C2%A0Focus" rel="nofollow">2.8&nbsp;Focus</a></p> 
         <p id="2.9%C2%A0Contract-toc" style="margin-left:40px;"><a href="#2.9%C2%A0Contract" rel="nofollow">2.9&nbsp;Contract</a></p> 
         <p id="2.10%20Expand-toc" style="margin-left:40px;"><a href="#2.10%20Expand" rel="nofollow">2.10 Expand</a></p> 
         <p id="2.11%20Concat-toc" style="margin-left:40px;"><a href="#2.11%20Concat" rel="nofollow">2.11 Concat</a></p> 
         <p id="%F0%9F%9A%80%E4%B8%89%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9D%97%C2%A0-toc" style="margin-left:0px;"><a href="#%F0%9F%9A%80%E4%B8%89%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9D%97%C2%A0" rel="nofollow">🚀三、注意力模块&nbsp;</a></p> 
         <p id="3.1%20TransformerLayer-toc" style="margin-left:40px;"><a href="#3.1%20TransformerLayer" rel="nofollow">3.1 TransformerLayer</a></p> 
         <p id="3.2%20TransformerBlock-toc" style="margin-left:40px;"><a href="#3.2%20TransformerBlock" rel="nofollow">3.2 TransformerBlock</a></p> 
         <p id="%F0%9F%9A%80%E5%9B%9B%E3%80%81%E5%B9%BB%E8%B1%A1%E6%A8%A1%E5%9D%97-toc" style="margin-left:0px;"><a href="#%F0%9F%9A%80%E5%9B%9B%E3%80%81%E5%B9%BB%E8%B1%A1%E6%A8%A1%E5%9D%97" rel="nofollow">🚀四、幻象模块</a></p> 
         <p id="4.1%C2%A0GhostConv-toc" style="margin-left:40px;"><a href="#4.1%C2%A0GhostConv" rel="nofollow">4.1&nbsp;GhostConv</a></p> 
         <p id="%C2%A04.2%C2%A0GhostBottleneck-toc" style="margin-left:40px;"><a href="#%C2%A04.2%C2%A0GhostBottleneck" rel="nofollow">4.2&nbsp;GhostBottleneck</a></p> 
         <p id="%F0%9F%9A%80%E4%BA%94%E3%80%81%E6%A8%A1%E5%9E%8B%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97-toc" style="margin-left:0px;"><a href="#%F0%9F%9A%80%E4%BA%94%E3%80%81%E6%A8%A1%E5%9E%8B%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97" rel="nofollow">🚀五、模型扩展模块</a></p> 
         <p id="5.1%20C3TR(C3)-toc" style="margin-left:40px;"><a href="#5.1%20C3TR%28C3%29" rel="nofollow">5.1 C3TR(C3)</a></p> 
         <p id="5.2%20AutoShape-toc" style="margin-left:40px;"><a href="#5.2%20AutoShape" rel="nofollow">5.2 AutoShape</a></p> 
         <p id="5.3%20Detections-toc" style="margin-left:40px;"><a href="#5.3%20Detections" rel="nofollow">5.3 Detections</a></p> 
         <p id="5.4%C2%A0Classify-toc" style="margin-left:40px;"><a href="#5.4%C2%A0Classify" rel="nofollow">5.4&nbsp;Classify</a></p> 
         <p id="%C2%A0%F0%9F%9A%80%E5%85%AD%E3%80%81common.py%E5%85%A8%E9%83%A8%E6%B3%A8%E9%87%8A-toc" style="margin-left:0px;"><a href="#%C2%A0%F0%9F%9A%80%E5%85%AD%E3%80%81common.py%E5%85%A8%E9%83%A8%E6%B3%A8%E9%87%8A" rel="nofollow">&nbsp;🚀六、common.py全部注释</a></p> 
         <p><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/d35d9edbb9675b824e2c1dabd7a35e91.gif"></p> 
         <h2 id="%F0%9F%9A%80%E4%B8%80%E3%80%81%20%E5%AF%BC%E5%8C%85%E5%92%8C%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%C2%A0">🚀一、 导包和基本配置&nbsp;</h2> 
         <h3 id="1.1%20%E5%AF%BC%E5%85%A5%E5%AE%89%E8%A3%85%E5%A5%BD%E7%9A%84python%E5%BA%93%C2%A0">1.1 导入安装好的python库</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''======================1.导入安装好的python库====================='''
import json  # 用于json和Python数据之间的相互转换
import math  # 数学函数模块
import platform  # 获取操作系统的信息
import warnings  # 警告程序员关于语言或库功能的变化的方法
from copy import copy  # 数据拷贝模块 分浅拷贝和深拷贝
from pathlib import Path  # Path将str转换为Path对象 使字符串路径易于操作的模块

import cv2  # 调用OpenCV的cv库
import numpy as np  # numpy数组操作模块
import pandas as pd  # panda数组操作模块
import requests  # Python的HTTP客户端库
import torch  # pytorch深度学习框架
import torch.nn as nn  # 专门为神经网络设计的模块化接口
from PIL import Image  # 图像基础操作模块
from torch.cuda import amp  # 混合精度训练模块</code ></pre> 
         <p>首先，导入一下常用的<strong>python库</strong>：&nbsp;</p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">json：</span></strong> &nbsp;<span style="color:#1a439c;">实现字典列表和JSON字符串之间的相互解析</span></li>
          <li><strong><span style="background-color:#fef2f0;">math:&nbsp;</span></strong><span style="background-color:#fef2f0;"> </span><span style="color:#1a439c;">&nbsp;数学函数模块</span></li>
          <li><strong><span style="background-color:#fef2f0;">platform:</span>&nbsp; </strong>&nbsp; <span style="color:#1a439c;">获取操作系统的信息</span></li>
          <li><strong><span style="background-color:#fef2f0;">warnings:</span></strong><span style="background-color:#fef2f0;">&nbsp;</span>&nbsp;<span style="color:#1a439c;">警告程序员关于语言或库功能的变化的方法&nbsp;</span></li>
          <li><strong><span style="background-color:#fef2f0;">copy:</span>&nbsp;</strong>&nbsp;<span style="color:#1a439c;">数据拷贝模块 分浅拷贝和深拷贝</span></li>
          <li><strong><span style="background-color:#fef2f0;">pathlib：</span></strong> &nbsp;<span style="color:#1a439c;">这个库提供了一种面向对象的方式来与文件系统交互，可以让代码更简洁、更易读</span></li>
         </ul> 
         <p>&nbsp;然后再导入一些<strong> pytorch库</strong>：</p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">cv2:&nbsp;</span></strong>&nbsp; <span style="color:#1a439c;">调用OpenCV的cv库</span></li>
          <li><strong><span style="background-color:#fef2f0;">numpy：</span></strong> &nbsp;<span style="color:#1a439c;">科学计算库，提供了矩阵，线性代数，傅立叶变换等等的解决方案，最常用的是它的N维数组对象</span></li>
          <li><strong><span style="background-color:#fef2f0;">pandas:</span></strong><span style="background-color:#fef2f0;">&nbsp;</span>&nbsp;<span style="color:#1a439c;">panda数组操作模块</span></li>
          <li><strong><span style="background-color:#fef2f0;">requests:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">Python的HTTP客户端库</span></li>
          <li><strong><span style="background-color:#fef2f0;">torch：</span></strong> &nbsp; <span style="color:#1a439c;">这是主要的Pytorch库。它提供了构建、训练和评估神经网络的工具</span></li>
          <li><strong><span style="background-color:#fef2f0;">torch.nn：</span></strong> &nbsp;<span style="color:#1a439c;">torch下包含用于搭建神经网络的modules和可用于继承的类的一个子包</span></li>
          <li><strong><span style="background-color:#fef2f0;">PIL:</span>&nbsp;</strong>&nbsp; <span style="color:#1a439c;">图像基础操作模块</span></li>
          <li><span style="color:#0d0016;"><strong><span style="background-color:#fef2f0;">torch.cuda：</span></strong></span> &nbsp;<span style="color:#1a439c;">自动混合精度训练 —— 节省显存并加快推理速度</span></li>
         </ul> 
         <hr> 
         <h3 id="1.2%20%E5%8A%A0%E8%BD%BD%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9D%97">1.2 加载自定义模块</h3> 
         <pre><code class="language-python">'''===================2.加载自定义模块============================'''
from utils.datasets import exif_transpose, letterbox  # 加载数据集的函数
from utils.general import (LOGGER, check_requirements, check_suffix, colorstr, increment_path, make_divisible,
                           non_max_suppression, scale_coords, xywh2xyxy, xyxy2xywh)  # 定义了一些常用的工具函数
from utils.plots import Annotator, colors, plot_one_box  # 定义了Annotator类，可以在图像上绘制矩形框和标注信息
from utils.torch_utils import time_sync  # 定义了一些与PyTorch有关的工具函数</code ></pre> 
         <p>这些都是用户自定义的库，由于上一步已经把路径加载上了，所以现在可以导入，这个顺序不可以调换。具体来说，<strong>代码从如下几个文件中导入了部分函数和类</strong>：&nbsp;</p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">utils.datasets：</span></strong>&nbsp; &nbsp;<span style="color:#1a439c;">加载数据集的函数</span></li>
          <li><strong><span style="background-color:#fef2f0;">utils.general：</span></strong> &nbsp; <span style="color:#1a439c;">定义了一些常用的工具函数，比如检查文件是否存在、检查图像大小是否符合要求、打印命令行参数等等</span></li>
          <li><strong><span style="background-color:#fef2f0;">utils.plots：</span></strong> &nbsp; &nbsp;<span style="color:#1a439c;">定义了Annotator类，可以在图像上绘制矩形框和标注信息</span></li>
          <li><strong><span style="background-color:#fef2f0;">utils.torch_utils：</span></strong> &nbsp; <span style="color:#1a439c;">定义了一些与PyTorch有关的工具函数，比如选择设备、同步时间等通过导入这些模块，可以更方便地进行目标检测的相关任务，并且减少了代码的复杂度和冗余</span></li>
         </ul> 
         <hr> 
         <h2 id="%F0%9F%9A%80%E4%BA%8C%E3%80%81%20%E5%9F%BA%E7%A1%80%E7%BB%84%E4%BB%B6">🚀二、 基础组件</h2> 
         <h3 id="2.1%C2%A0autopad">2.1&nbsp;autopad</h3> 
         <pre><code class="language-python">'''===========1.autopad：根据输入的卷积核计算该卷积模块所需的pad值================'''
# 为same卷积或者same池化自动扩充
# 通过卷积核的大小来计算需要的padding为多少才能把tensor补成原来的形状
def autopad(k, p=None):  # kernel, padding
    # 如果p是none 则进行下一步
    if p is None:
        # 如果k是int 则进行k//2 若不是则进行x//2
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>autopad</strong>主要作用是<strong>根据输入的卷积核计算需要的padding为多少才能把tensor补成原来的形状</strong></span></p> 
         <p><strong><span style="color:#0d0016;">参数：</span></strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">k:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">卷积核的kernel_size</span></li>
          <li><strong><span style="background-color:#fef2f0;">p:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">计算的需要pad值（0填充）</span></li>
         </ul> 
         <p>这里首先是判断是否有<span style="color:#ff9900;">p</span>值：</p> 
         <ul>
          <li><span style="color:#4da8ee;">如果有既定的 p </span>，则直接 return p，自动计算所需要的pad值</li>
          <li><span style="color:#4da8ee;">如果无设定的 p</span>，则 return 使图像在卷积操作后尺寸不变的 p</li>
         </ul> 
         <hr> 
         <h3 id="2.2%C2%A0Conv">2.2&nbsp;Conv</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========2.Conv：标准卷积 由Conv + BN + activate组成================'''
class Conv(nn.Module):
    # Standard convolution
    # init初始化构造函数
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        
        super().__init__()
        # 卷积层
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        # 归一化层
        self.bn = nn.BatchNorm2d(c2)
        # 激活函数
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    # 正向计算，网络执行的顺序是根据forward函数来决定的
    def forward(self, x):
        # conv卷积 -&gt; bn -&gt; act激活
        return self.act(self.bn(self.conv(x)))

    # 正向融合计算
    def forward_fuse(self, x):
        # 这里只有卷积和激活
        return self.act(self.conv(x))
</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>Conv</strong>是<strong>标准卷积层函数，是整个网络中最核心的模块，由卷积层 + BN层 + 激活函数 组成</strong>。</span></p> 
         <p>主要作用是实现了将输入特征经过卷积层，激活函数，归一化层，得到输出层。同时可以指定是否使用归一化层。</p> 
         <p><strong>具体结构如下图：</strong></p> 
         <p style="text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/354621ee91e4a1967e4b3b313feb529f.png"></p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">输入的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:</span>&nbsp;</strong> &nbsp; <span style="color:#1a439c;">输出的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">k:</span>&nbsp;</strong> &nbsp; <span style="color:#1a439c;">卷积的kernel_size，k=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">s:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">卷积的stride，s=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">p:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">卷积的padding ，一般是None ，可以通过autopad自行计算需要pad的padding数</span></li>
          <li><strong><span style="background-color:#fef2f0;">autopad（k,p）：</span></strong>&nbsp; <span style="color:#1a439c;">此处换成自动填充</span></li>
          <li><strong><span style="background-color:#fef2f0;">g：</span>&nbsp;&nbsp;</strong>&nbsp; <span style="color:#1a439c;">g=1表示从输入通道到输出通道的阻塞连接数为1</span></li>
          <li><strong><span style="background-color:#fef2f0;">act：</span></strong>&nbsp; <span style="color:#1a439c;">激活函数类型，True就是SiLU()/Swish，False就是不使用激活函数，类型是nn.Module就使用传进来的激活函数类型</span></li>
         </ul> 
         <p>注意，这个类中还有一个<strong><span style="color:#1c7331;">特殊函数 fuseforward</span></strong> ，这是一个<strong>前向加速推理模块</strong>，在前向传播过程中，通过融合<strong><span style="color:#956fe7;">conv + bn</span></strong>层，达到<strong>加速推理的作用</strong>，一般用于<strong>测试或验证</strong>阶段。&nbsp;</p> 
         <blockquote> 
          <p><strong>nn.Conv2d函数基本参数：</strong></p> 
          <pre><code class="language-python">nn.Conv2d(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')</code ></pre> 
          <ul>
           <li><strong>in_channel:&nbsp;</strong> 输入数据的通道数，例RGB图片通道数为3。</li>
           <li><strong>out_channel:&nbsp;</strong> &nbsp;输出数据的通道数，这个根据模型调整。</li>
           <li><strong>kennel_size:&nbsp;</strong> &nbsp;卷积核大小，可以是int，或tuple；kennel_size=2,意味着卷积大小(2,2)，kennel_size=（2,3），意味着卷积大小（2，3）即非正方形卷积。</li>
           <li><strong>stride：&nbsp;&nbsp;</strong>步长，默认为1，与kennel_size类似，stride=2,意味着步长上下左右扫描皆为2，stride=（2,3），左右扫描步长为2，上下为3。</li>
           <li><strong>padding：&nbsp;&nbsp;</strong>零填充。</li>
           <li><strong>groups：&nbsp;&nbsp;</strong>从输入通道到输出通道的阻塞连接数。</li>
           <li><strong>bias：&nbsp;&nbsp;</strong>如果为“True“，则向输出添加可学习的偏置。</li>
          </ul> 
          <p></p> 
         </blockquote> 
         <hr> 
         <h3 id="2.3%C2%A0DWConv">2.3&nbsp;DWConv</h3> 
         <pre><code class="language-python">'''===========3.DWConv：深度可分离卷积================'''
class DWConv(Conv):
    # Depth-wise convolution class
    def __init__(self, c1, c2, k=1, s=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), act=act)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>DWConv</strong>是<strong>GCONV的极端情况，深度分离(DepthWise)卷积层</strong></span></p> 
         <p>分组数量等于输入通道数量，即每个通道作为一个小组分别进行卷积，结果联结作为输出，<strong><span style="color:#ad720d;">Cin = Cout = g</span></strong>，没有bias项。</p> 
         <p>主要作用是<strong>将通道按输入输出的最大公约数进行切分</strong>，在不同的通道图层上进行特征学习深度分离卷积层，不用深入研究，因为在yolov5中没有真正的使用~</p> 
         <p><strong>具体结构如下图：</strong></p> 
         <p style="text-align:center;"><img alt="" height="254" src="https://i-blog.csdnimg.cn/blog_migrate/8c8cd1026a29031de317605deb7aa830.png" width="416"></p> 
         <p><strong>参数</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:&nbsp;</span></strong>&nbsp; &nbsp;<span style="color:#1a439c;">输入的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:</span>&nbsp;</strong> &nbsp; <span style="color:#1a439c;">输出的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">k:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">卷积的kernel_size，k=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">s:</span>&nbsp;</strong> &nbsp; <span style="color:#1a439c;">卷积的stride，s=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">act:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">激活函数类型，True就是SiLU()/Swish，False就是不使用激活函数，类型是nn.Module就使用传进来的激活函数类型</span></li>
         </ul> 
         <hr> 
         <h3 id="2.4%C2%A0Bottleneck">2.4&nbsp;Bottleneck</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========4.Bottleneck：标准的瓶颈层 由1x1conv+3x3conv+残差块组成================'''
class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
      
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        # 1*1卷积层
        self.cv1 = Conv(c1, c_, 1, 1)
        # 3*3卷积层
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        # 如果shortcut为True就会将输入和输出相加之后再输出
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>Bottleneck</strong>是<strong>一个标准的瓶颈层，由一些 1x1conv、3x3conv、残差块组成</strong>。</span></p> 
         <p><strong>具体结构如下图：</strong>&nbsp;</p> 
         <p style="text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/2020b65aa16ae6e920957252bd8eb297.png"></p> 
         <p>我们可以通过上图看出，网络架构中的<strong><span style="color:#1c7331;">Bottleneck模块</span></strong>分为True和False。主要作用是<strong>可以更加有效的提取特征，既减少了参数量，又优化了计算，保持了原有的精度。</strong></p> 
         <p>首先Bottleneck先进行<span style="background-color:#fefcd8;">1x1</span>卷积降维，再进行常规<span style="background-color:#fff5e6;">3×3</span>卷积核的卷积。最后通过残差结构连接在一起。</p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1：</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">第一个卷积的输入channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2：</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">第二个卷积的输出channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">shortcut：</span>&nbsp;</strong> <span style="color:#1a439c;">&nbsp;bool 是否有shortcut连接 默认是True</span></li>
          <li><strong><span style="background-color:#fef2f0;">g：</span></strong> <span style="color:#1a439c;">表示从输入通道到输出通道的阻塞连接数为1</span></li>
          <li><strong><span style="background-color:#fef2f0;">e：</span></strong>&nbsp; &nbsp;<span style="color:#1a439c;">expansion ratio &nbsp;e*c2就是第一个卷积的输出channel=第二个卷积的输入channel</span></li>
         </ul> 
         <p><strong>模型结构：</strong>&nbsp;</p> 
         <p style="text-align:center;"><img alt="" height="198" src="https://i-blog.csdnimg.cn/blog_migrate/ac61dfece8be9ab93e6f38019f4ccec0.png" width="216"></p> 
         <p style="margin-left:auto;"><span style="color:#333333;"><span style="background-color:#ffffff;">通过上面瓶颈层的模型结构，我们可以看到瓶颈主要体现在<strong>通道数channel</strong>上面。</span></span></p> 
         <p style="margin-left:auto;"><span style="color:#333333;"><span style="background-color:#ffffff;">图中的红色虚线是</span></span><span style="color:#4da8ee;"><span style="background-color:#ffffff;"><strong>shortcut</strong></span></span><span style="color:#333333;"><span style="background-color:#ffffff;">，这里使用的</span></span><span style="color:#4da8ee;"><span style="background-color:#ffffff;"><strong>shortcut</strong></span></span><span style="color:#333333;"><span style="background-color:#ffffff;">成为</span></span><span style="color:#4da8ee;"><span style="background-color:#ffffff;"><strong>identity</strong></span></span><span style="color:#333333;"><span style="background-color:#ffffff;">分支，可以理解为<strong>恒等映射</strong>，另一个分支被称为</span></span><span style="color:#511b78;"><span style="background-color:#ffffff;">残差分支<strong>(Residual分支)</strong></span></span><span style="color:#333333;"><span style="background-color:#ffffff;">。</span></span></p> 
         <p style="margin-left:auto;"><span style="color:#333333;"><span style="background-color:#ffffff;">我们常使用的残差分支实际上是</span><strong><code><span style="background-color:#fefcd8;">1x1</span></code ><span style="background-color:#fefcd8;">+</span><code><span style="background-color:#fefcd8;">3x3</span></code ><span style="background-color:#fefcd8;">+</span><code><span style="background-color:#fefcd8;">1x1</span></code ></strong><span style="background-color:#ffffff;">的结构</span></span></p> 
         <hr> 
         <h3 id="2.5%C2%A0BottleneckCSP">2.5&nbsp;BottleneckCSP</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========5.BottleneckCSP：瓶颈层 由几个Bottleneck模块的堆叠+CSP结构组成================'''
class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        # 4个1*1卷积层的堆叠
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        # bn层
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        # 激活函数
        self.act = nn.SiLU()
        # m：叠加n次Bottleneck的操作
        # 操作符*可以把一个list拆开成一个个独立的元素
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        # y1相当于先做一次cv1操作然后进行m操作最后进行cv3操作，也就是BCSPn模块中的上面的分支操作
        # 输入x -&gt;Conv模块 -&gt;n个bottleneck模块 -&gt;Conv模块 -&gt;y1
        y1 = self.cv3(self.m(self.cv1(x)))
        # y2就是进行cv2操作，也就是BCSPn模块中的下面的分支操作（直接逆行conv操作的分支， Conv--nXBottleneck--conv）
        # 输入x -&gt; Conv模块 -&gt; 输出y2
        y2 = self.cv2(x)
        # 最后y1和y2做拼接， 接着进入bn层做归一化， 然后做act激活， 最后输出cv4
        # 输入y1,y2-&gt;按照通道数融合 -&gt;归一化 -&gt; 激活函数 -&gt; Conv输出 -&gt; 输出
        # torch.cat(y1, y2), dim=1: 这里是指定在第一个维度上进行合并，即在channel维度上合并
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))
</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>BottleneckCSP</strong>也是<strong>瓶颈层，由Bottleneck模块和CSP结构组成</strong></span></p> 
         <p><strong>具体结构如下图：</strong>&nbsp;</p> 
         <p><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/b158314ed4baf22dbd92fc4a144e0454.png">由上图可以看出<span style="color:#4da8ee;"><strong>BottleneckCSP</strong></span>中<strong><span style="color:#ff9900;">cv2</span></strong>和<span style="color:#ff9900;"><strong>cv3</strong></span>调用的是系统的卷积层，使用<strong><span style="color:#ff9900;">concat</span></strong>连接之后，加上BN层和激活函数。</p> 
         <p><strong>CSP结构</strong>主要思想是在输入block（如Bottleneck）之前，将输入分为两个部分，其中一部分<strong>通过block进行计算</strong>，另一部分直接<strong>通过一个带卷积shortcut进行concat</strong>。<br> 主要作用是<strong>加强CNN的学习能力、减少内存消耗，减少计算瓶颈</strong>，现在的网络大多计算代价昂贵，不利于工业的落地。</p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">整个BottleneckCSP的输入channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">整个BottleneckCSP的输出channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">n:</span></strong>&nbsp; <span style="color:#1a439c;">有n个Bottleneck</span></li>
          <li><strong><span style="background-color:#fef2f0;">g：</span>&nbsp;</strong>&nbsp;<span style="color:#1a439c;">g=1，表示从输入通道到输出通道的阻塞连接数为1</span></li>
          <li><strong><span style="background-color:#fef2f0;">e:</span></strong><span style="background-color:#fef2f0;">&nbsp;</span> &nbsp;<span style="color:#1a439c;">expansion ratio c2xe=中间其他所有层的卷积核个数/中间所有层的输入输出channel数</span></li>
          <li><span style="color:#0d0016;"><strong><span style="background-color:#fef2f0;">torch.cat((y1, y2), dim=1)</span></strong></span><span style="background-color:#fef2f0;">：</span> <span style="color:#1a439c;">这里是指定在第11个维度上进行合并，即在channel维度上合并</span></li>
          <li><strong><span style="background-color:#fef2f0;">c_:</span>&nbsp;</strong> <span style="color:#1a439c;">&nbsp;bottleneckCSP 结构的中间层的通道数，由膨胀率e决定</span></li>
         </ul> 
         <p><strong>模型结构：&nbsp;</strong></p> 
         <p style="text-align:center;"><strong><img alt="" height="339" src="https://i-blog.csdnimg.cn/blog_migrate/c44d088559553b7a7629ade7d9c894a0.png" width="201"></strong></p> 
         <p><span style="color:#4da8ee;"><strong>CSP瓶颈层结构</strong></span>在Bottleneck部分存在一个可修改的参数<span style="color:#ff9900;">n</span>，标识使用的Bottleneck结构个数。<strong>这一条也是我们的主分支，是对残差进行学习的主要结构</strong>(这里没有实现DenseNet，可选的有卷积块，transformer块、Ghost块)，右侧分支<strong><code><span style="background-color:#fff5e6;">nn.Conv2d</span></code ></strong>实际上是<strong>shortcut分支</strong>实现不同stage的连接(CSP的思想实现)。</p> 
         <hr> 
         <h3 id="2.6%C2%A0C3">2.6&nbsp;C3</h3> 
         <h4 id="2.6.1%20C3">2.6.1 C3</h4> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========6.C3：和BottleneckCSP模块类似，但是少了一个Conv模块================'''
# ===6.1 C3=== #
class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion

        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        # 3个1*1卷积层的堆叠，比BottleneckCSP少一个
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        # 将第一个卷积层与第二个卷积层的结果拼接在一起
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>C3</strong>是一种简化版的BottleneckCSP，<strong>模块和BottleneckCSP模块类似，但是少了一个Conv模块</strong>，<strong>只有3个卷积</strong>，可以减少参数，所以取名C3。其实结构是一样的，写法略微有差异。</span></p> 
         <p><span style="color:#4da8ee;"><strong>BottleneckCSP</strong></span>中<span style="color:#ff9900;">cv2</span>和<span style="color:#ff9900;">cv3</span>调用的是系统的卷积层，使用<strong>concat</strong>连接之后加上BN层和激活函数；C3则直接使用了作者自己定义的卷积层（conv+batchnorm+SiLU），这里激活函数也有修改。</p> 
         <p>&nbsp;<strong>具体结构如下图：</strong>&nbsp;</p> 
         <p style="text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/734de2a3d5f7d351177d29cc4ef436b4.png"></p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">整个BottleneckCSP的输入channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">整个BottleneckCSP的输出channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">n:</span></strong>&nbsp; <span style="color:#1a439c;">有n个Bottleneck</span></li>
          <li><strong><span style="background-color:#fef2f0;">shortcut:</span>&nbsp; &nbsp;</strong><span style="color:#1a439c;">bool Bottleneck中是否有shortcut，默认True</span></li>
          <li><strong><span style="background-color:#fef2f0;">g：</span>&nbsp;</strong>&nbsp;<span style="color:#1a439c;">g=1，表示从输入通道到输出通道的阻塞连接数为1</span></li>
          <li><strong><span style="background-color:#fef2f0;">e:</span></strong>&nbsp; &nbsp;<span style="color:#1a439c;">expansion ratio c2xe=中间其他所有层的卷积核个数/中间所有层的输入输出channel数</span></li>
         </ul> 
         <hr> 
         <h4 id="2.6.2%20C3SPP(C3)">2.6.2 C3SPP(C3)</h4> 
         <pre><code class="language-python"># ===6.2 C3SPP(C3)：继承自 C3，n 个 Bottleneck 更换为 1 个 SPP=== #
class C3SPP(C3):
    # C3 module with SPP()
    def __init__(self, c1, c2, k=(5, 9, 13), n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = SPP(c_, c_, k)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>C3SPP(C3)</strong>：<strong>继承自 C3，将n 个 Bottleneck 更换为 1 个 SPP</strong></span></p> 
         <p>参数和上面一样，不再细讲~</p> 
         <hr> 
         <h4 id="2.6.3%20C3Ghost(C3)">2.6.3 C3Ghost(C3)</h4> 
         <pre><code class="language-python"># ===6.3 C3Ghost(C3)：继承自 C3，Bottleneck 更换为 GhostBottleneck=== #
class C3Ghost(C3):
    # C3 module with GhostBottleneck()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)  # hidden channels
        self.m = nn.Sequential(*(GhostBottleneck(c_, c_) for _ in range(n)))</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>C3Ghost(C3)：继承自 C3，将Bottleneck 更换为 GhostBottleneck</strong></span></p> 
         <p>参数和上面一样，不再细讲~</p> 
         <hr> 
         <h3 id="2.7%C2%A0SPP">2.7&nbsp;SPP</h3> 
         <h4 id="2.7.1%20SPP">2.7.1 SPP</h4> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========7.SPP：空间金字塔池化模块================'''

# ===7.1 SPP：空间金字塔池化=== #
class SPP(nn.Module):
    # Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729
    def __init__(self, c1, c2, k=(5, 9, 13)):
       
        super().__init__()
        c_ = c1 // 2  # hidden channels
        # 1*1卷积
        self.cv1 = Conv(c1, c_, 1, 1)
        #  这里+1是因为有len(k)+1个输入
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        # m先进行最大池化操作， 然后通过nn.ModuleList进行构造一个模块 在构造时对每一个k都要进行最大池化
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])

    def forward(self, x):
        # 先进行cv1的操作
        x = self.cv1(x)
        # 忽略了警告错误的输出
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            # 对每一个m进行最大池化 和没有做池化的每一个输入进行叠加  然后做拼接 最后做cv2操作
            return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>SPP</strong>&nbsp;是<strong>空间金字塔池化的缩写</strong>。<strong>用在骨干网络收尾阶段，用于融合多尺度特征</strong>。</span></p> 
         <p><span style="color:#4da8ee;"><strong>SPP模块</strong></span>是何恺明等大佬提出来的，非常经典从yolov3中开始使用到现在，yolo系列基本上都用到了。这个模块的主要作用是为了将更多不同分辨率的特征进行融合，得到更多的信息。</p> 
         <p><strong>具体结构如下图：</strong>&nbsp;</p> 
         <p style="text-align:center;"><img alt="" height="162" src="https://i-blog.csdnimg.cn/blog_migrate/747d9eb4d7e006cc28d759a7d49902e6.png" width="579"></p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">SPP模块的输入channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:&nbsp;</span></strong>&nbsp; <span style="color:#1a439c;">SPP模块的输出channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">k:</span></strong>&nbsp; <span style="color:#1a439c;">保存着三个maxpool的卷积核大小 默认是(5, 9, 13)</span></li>
         </ul> 
         <hr> 
         <h4 id="%C2%A02.7.2%20SPPF">&nbsp;2.7.2 SPPF</h4> 
         <pre><code  style="height: 50vh;" class="language-python"># ===7.2 SPPF：快速版的空间金字塔池化=== #
class SPPF(nn.Module):
    # Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher
    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

    def forward(self, x):
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            y1 = self.m(x)
            y2 = self.m(y1)
            return self.cv2(torch.cat([x, y1, y2, self.m(y2)], 1))</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>SPPF</strong>是<strong>快速版的空间金字塔池化</strong></span></p> 
         <p>池化尺寸等价于：5、9、13，和原来一样，但是运算量从原来的&nbsp;<img alt="5^{2}+9^{2}+13^{2}=275" src="https://latex.csdn.net/eq?5%5E%7B2%7D&amp;plus;9%5E%7B2%7D&amp;plus;13%5E%7B2%7D%3D275">&nbsp;减少到了&nbsp;<img alt="3 \cdot 5^{2}=75" src="https://latex.csdn.net/eq?3%20%5Ccdot%205%5E%7B2%7D%3D75"></p> 
         <p>（YOLOv5中SPP和SPPF可以看这篇：<a href="https://blog.csdn.net/weixin_55073640/article/details/122621148?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168015601116800222867622%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168015601116800222867622&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_click~default-2-122621148-null-null.142%5Ev77%5Ewechat,201%5Ev4%5Eadd_ask,239%5Ev2%5Einsert_chatgpt&amp;utm_term=SPPF&amp;spm=1018.2226.3001.4187" title="YOLOv5中的SPP/SPPF结构详解_tt丫的博客-CSDN博客">YOLOv5中的SPP/SPPF结构详解_tt丫的博客-CSDN博客</a>）&nbsp;</p> 
         <hr> 
         <h3 id="2.8%C2%A0Focus">2.8&nbsp;Focus</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========8.Focus：把宽度w和高度h的信息整合到c空间================'''
class Focus(nn.Module):
    # Focus wh information into c-space
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
       
        super().__init__()
        # concat后的卷积（最后的卷积）
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)
        # self.contract = Contract(gain=2)

    def forward(self, x):  # x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)
        # 先进行切分， 然后进行拼接， 最后再做conv操作
        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))
        # return self.conv(self.contract(x))

    # 以下模块Contract，Expand,Concat是用来处理输入特征的shape的</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>Focus</strong>是YOLOv5作者自己设计的一个模块，用在了模型的一开始，<strong>作用是把宽度w和高度h的信息整合到c空间。</strong></span></p> 
         <p><strong>具体结构如下图：</strong>&nbsp;</p> 
         <p style="text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/234dc0d63513da90dfbef8d513e68847.png"></p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">slice后的channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:&nbsp;</span></strong>&nbsp; <span style="color:#1a439c;">Focus最终输出的channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">k:</span></strong><span style="background-color:#fef2f0;">&nbsp;</span> <span style="color:#1a439c;">最后卷积的kernel，k=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">s:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">最后卷积的stride，s=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">p:</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">最后卷积的padding</span></li>
          <li><strong><span style="background-color:#fef2f0;">g：</span>&nbsp;</strong>&nbsp;<span style="color:#1a439c;">g=1，表示从输入通道到输出通道的阻塞连接数为1</span></li>
          <li><strong><span style="background-color:#fef2f0;">act:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">bool激活函数类型 &nbsp;默认True:SiLU()/Swish &nbsp;False:不用激活函数</span></li>
         </ul> 
         <p><strong>主要思想：&nbsp;</strong></p> 
         <p><span style="color:#4da8ee;"><strong>Focus模块</strong></span>在YOLOv5中是图片进入<span style="color:#1c7331;">Backbone</span>前，对图片进行切片操作，具体操作是在一张图片中每隔一个像素拿到一个值，类似于邻近下采样，这样就拿到了四张图片，四张图片互补，长得差不多，但是没有信息丢失，这样一来，将W、H信息就集中到了通道空间，输入通道扩充了4倍，即拼接起来的图片相对于原先的RGB三通道模式变成了12个通道，最后将得到的新图片再经过卷积操作，最终得到了没有信息丢失情况下的二倍下采样特征图。</p> 
         <p style="text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/bc893643e26c9a2ada44c12c9c9bda8d.png"></p> 
         <p><strong>步骤：</strong></p> 
         <p>首先把输入x分别从（0,0）、（1,0）、（0,1）、（1,1）开始，按步长为2取值，然后进行一次卷积。</p> 
         <p>然后将输入（b,c,w,h）的shape变成了输出（b, 4c, w/2, h/2）。也就是说将特征层的长和宽都缩减为原来的一半，然后通道数变成原来的4倍，也可以理解成将一个图片等分切成4个，接着将这四个小的上下堆叠起来。</p> 
         <p>最后再经过一个conv输出。</p> 
         <hr> 
         <h3 id="2.9%C2%A0Contract">2.9&nbsp;Contract</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========9.Contract：收缩模块：调整张量的大小，将宽高收缩到通道中。================'''
class Contract(nn.Module):
    # Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)


    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        b, c, h, w = x.size()  # assert (h / s == 0) and (W / s == 0), 'Indivisible gain'
        s = self.gain
        # permute: 改变tensor的维度顺序
        x = x.view(b, c, h // s, s, w // s, s)  # x(1,64,40,2,40,2)
        # .view: 改变tensor的维度
        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
        return x.view(b, c * s * s, h // s, w // s)  # x(1,256,40,40)
</code ></pre> 
         <p>&nbsp;<span style="color:#fe2c24;"><strong>Contract</strong>是<strong>收缩模块，调整张量的大小，将宽高收缩到通道中</strong>。</span></p> 
         <p>将<strong><span style="color:#4da8ee;">feature map</span></strong>的<strong>w和h维度(缩小)的数据收缩到channel维度上(放大)</strong></p> 
         <p>如：当 gain = 2 的时候，(64, 80, 80) 的图像 -&gt; (256, 40, 40) 的图像。其操作类似 Focus，但更灵活，相比之下少了一个卷积。</p> 
         <hr> 
         <h3 id="2.10%20Expand">2.10 Expand</h3> 
         <pre><code class="language-python">'''===========10.Expand：扩张模块，将特征图像素变大================'''
class Expand(nn.Module):
    # Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        b, c, h, w = x.size()  # assert C / s ** 2 == 0, 'Indivisible gain'
        s = self.gain
        x = x.view(b, s, s, c // s ** 2, h, w)  # x(1,2,2,16,80,80)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
        return x.view(b, c // s ** 2, h * s, w * s)  # x(1,16,160,160)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>Expand</strong>是<strong>Contract的逆操作，扩张模块，将特征图像素变大</strong>。</span><br> 改变输入特征的shape，是将channel维度（变小）的数据扩展到 W 和 H 维度（变大）。</p> 
         <p>如：当 gain = 2 的时候，(1,64,80,80) 的图像 -&gt; (1,16,160,160)&nbsp;的图像。</p> 
         <hr> 
         <h3 id="2.11%20Concat">2.11 Concat</h3> 
         <pre><code class="language-python">'''===========11.Concat：自定义concat模块，dimension就是维度值，说明沿着哪一个维度进行拼接================'''
# 作拼接的一个类
# 拼接函数，将两个tensor进行拼接
class Concat(nn.Module):
    # Concatenate a list of tensors along dimension
    def __init__(self, dimension=1):
        super().__init__()
        self.d = dimension

    def forward(self, x):
        return torch.cat(x, self.d)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>Concat</strong>是<strong>拼接函数，将两个tensor进行拼接起来。</strong></span></p> 
         <p>这个是<span style="color:#4da8ee;"><strong>自定义concat模块</strong></span>，<span style="color:#ff9900;">dimension</span>就是维度值，说明沿着哪一个维度进行拼接。当 dimension = 1 时，将多张相同尺寸的图像在通道维度上拼接 (通道数可能不同)</p> 
         <p>这个函数是讲自身按照某个维度进行concat，常用来合并前后两个feature map，也就是yolov5s结构图中的Concat。</p> 
         <hr> 
         <h2 id="%F0%9F%9A%80%E4%B8%89%E3%80%81%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9D%97%C2%A0">🚀三、注意力模块&nbsp;</h2> 
         <p><s>关于transformer这个我还没有学习，所以这一块内容暂不做详解，等我后期学过再来填这个坑吧~</s></p> 
         <p><s>这里先放代码，小伙伴们自己看看吧！</s></p> 
         <p>我来填坑啦！transformer请看这里→<a href="https://blog.csdn.net/weixin_43334693/category_12288776.html?spm=1001.2014.3001.5482" title="transformer_路人贾'ω'的博客-CSDN博客">transformer_路人贾'ω'的博客-CSDN博客</a></p> 
         <h3 id="3.1%20TransformerLayer">3.1 TransformerLayer</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========1.TransformerLayer：================'''
class TransformerLayer(nn.Module):
    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)
    """
        Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)

        这部分相当于原论文中的单个Encoder部分(只移除了两个Norm部分, 其他结构和原文中的Encoding一模一样)
       """
    def __init__(self, c, num_heads):
        super().__init__()
        self.q = nn.Linear(c, c, bias=False)
        self.k = nn.Linear(c, c, bias=False)
        self.v = nn.Linear(c, c, bias=False)
        # 输入: query、key、value
        # 输出: 0 attn_output 即通过self-attention之后，从每一个词语位置输出来的attention 和输入的query它们形状一样的
        #      1 attn_output_weights 即attention weights 每一个单词和任意另一个单词之间都会产生一个weight
        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)
        self.fc1 = nn.Linear(c, c, bias=False)
        self.fc2 = nn.Linear(c, c, bias=False)

    def forward(self, x):
        # 多头注意力机制 + 残差(这里移除了LayerNorm for better performance)
        x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
        # feed forward 前馈神经网络 + 残差(这里移除了LayerNorm for better performance)
        x = self.fc2(self.fc1(x)) + x
        return x</code ></pre> 
         <hr> 
         <h3 id="3.2%20TransformerBlock">3.2 TransformerBlock</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========2.TransformerBlock：================'''
class TransformerBlock(nn.Module):
    # Vision Transformer https://arxiv.org/abs/2010.11929
    def __init__(self, c1, c2, num_heads, num_layers):
        super().__init__()
        self.conv = None
        if c1 != c2:
            self.conv = Conv(c1, c2)
        self.linear = nn.Linear(c2, c2)  # learnable position embedding
        self.tr = nn.Sequential(*(TransformerLayer(c2, num_heads) for _ in range(num_layers)))
        self.c2 = c2

    def forward(self, x):
        if self.conv is not None:
            x = self.conv(x)
        b, _, w, h = x.shape
        p = x.flatten(2).permute(2, 0, 1)
        return self.tr(p + self.linear(p)).permute(1, 2, 0).reshape(b, self.c2, w, h)
</code ></pre> 
         <hr> 
         <h2 id="%F0%9F%9A%80%E5%9B%9B%E3%80%81%E5%B9%BB%E8%B1%A1%E6%A8%A1%E5%9D%97">🚀四、幻象模块</h2> 
         <h3 id="4.1%C2%A0GhostConv">4.1&nbsp;GhostConv</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========1.GhostConv：幻象卷积  轻量化网络卷积模块================'''
class GhostConv(nn.Module):
    # Ghost Convolution https://github.com/huawei-noah/ghostnet

    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups
        super().__init__()
        c_ = c2 // 2  # hidden channels
        # 第一步卷积: 少量卷积, 一般是一半的计算量
        self.cv1 = Conv(c1, c_, k, s, None, g, act)
        # 第二步卷积: cheap operations 使用3x3或5x5的卷积, 并且是逐个特征图的进行卷积（Depth-wise convolutional
        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act)

    def forward(self, x):
        y = self.cv1(x)
        return torch.cat([y, self.cv2(y)], 1)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>GhostConv</strong>是<strong>幻象卷积，属于轻量化网络卷积模块</strong></span></p> 
         <p><strong>具体结构如下图：</strong>&nbsp;</p> 
         <p style="text-align:center;"><img alt="" height="208" src="https://i-blog.csdnimg.cn/blog_migrate/5f7594a87a05d76d85db9fe947579b1e.png" width="538"></p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">输入的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">输出的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">k:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">卷积的kernel_size，k=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">s:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">卷积的stride，s=1</span></li>
          <li><strong><span style="background-color:#fef2f0;">g:&nbsp;</span> </strong>&nbsp; <span style="color:#1a439c;">g=1表示从输入通道到输出通道的阻塞连接数为1</span></li>
          <li><strong><span style="background-color:#fef2f0;">act:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">激活函数类型，True就是SiLU()/Swish，False就是不使用激活函数，类型是nn.Module就使用传进来的激活函数类型</span></li>
         </ul> 
         <p><span style="color:#4da8ee;"><strong>GhostConv</strong></span>主要作用是<strong>可以代替一般的Conv，GhostBottleneck代替C3</strong>，至于在哪些位置代替，可以自己决定。幻象模块虽然不能增加mAP，但是可以大大减少模型计算量。</p> 
         <hr> 
         <h3 id="%C2%A04.2%C2%A0GhostBottleneck">&nbsp;4.2&nbsp;GhostBottleneck</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========2.GhostBottleneck：幻象瓶颈层 ================'''
class GhostBottleneck(nn.Module):
    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride
        super().__init__()
        c_ = c2 // 2
        self.conv = nn.Sequential(GhostConv(c1, c_, 1, 1),  # pw
                                  DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw
                                  GhostConv(c_, c2, 1, 1, act=False))  # pw-linear
        # 注意, 源码中并不是直接Identity连接, 而是先经过一个DWConv + Conv, 再进行shortcut连接的。
        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False),
                                      Conv(c1, c2, 1, 1, act=False)) if s == 2 else nn.Identity()

    def forward(self, x):
        return self.conv(x) + self.shortcut(x)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>GhostBottleneck</strong>顾名思义就是<strong>幻象模块的瓶颈层</strong>。</span></p> 
         <p><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">输入的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">输出的channel值</span></li>
          <li><strong><span style="background-color:#fef2f0;">k:</span>&nbsp;</strong> &nbsp; <span style="color:#1a439c;">卷积的kernel_size，k=3</span></li>
          <li><strong><span style="background-color:#fef2f0;">s:</span>&nbsp;</strong> &nbsp; <span style="color:#1a439c;">卷积的stride，s=1</span></li>
         </ul> 
         <p><strong>具体结构如下图：</strong>&nbsp;</p> 
         <p style="text-align:center;"><img alt="" height="366" src="https://i-blog.csdnimg.cn/blog_migrate/77e2d3e2159b92e41adc2ee81f56e3db.png" width="551"></p> 
         <p>这是一个可复用模块，我们可以放到现有的网络中替换掉Bottleneck模块，从而减少计算了，降低模型体积。类似于ResNet中的基本残差块，由两个堆叠的Ghost模块组成：</p> 
         <ul>
          <li>第一个Ghost模块用作扩展层，增加了通道数。这里将输出通道数与输入通道数之比称为expansion ratio。第二个Ghost模块减少通道数，以与shortcut路径匹配。然后，使用shortcut连接这两个Ghost模块的输入和输出。</li>
          <li>第二个Ghost 模块不使用ReLU其他层在每层之后都应用了批量归一化（BN）和ReLu激活函数（主要借鉴了MobileNetV2的思想）</li>
         </ul> 
         <p><span style="color:#4da8ee;"><strong>Ghost Bottleneck</strong></span>中对于stride = 2的情况，两个Ghost module之间通过一个stride = 2的深度卷积进行连接。</p> 
         <p>（这个内容以后也会等学习后再详细说，这里参考：<a href="https://blog.csdn.net/ai_faker/article/details/109261824" title="[目标检测]-cv常用模块ghostbottleneck原理讲解与pytorch实现_orangezs的博客-CSDN博客">[目标检测]-cv常用模块ghostbottleneck原理讲解与pytorch实现_orangezs的博客-CSDN博客</a>）</p> 
         <hr> 
         <h2 id="%F0%9F%9A%80%E4%BA%94%E3%80%81%E6%A8%A1%E5%9E%8B%E6%89%A9%E5%B1%95%E6%A8%A1%E5%9D%97">🚀五、模型扩展模块</h2> 
         <h3 id="5.1%20C3TR(C3)">5.1 C3TR(C3)</h3> 
         <pre><code class="language-python">'''===========1.C3TR(C3)：继承自 C3，n 个 Bottleneck 更换为 1 个 TransformerBlock ================'''
class C3TR(C3):

    # C3 module with TransformerBlock()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = TransformerBlock(c_, c_, 4, n)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>C3TR(C3)</strong>是<strong>继承自 C3，将n 个 Bottleneck 更换为 1 个 TransformerBlock</strong></span><br> 这部分是根据上面的C3结构改编而来的，将原先的Bottleneck替换为调用TransformerBlock模块<br><strong>参数：</strong></p> 
         <ul>
          <li><strong><span style="background-color:#fef2f0;">c1:</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">整个C3的输入channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">c2:</span>&nbsp;</strong> &nbsp;<span style="color:#1a439c;">整个C3的输出channel</span></li>
          <li><strong><span style="background-color:#fef2f0;">n:</span></strong><span style="background-color:#fef2f0;">&nbsp;</span> &nbsp; <span style="color:#1a439c;">有n个子模块[Bottleneck/CrossConv]</span></li>
          <li><strong><span style="background-color:#fef2f0;">shortcut:&nbsp;</span></strong> &nbsp;<span style="color:#1a439c;">bool值，子模块[Bottlenec/CrossConv]中是否有shortcut，默认True</span></li>
          <li><strong><span style="background-color:#fef2f0;">g:&nbsp;</span> </strong>&nbsp; <span style="color:#1a439c;">g=1表示从输入通道到输出通道的阻塞连接数为1</span></li>
          <li><strong><span style="background-color:#fef2f0;">e:&nbsp;</span></strong> &nbsp; <span style="color:#1a439c;">expansion ratio，e*c2=中间其它所有层的卷积核个数=中间所有层的的输入输出channel</span></li>
         </ul> 
         <hr> 
         <h3 id="5.2%20AutoShape">5.2 AutoShape</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========2.AutoShape：自动调整shape,该类基本未用================'''
class AutoShape(nn.Module):
    # YOLOv5 input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS
    conf = 0.25  # NMS confidence threshold
    iou = 0.45  # NMS IoU threshold
    classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs
    multi_label = False  # NMS multiple labels per box
    max_det = 1000  # maximum number of detections per image

    def __init__(self, model):
        super().__init__()
        self.model = model.eval()

    def autoshape(self):
        LOGGER.info('AutoShape already enabled, skipping... ')  # model already converted to model.autoshape()
        return self

    def _apply(self, fn):
        # Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers
        self = super()._apply(fn)
        m = self.model.model[-1]  # Detect()
        m.stride = fn(m.stride)
        m.grid = list(map(fn, m.grid))
        if isinstance(m.anchor_grid, list):
            m.anchor_grid = list(map(fn, m.anchor_grid))
        return self

    @torch.no_grad()
    def forward(self, imgs, size=640, augment=False, profile=False):
        # Inference from various sources. For height=640, width=1280, RGB images example inputs are:
        #   file:       imgs = 'data/images/zidane.jpg'  # str or PosixPath
        #   URI:             = 'https://ultralytics.com/images/zidane.jpg'
        #   OpenCV:          = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)
        #   PIL:             = Image.open('image.jpg') or ImageGrab.grab()  # HWC x(640,1280,3)
        #   numpy:           = np.zeros((640,1280,3))  # HWC
        #   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)
        #   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images

        t = [time_sync()]
        p = next(self.model.parameters())  # for device and type
        if isinstance(imgs, torch.Tensor):  # torch
            with amp.autocast(enabled=p.device.type != 'cpu'):
                return self.model(imgs.to(p.device).type_as(p), augment, profile)  # inference

        # Pre-process
        n, imgs = (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])  # number of images, list of images
        shape0, shape1, files = [], [], []  # image and inference shapes, filenames
        for i, im in enumerate(imgs):
            f = f'image{i}'  # filename
            if isinstance(im, (str, Path)):  # filename or uri
                im, f = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im), im
                im = np.asarray(exif_transpose(im))
            elif isinstance(im, Image.Image):  # PIL Image
                im, f = np.asarray(exif_transpose(im)), getattr(im, 'filename', f) or f
            files.append(Path(f).with_suffix('.jpg').name)
            if im.shape[0] &lt; 5:  # image in CHW
                im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)
            im = im[..., :3] if im.ndim == 3 else np.tile(im[..., None], 3)  # enforce 3ch input
            s = im.shape[:2]  # HWC
            shape0.append(s)  # image shape
            g = (size / max(s))  # gain
            shape1.append([y * g for y in s])
            imgs[i] = im if im.data.contiguous else np.ascontiguousarray(im)  # update
        shape1 = [make_divisible(x, int(self.stride.max())) for x in np.stack(shape1, 0).max(0)]  # inference shape
        x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad
        x = np.stack(x, 0) if n &gt; 1 else x[0][None]  # stack
        x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW
        x = torch.from_numpy(x).to(p.device).type_as(p) / 255  # uint8 to fp16/32
        t.append(time_sync())

        with amp.autocast(enabled=p.device.type != 'cpu'):
            # Inference
            y = self.model(x, augment, profile)[0]  # forward
            t.append(time_sync())

            # Post-process
            y = non_max_suppression(y, self.conf, iou_thres=self.iou, classes=self.classes,
                                    multi_label=self.multi_label, max_det=self.max_det)  # NMS
            for i in range(n):
                scale_coords(shape1, y[i][:, :4], shape0[i])

            t.append(time_sync())
            return Detections(imgs, y, files, t, self.names, x.shape)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>AutoShape</strong>是一<strong>个模型扩展模块，给模型封装成包含前处理、推理、后处理的模块(预处理 + 推理 + nms)</strong>。</span></p> 
         <p>注意<span style="color:#0d0016;">A</span>utoshape模块在train中不会被调用，当模型训练结束后，会通过这个模块对图片进行重塑，来方便模型的预测。</p> 
         <p>因为这个模块基本没啥用，所以不做细讲。</p> 
         <hr> 
         <h3 id="5.3%20Detections">5.3 Detections</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========3.Detections：对推理结果进行处理================'''
class Detections:
    # YOLOv5 detections class for inference results
    """用在AutoShape函数结尾
    detections class for YOLOv5 inference results
    """
    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):
        super().__init__()
        d = pred[0].device  # device
        gn = [torch.tensor([*(im.shape[i] for i in [1, 0, 1, 0]), 1, 1], device=d) for im in imgs]  # normalizations
        # imgs：原图
        self.imgs = imgs  # list of images as numpy arrays
        # pred：预测值(xyxy, conf, cls)
        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)
        # names： 类名
        self.names = names  # class names
        # files： 图像文件名
        self.files = files  # image filenames
        # xyxy：左上角+右下角格式
        self.xyxy = pred  # xyxy pixels
        # xywh：中心点+宽长格式
        self.xywh = [xyxy2xywh(x) for x in pred]  # xywh pixels
        # xyxyn：xyxy标准化
        self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # xyxy normalized
        # xywhn：xywhn标准化
        self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # xywh normalized
        self.n = len(self.pred)  # number of images (batch size)
        self.t = tuple((times[i + 1] - times[i]) * 1000 / self.n for i in range(3))  # timestamps (ms)
        self.s = shape  # inference BCHW shape

    def display(self, pprint=False, show=False, save=False, crop=False, render=False, save_dir=Path('')):
        crops = []
        for i, (im, pred) in enumerate(zip(self.imgs, self.pred)):
            s = f'image {i + 1}/{len(self.pred)}: {im.shape[0]}x{im.shape[1]} '  # string
            if pred.shape[0]:
                for c in pred[:, -1].unique():
                    n = (pred[:, -1] == c).sum()  # detections per class
                    s += f"{n} {self.names[int(c)]}{'s' * (n &gt; 1)}, "  # add to string
                if show or save or render or crop:
                    annotator = Annotator(im, example=str(self.names))
                    for *box, conf, cls in reversed(pred):  # xyxy, confidence, class
                        label = f'{self.names[int(cls)]} {conf:.2f}'
                        if crop:
                            file = save_dir / 'crops' / self.names[int(cls)] / self.files[i] if save else None
                            crops.append({'box': box, 'conf': conf, 'cls': cls, 'label': label,
                                          'im': save_one_box(box, im, file=file, save=save)})
                        else:  # all others
                            annotator.box_label(box, label, color=colors(cls))
                    im = annotator.im
            else:
                s += '(no detections)'

            im = Image.fromarray(im.astype(np.uint8)) if isinstance(im, np.ndarray) else im  # from np
            if pprint:
                LOGGER.info(s.rstrip(', '))
            if show:
                im.show(self.files[i])  # show
            if save:
                f = self.files[i]
                im.save(save_dir / f)  # save
                if i == self.n - 1:
                    LOGGER.info(f"Saved {self.n} image{'s' * (self.n &gt; 1)} to {colorstr('bold', save_dir)}")
            if render:
                self.imgs[i] = np.asarray(im)
        if crop:
            if save:
                LOGGER.info(f'Saved results to {save_dir}\n')
            return crops

    def print(self):
        self.display(pprint=True)  # print results
        LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {tuple(self.s)}' %
                    self.t)

    def show(self):
        self.display(show=True)  # show results

    def save(self, save_dir='runs/detect/exp'):
        save_dir = increment_path(save_dir, exist_ok=save_dir != 'runs/detect/exp', mkdir=True)  # increment save_dir
        self.display(save=True, save_dir=save_dir)  # save results

    def crop(self, save=True, save_dir='runs/detect/exp'):
        save_dir = increment_path(save_dir, exist_ok=save_dir != 'runs/detect/exp', mkdir=True) if save else None
        return self.display(crop=True, save=save, save_dir=save_dir)  # crop results

    def render(self):
        self.display(render=True)  # render results
        return self.imgs

    def pandas(self):
        # return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])
        new = copy(self)  # return copy
        ca = 'xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'  # xyxy columns
        cb = 'xcenter', 'ycenter', 'width', 'height', 'confidence', 'class', 'name'  # xywh columns
        for k, c in zip(['xyxy', 'xyxyn', 'xywh', 'xywhn'], [ca, ca, cb, cb]):
            a = [[x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()] for x in getattr(self, k)]  # update
            setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
        return new

    def tolist(self):
        # return a list of Detections objects, i.e. 'for result in results.tolist():'
        x = [Detections([self.imgs[i]], [self.pred[i]], self.names, self.s) for i in range(self.n)]
        for d in x:
            for k in ['imgs', 'pred', 'xyxy', 'xyxyn', 'xywh', 'xywhn']:
                setattr(d, k, getattr(d, k)[0])  # pop out of list
        return x

    def __len__(self):
        return self.n
</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>Detections</strong>是<strong>专门针对目标检测的封装类，对推理结果进行处理。</strong></span></p> 
         <p>这个模块吧，代码so长。是对推理结果进行一些处理，用的不是很多，整个YOLOv5只在上面的<strong><span style="color:#1c7331;">AutoShape函数</span></strong>结尾调用了一下。不用仔细研究的，把yolo.py的<span style="color:#0d0016;">Detect模块了解清楚既可~</span></p> 
         <hr> 
         <h3 id="5.4%C2%A0Classify">5.4&nbsp;Classify</h3> 
         <pre><code  style="height: 50vh;" class="language-python">'''===========4.Classify：二级分类模块================'''
class Classify(nn.Module):
    # Classification head, i.e. x(b,c1,20,20) to x(b,c2)
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups

        super().__init__()
        self.aap = nn.AdaptiveAvgPool2d(1)  # to x(b,c1,1,1)
        # 自适应平均池化操作
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g)  # to x(b,c2,1,1)
        # 展平
        self.flat = nn.Flatten()

    def forward(self, x):
        # 先自适应平均池化操作， 然后拼接
        z = torch.cat([self.aap(y) for y in (x if isinstance(x, list) else [x])], 1)  # cat if list
        # 对z进行展平操作
        return self.flat(self.conv(z))  # flatten to x(b,c2)</code ></pre> 
         <p><span style="color:#fe2c24;"><strong>Classify</strong>是<strong>一个二级分类模块</strong></span></p> 
         <blockquote> 
          <p><span style="color:#ff9900;">什么是二级分类模块?</span></p> 
          <p>比如做车牌的识别，先识别出车牌，如果想对车牌上的字进行识别，就需要二级分类进一步检测。</p> 
          <p>再比如要做识别人脸面部表情，先要识别出人脸，如果想识别出人的面部表情，就需要二级分类进一步检测。</p> 
         </blockquote> 
         <hr> 
         <h2 id="%C2%A0%F0%9F%9A%80%E5%85%AD%E3%80%81common.py%E5%85%A8%E9%83%A8%E6%B3%A8%E9%87%8A">&nbsp;🚀六、common.py全部注释</h2> 
         <pre><code  style="height: 50vh;" class="language-python"># YOLOv5 🚀 by Ultralytics, GPL-3.0 license
"""
Common modules
"""
'''===============================================一、导入包==================================================='''
'''======================1.导入安装好的python库====================='''
import json  # 用于json和Python数据之间的相互转换
import math  # 数学函数模块
import platform  # 获取操作系统的信息
import warnings  # 警告程序员关于语言或库功能的变化的方法
from copy import copy  # 数据拷贝模块 分浅拷贝和深拷贝
from pathlib import Path  # Path将str转换为Path对象 使字符串路径易于操作的模块

import cv2  # 调用OpenCV的cv库
import numpy as np  # numpy数组操作模块
import pandas as pd  # panda数组操作模块
import requests  # Python的HTTP客户端库
import torch  # pytorch深度学习框架
import torch.nn as nn  # 专门为神经网络设计的模块化接口
from PIL import Image  # 图像基础操作模块
from torch.cuda import amp  # 混合精度训练模块

'''===================2.加载自定义模块============================'''
from utils.datasets import exif_transpose, letterbox  # 加载数据集的函数
from utils.general import (LOGGER, check_requirements, check_suffix, colorstr, increment_path, make_divisible,
                           non_max_suppression, scale_coords, xywh2xyxy, xyxy2xywh)  # 定义了一些常用的工具函数
from utils.plots import Annotator, colors, plot_one_box  # 定义了Annotator类，可以在图像上绘制矩形框和标注信息
from utils.torch_utils import time_sync  # 定义了一些与PyTorch有关的工具函数

'''===============================================二、基础组件==================================================='''
'''===========1.autopad：根据输入的卷积核计算该卷积模块所需的pad值================'''
# 为same卷积或者same池化自动扩充
# 通过卷积核的大小来计算需要的padding为多少才能把tensor补成原来的形状
def autopad(k, p=None):  # kernel, padding
    # Pad to 'same'
    # 如果p是none 则进行下一步
    if p is None:
        # 如果k是int 则进行k//2 若不是则进行x//2
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p

'''===========2.Conv：标准卷积 由Conv + BN + activate组成================'''
class Conv(nn.Module):
    # Standard convolution
    # init初始化构造函数
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        """在Focus、Bottleneck、BottleneckCSP、C3、SPP、DWConv、TransformerBloc等模块中调用
                Standard convolution  conv+BN+act
                :params c1: 输入的channel值
                :params c2: 输出的channel值
                :params k: 卷积的kernel_size
                :params s: 卷积的stride
                :params p: 卷积的padding  一般是None  可以通过autopad自行计算需要pad的padding数
                :params g: 卷积的groups数  =1就是普通的卷积  &gt;1就是深度可分离卷积
                :params act: 激活函数类型   True就是SiLU()/Swish   False就是不使用激活函数
                             类型是nn.Module就使用传进来的激活函数类型
        """
        super().__init__()
        # 卷积层
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        # 归一化层
        self.bn = nn.BatchNorm2d(c2)
        # 激活函数
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    # 正向计算，网络执行的顺序是根据forward函数来决定的
    def forward(self, x):
        # conv卷积 -&gt; bn -&gt; act激活
        return self.act(self.bn(self.conv(x)))

    # 正向融合计算
    def forward_fuse(self, x):
        # 这里只有卷积和激活
        return self.act(self.conv(x))

'''===========3.DWConv：深度可分离卷积================'''
class DWConv(Conv):
    # Depth-wise convolution class
    def __init__(self, c1, c2, k=1, s=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), act=act)

'''===========4.Bottleneck：标准的瓶颈层 由1x1conv+3x3conv+残差块组成================'''
class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        """在BottleneckCSP和yolo.py的parse_model中调用
          Standard bottleneck  Conv+Conv+shortcut
          :params c1: 第一个卷积的输入channel
          :params c2: 第二个卷积的输出channel
          :params shortcut: bool 是否有shortcut连接 默认是True
          :params g: 卷积分组的个数  =1就是普通卷积  &gt;1就是深度可分离卷积
          :params e: expansion ratio  e*c2就是第一个卷积的输出channel=第二个卷积的输入channel
          """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        # 1*1卷积层
        self.cv1 = Conv(c1, c_, 1, 1)
        # 3*3卷积层
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        # 如果shortcut为True就会将输入和输出相加之后再输出
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

'''===========5.BottleneckCSP：瓶颈层 由几个Bottleneck模块的堆叠+CSP结构组成================'''
class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        """在C3模块和yolo.py的parse_model模块调用
            CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
            :params c1: 整个BottleneckCSP的输入channel
            :params c2: 整个BottleneckCSP的输出channel
            :params n: 有n个Bottleneck
            :params shortcut: bool Bottleneck中是否有shortcut，默认True
            :params g: Bottleneck中的3x3卷积类型  =1普通卷积  &gt;1深度可分离卷积
            :params e: expansion ratio c2xe=中间其他所有层的卷积核个数/中间所有层的输入输出channel数
            c_: bottleneckCSP 结构的中间层的通道数，由膨胀率e决定
            """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        # 4个1*1卷积层的堆叠
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        # bn层
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        # 激活函数
        self.act = nn.SiLU()
        # m：叠加n次Bottleneck的操作
        # 操作符*可以把一个list拆开成一个个独立的元素
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        # y1相当于先做一次cv1操作然后进行m操作最后进行cv3操作，也就是BCSPn模块中的上面的分支操作
        # 输入x -&gt;Conv模块 -&gt;n个bottleneck模块 -&gt;Conv模块 -&gt;y1
        y1 = self.cv3(self.m(self.cv1(x)))
        # y2就是进行cv2操作，也就是BCSPn模块中的下面的分支操作（直接逆行conv操作的分支， Conv--nXBottleneck--conv）
        # 输入x -&gt; Conv模块 -&gt; 输出y2
        y2 = self.cv2(x)
        # 最后y1和y2做拼接， 接着进入bn层做归一化， 然后做act激活， 最后输出cv4
        # 输入y1,y2-&gt;按照通道数融合 -&gt;归一化 -&gt; 激活函数 -&gt; Conv输出 -&gt; 输出
        # torch.cat(y1, y2), dim=1: 这里是指定在第一个维度上进行合并，即在channel维度上合并
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))

'''===========6.C3：和BottleneckCSP模块类似，但是少了一个Conv模块================'''
# ===6.1 C3=== #
class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        """在C3TR模块和yolo.py的parse_model模块调用
         CSP Bottleneck with 3 convolutions
         :params c1: 整个BottleneckCSP的输入channel
         :params c2: 整个BottleneckCSP的输出channel
         :params n: 有n个Bottleneck
         :params shortcut: bool Bottleneck中是否有shortcut，默认True
         :params g: Bottleneck中的3x3卷积类型  =1普通卷积  &gt;1深度可分离卷积
         :params e: expansion ratio c2xe=中间其他所有层的卷积核个数/中间所有层的输入输出channel数
         """
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        # 3个1*1卷积层的堆叠，比BottleneckCSP少一个
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        # 将第一个卷积层与第二个卷积层的结果拼接在一起
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))

# ===6.2 C3SPP(C3)：继承自 C3，n 个 Bottleneck 更换为 1 个 SPP=== #
class C3SPP(C3):
    # C3 module with SPP()
    def __init__(self, c1, c2, k=(5, 9, 13), n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = SPP(c_, c_, k)

# ===6.3 C3Ghost(C3)：继承自 C3，Bottleneck 更换为 GhostBottleneck=== #
class C3Ghost(C3):
    # C3 module with GhostBottleneck()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)  # hidden channels
        self.m = nn.Sequential(*(GhostBottleneck(c_, c_) for _ in range(n)))

'''===========7.SPP：空间金字塔池化模块================'''
# 用在骨干网络收尾阶段，用于融合多尺度特征。
# ===7.1 SPP：空间金字塔池化=== #
class SPP(nn.Module):
    # Spatial Pyramid Pooling (SPP) layer https://arxiv.org/abs/1406.4729
    def __init__(self, c1, c2, k=(5, 9, 13)):
        """在yolo.py的parse_model模块调用
               空间金字塔池化 Spatial pyramid pooling layer used in YOLOv3-SPP
               :params c1: SPP模块的输入channel
               :params c2: SPP模块的输出channel
               :params k: 保存着三个maxpool的卷积核大小 默认是(5, 9, 13)
               """
        super().__init__()
        c_ = c1 // 2  # hidden channels
        # 1*1卷积
        self.cv1 = Conv(c1, c_, 1, 1)
        #  这里+1是因为有len(k)+1个输入
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        # m先进行最大池化操作， 然后通过nn.ModuleList进行构造一个模块 在构造时对每一个k都要进行最大池化
        self.m = nn.ModuleList([nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k])

    def forward(self, x):
        # 先进行cv1的操作
        x = self.cv1(x)
        # 忽略了警告错误的输出
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            # 对每一个m进行最大池化 和没有做池化的每一个输入进行叠加  然后做拼接 最后做cv2操作
            return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))

# ===7.2 SPPF：快速版的空间金字塔池化=== #
class SPPF(nn.Module):
    # Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher
    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

    def forward(self, x):
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            y1 = self.m(x)
            y2 = self.m(y1)
            return self.cv2(torch.cat([x, y1, y2, self.m(y2)], 1))


'''===========8.Focus：把宽度w和高度h的信息整合到c空间================'''
class Focus(nn.Module):
    # Focus wh information into c-space
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        """在yolo.py的parse_model函数中被调用
                理论：从高分辨率图像中，周期性的抽出像素点重构到低分辨率图像中，即将图像相邻的四个位置进行堆叠，
                    聚焦wh维度信息到c通道空，提高每个点感受野，并减少原始信息的丢失，该模块的设计主要是减少计算量加快速度。
                Focus wh information into c-space 把宽度w和高度h的信息整合到c空间中
                先做4个slice 再concat 最后再做Conv
                slice后 (b,c1,w,h) -&gt; 分成4个slice 每个slice(b,c1,w/2,h/2)
                concat(dim=1)后 4个slice(b,c1,w/2,h/2)) -&gt; (b,4c1,w/2,h/2)
                conv后 (b,4c1,w/2,h/2) -&gt; (b,c2,w/2,h/2)
                :params c1: slice后的channel
                :params c2: Focus最终输出的channel
                :params k: 最后卷积的kernel
                :params s: 最后卷积的stride
                :params p: 最后卷积的padding
                :params g: 最后卷积的分组情况  =1普通卷积  &gt;1深度可分离卷积
                :params act: bool激活函数类型  默认True:SiLU()/Swish  False:不用激活函数
                """
        super().__init__()
        # concat后的卷积（最后的卷积）
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)
        # self.contract = Contract(gain=2)

    def forward(self, x):  # x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)
        # 先进行切分， 然后进行拼接， 最后再做conv操作
        return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))
        # return self.conv(self.contract(x))

    # 以下模块Contract，Expand,Concat是用来处理输入特征的shape的
'''===========9.Contract：收缩模块：调整张量的大小，将宽高收缩到通道中。================'''
class Contract(nn.Module):
    # Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    """用在yolo.py的parse_model模块 用的不多
    改变输入特征的shape 将w和h维度(缩小)的数据收缩到channel维度上(放大)
    Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    """

    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        b, c, h, w = x.size()  # assert (h / s == 0) and (W / s == 0), 'Indivisible gain'
        s = self.gain
        # permute: 改变tensor的维度顺序
        x = x.view(b, c, h // s, s, w // s, s)  # x(1,64,40,2,40,2)
        # .view: 改变tensor的维度
        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
        return x.view(b, c * s * s, h // s, w // s)  # x(1,256,40,40)

'''===========10.Expand：扩张模块，将特征图像素变大================'''
class Expand(nn.Module):
    # Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        b, c, h, w = x.size()  # assert C / s ** 2 == 0, 'Indivisible gain'
        s = self.gain
        x = x.view(b, s, s, c // s ** 2, h, w)  # x(1,2,2,16,80,80)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
        return x.view(b, c // s ** 2, h * s, w * s)  # x(1,16,160,160)

'''===========11.Concat：自定义concat模块，dimension就是维度值，说明沿着哪一个维度进行拼接================'''
# 作拼接的一个类
# 拼接函数，将两个tensor进行拼接
class Concat(nn.Module):
    # Concatenate a list of tensors along dimension
    def __init__(self, dimension=1):
        super().__init__()
        self.d = dimension

    def forward(self, x):
        return torch.cat(x, self.d)

'''===============================================三、注意力模块==================================================='''
'''===========1.TransformerLayer：================'''
class TransformerLayer(nn.Module):
    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)
    """
        Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)

        这部分相当于原论文中的单个Encoder部分(只移除了两个Norm部分, 其他结构和原文中的Encoding一模一样)
       """
    def __init__(self, c, num_heads):
        super().__init__()
        self.q = nn.Linear(c, c, bias=False)
        self.k = nn.Linear(c, c, bias=False)
        self.v = nn.Linear(c, c, bias=False)
        # 输入: query、key、value
        # 输出: 0 attn_output 即通过self-attention之后，从每一个词语位置输出来的attention 和输入的query它们形状一样的
        #      1 attn_output_weights 即attention weights 每一个单词和任意另一个单词之间都会产生一个weight
        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)
        self.fc1 = nn.Linear(c, c, bias=False)
        self.fc2 = nn.Linear(c, c, bias=False)

    def forward(self, x):
        # 多头注意力机制 + 残差(这里移除了LayerNorm for better performance)
        x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
        # feed forward 前馈神经网络 + 残差(这里移除了LayerNorm for better performance)
        x = self.fc2(self.fc1(x)) + x
        return x

'''===========2.TransformerBlock：================'''
class TransformerBlock(nn.Module):
    # Vision Transformer https://arxiv.org/abs/2010.11929
    def __init__(self, c1, c2, num_heads, num_layers):
        super().__init__()
        self.conv = None
        if c1 != c2:
            self.conv = Conv(c1, c2)
        self.linear = nn.Linear(c2, c2)  # learnable position embedding
        self.tr = nn.Sequential(*(TransformerLayer(c2, num_heads) for _ in range(num_layers)))
        self.c2 = c2

    def forward(self, x):
        if self.conv is not None:
            x = self.conv(x)
        b, _, w, h = x.shape
        p = x.flatten(2).permute(2, 0, 1)
        return self.tr(p + self.linear(p)).permute(1, 2, 0).reshape(b, self.c2, w, h)

'''===============================================四、幻象模块==================================================='''
'''===========1.GhostConv：幻象卷积  轻量化网络卷积模块================'''
class GhostConv(nn.Module):
    # Ghost Convolution https://github.com/huawei-noah/ghostnet

    def __init__(self, c1, c2, k=1, s=1, g=1, act=True):  # ch_in, ch_out, kernel, stride, groups
        super().__init__()
        c_ = c2 // 2  # hidden channels
        # 第一步卷积: 少量卷积, 一般是一半的计算量
        self.cv1 = Conv(c1, c_, k, s, None, g, act)
        # 第二步卷积: cheap operations 使用3x3或5x5的卷积, 并且是逐个特征图的进行卷积（Depth-wise convolutional
        self.cv2 = Conv(c_, c_, 5, 1, None, c_, act)

    def forward(self, x):
        y = self.cv1(x)
        return torch.cat([y, self.cv2(y)], 1)

'''===========2.GhostBottleneck：幻象瓶颈层 ================'''
class GhostBottleneck(nn.Module):
    # Ghost Bottleneck https://github.com/huawei-noah/ghostnet
    def __init__(self, c1, c2, k=3, s=1):  # ch_in, ch_out, kernel, stride
        super().__init__()
        c_ = c2 // 2
        self.conv = nn.Sequential(GhostConv(c1, c_, 1, 1),  # pw
                                  DWConv(c_, c_, k, s, act=False) if s == 2 else nn.Identity(),  # dw
                                  GhostConv(c_, c2, 1, 1, act=False))  # pw-linear
        # 注意, 源码中并不是直接Identity连接, 而是先经过一个DWConv + Conv, 再进行shortcut连接的。
        self.shortcut = nn.Sequential(DWConv(c1, c1, k, s, act=False),
                                      Conv(c1, c2, 1, 1, act=False)) if s == 2 else nn.Identity()

    def forward(self, x):
        return self.conv(x) + self.shortcut(x)

'''===============================================五、模型扩展模块==================================================='''
'''===========1.C3TR(C3)：继承自 C3，n 个 Bottleneck 更换为 1 个 TransformerBlock ================'''
class C3TR(C3):
    """
        这部分是根据上面的C3结构改编而来的, 将原先的Bottleneck替换为调用TransformerBlock模块
        """
    # C3 module with TransformerBlock()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        ''' 在C3RT模块和yolo.py的parse_model函数中被调用
                :params c1: 整个C3的输入channel
                :params c2: 整个C3的输出channel
                :params n: 有n个子模块[Bottleneck/CrossConv]
                :params shortcut: bool值，子模块[Bottlenec/CrossConv]中是否有shortcut，默认True
                :params g: 子模块[Bottlenec/CrossConv]中的3x3卷积类型，=1普通卷积，&gt;1深度可分离卷积
                :params e: expansion ratio，e*c2=中间其它所有层的卷积核个数=中间所有层的的输入输出channel
                '''
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = TransformerBlock(c_, c_, 4, n)

'''===========2.DetectMultiBackend： ================'''
class DetectMultiBackend(nn.Module):
    # YOLOv5 MultiBackend class for python inference on various backends
    def __init__(self, weights='yolov5s.pt', device=None, dnn=True):
        # Usage:
        #   PyTorch:      weights = *.pt
        #   TorchScript:            *.torchscript.pt
        #   CoreML:                 *.mlmodel
        #   TensorFlow:             *_saved_model
        #   TensorFlow:             *.pb
        #   TensorFlow Lite:        *.tflite
        #   ONNX Runtime:           *.onnx
        #   OpenCV DNN:             *.onnx with dnn=True
        super().__init__()
        # 判断weights是否为list，若是取出第一个值作为传入路径
        w = str(weights[0] if isinstance(weights, list) else weights)
        suffix, suffixes = Path(w).suffix.lower(), ['.pt', '.onnx', '.tflite', '.pb', '', '.mlmodel']
        check_suffix(w, suffixes)  # check weights have acceptable suffix
        pt, onnx, tflite, pb, saved_model, coreml = (suffix == x for x in suffixes)  # backend booleans
        jit = pt and 'torchscript' in w.lower()
        stride, names = 64, [f'class{i}' for i in range(1000)]  # assign defaults

        if jit:  # TorchScript
            LOGGER.info(f'Loading {w} for TorchScript inference...')
            extra_files = {'config.txt': ''}  # model metadata
            model = torch.jit.load(w, _extra_files=extra_files)
            if extra_files['config.txt']:
                d = json.loads(extra_files['config.txt'])  # extra_files dict
                stride, names = int(d['stride']), d['names']
        elif pt:  # PyTorch
            from models.experimental import attempt_load  # scoped to avoid circular import
            model = torch.jit.load(w) if 'torchscript' in w else attempt_load(weights, map_location=device)
            stride = int(model.stride.max())  # model stride
            names = model.module.names if hasattr(model, 'module') else model.names  # get class names
        elif coreml:  # CoreML *.mlmodel
            import coremltools as ct
            model = ct.models.MLModel(w)
        elif dnn:  # ONNX OpenCV DNN
            LOGGER.info(f'Loading {w} for ONNX OpenCV DNN inference...')
            check_requirements(('opencv-python&gt;=4.5.4',))
            net = cv2.dnn.readNetFromONNX(w)
        elif onnx:  # ONNX Runtime
            LOGGER.info(f'Loading {w} for ONNX Runtime inference...')
            check_requirements(('onnx', 'onnxruntime-gpu' if torch.has_cuda else 'onnxruntime'))
            import onnxruntime
            session = onnxruntime.InferenceSession(w, None)
        else:  # TensorFlow model (TFLite, pb, saved_model)
            import tensorflow as tf
            if pb:  # https://www.tensorflow.org/guide/migrate#a_graphpb_or_graphpbtxt
                def wrap_frozen_graph(gd, inputs, outputs):
                    x = tf.compat.v1.wrap_function(lambda: tf.compat.v1.import_graph_def(gd, name=""), [])  # wrapped
                    return x.prune(tf.nest.map_structure(x.graph.as_graph_element, inputs),
                                   tf.nest.map_structure(x.graph.as_graph_element, outputs))

                LOGGER.info(f'Loading {w} for TensorFlow *.pb inference...')
                graph_def = tf.Graph().as_graph_def()
                graph_def.ParseFromString(open(w, 'rb').read())
                frozen_func = wrap_frozen_graph(gd=graph_def, inputs="x:0", outputs="Identity:0")
            elif saved_model:
                LOGGER.info(f'Loading {w} for TensorFlow saved_model inference...')
                model = tf.keras.models.load_model(w)
            elif tflite:  # https://www.tensorflow.org/lite/guide/python#install_tensorflow_lite_for_python
                if 'edgetpu' in w.lower():
                    LOGGER.info(f'Loading {w} for TensorFlow Edge TPU inference...')
                    import tflite_runtime.interpreter as tfli
                    delegate = {'Linux': 'libedgetpu.so.1',  # install https://coral.ai/software/#edgetpu-runtime
                                'Darwin': 'libedgetpu.1.dylib',
                                'Windows': 'edgetpu.dll'}[platform.system()]
                    interpreter = tfli.Interpreter(model_path=w, experimental_delegates=[tfli.load_delegate(delegate)])
                else:
                    LOGGER.info(f'Loading {w} for TensorFlow Lite inference...')
                    interpreter = tf.lite.Interpreter(model_path=w)  # load TFLite model
                interpreter.allocate_tensors()  # allocate
                input_details = interpreter.get_input_details()  # inputs
                output_details = interpreter.get_output_details()  # outputs
        self.__dict__.update(locals())  # assign all variables to self

    def forward(self, im, augment=False, visualize=False, val=False):
        # YOLOv5 MultiBackend inference
        b, ch, h, w = im.shape  # batch, channel, height, width
        if self.pt:  # PyTorch
            y = self.model(im) if self.jit else self.model(im, augment=augment, visualize=visualize)
            return y if val else y[0]
        elif self.coreml:  # CoreML *.mlmodel
            im = im.permute(0, 2, 3, 1).cpu().numpy()  # torch BCHW to numpy BHWC shape(1,320,192,3)
            im = Image.fromarray((im[0] * 255).astype('uint8'))
            # im = im.resize((192, 320), Image.ANTIALIAS)
            y = self.model.predict({'image': im})  # coordinates are xywh normalized
            box = xywh2xyxy(y['coordinates'] * [[w, h, w, h]])  # xyxy pixels
            conf, cls = y['confidence'].max(1), y['confidence'].argmax(1).astype(np.float)
            y = np.concatenate((box, conf.reshape(-1, 1), cls.reshape(-1, 1)), 1)
        elif self.onnx:  # ONNX
            im = im.cpu().numpy()  # torch to numpy
            if self.dnn:  # ONNX OpenCV DNN
                self.net.setInput(im)
                y = self.net.forward()
            else:  # ONNX Runtime
                y = self.session.run([self.session.get_outputs()[0].name], {self.session.get_inputs()[0].name: im})[0]
        else:  # TensorFlow model (TFLite, pb, saved_model)
            im = im.permute(0, 2, 3, 1).cpu().numpy()  # torch BCHW to numpy BHWC shape(1,320,192,3)
            if self.pb:
                y = self.frozen_func(x=self.tf.constant(im)).numpy()
            elif self.saved_model:
                y = self.model(im, training=False).numpy()
            elif self.tflite:
                input, output = self.input_details[0], self.output_details[0]
                int8 = input['dtype'] == np.uint8  # is TFLite quantized uint8 model
                if int8:
                    scale, zero_point = input['quantization']
                    im = (im / scale + zero_point).astype(np.uint8)  # de-scale
                self.interpreter.set_tensor(input['index'], im)
                self.interpreter.invoke()
                y = self.interpreter.get_tensor(output['index'])
                if int8:
                    scale, zero_point = output['quantization']
                    y = (y.astype(np.float32) - zero_point) * scale  # re-scale
            y[..., 0] *= w  # x
            y[..., 1] *= h  # y
            y[..., 2] *= w  # w
            y[..., 3] *= h  # h
        y = torch.tensor(y)
        return (y, []) if val else y

'''===========3.AutoShape：自动调整shape,该类基本未用================'''
class AutoShape(nn.Module):
    # YOLOv5 input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS
    conf = 0.25  # NMS confidence threshold
    iou = 0.45  # NMS IoU threshold
    classes = None  # (optional list) filter by class, i.e. = [0, 15, 16] for COCO persons, cats and dogs
    multi_label = False  # NMS multiple labels per box
    max_det = 1000  # maximum number of detections per image

    def __init__(self, model):
        super().__init__()
        self.model = model.eval()

    def autoshape(self):
        LOGGER.info('AutoShape already enabled, skipping... ')  # model already converted to model.autoshape()
        return self

    def _apply(self, fn):
        # Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers
        self = super()._apply(fn)
        m = self.model.model[-1]  # Detect()
        m.stride = fn(m.stride)
        m.grid = list(map(fn, m.grid))
        if isinstance(m.anchor_grid, list):
            m.anchor_grid = list(map(fn, m.anchor_grid))
        return self

    @torch.no_grad()
    def forward(self, imgs, size=640, augment=False, profile=False):
        # Inference from various sources. For height=640, width=1280, RGB images example inputs are:
        #   file:       imgs = 'data/images/zidane.jpg'  # str or PosixPath
        #   URI:             = 'https://ultralytics.com/images/zidane.jpg'
        #   OpenCV:          = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)
        #   PIL:             = Image.open('image.jpg') or ImageGrab.grab()  # HWC x(640,1280,3)
        #   numpy:           = np.zeros((640,1280,3))  # HWC
        #   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)
        #   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images

        t = [time_sync()]
        p = next(self.model.parameters())  # for device and type
        if isinstance(imgs, torch.Tensor):  # torch
            with amp.autocast(enabled=p.device.type != 'cpu'):
                return self.model(imgs.to(p.device).type_as(p), augment, profile)  # inference

        # Pre-process
        n, imgs = (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])  # number of images, list of images
        shape0, shape1, files = [], [], []  # image and inference shapes, filenames
        for i, im in enumerate(imgs):
            f = f'image{i}'  # filename
            if isinstance(im, (str, Path)):  # filename or uri
                im, f = Image.open(requests.get(im, stream=True).raw if str(im).startswith('http') else im), im
                im = np.asarray(exif_transpose(im))
            elif isinstance(im, Image.Image):  # PIL Image
                im, f = np.asarray(exif_transpose(im)), getattr(im, 'filename', f) or f
            files.append(Path(f).with_suffix('.jpg').name)
            if im.shape[0] &lt; 5:  # image in CHW
                im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)
            im = im[..., :3] if im.ndim == 3 else np.tile(im[..., None], 3)  # enforce 3ch input
            s = im.shape[:2]  # HWC
            shape0.append(s)  # image shape
            g = (size / max(s))  # gain
            shape1.append([y * g for y in s])
            imgs[i] = im if im.data.contiguous else np.ascontiguousarray(im)  # update
        shape1 = [make_divisible(x, int(self.stride.max())) for x in np.stack(shape1, 0).max(0)]  # inference shape
        x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad
        x = np.stack(x, 0) if n &gt; 1 else x[0][None]  # stack
        x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW
        x = torch.from_numpy(x).to(p.device).type_as(p) / 255  # uint8 to fp16/32
        t.append(time_sync())

        with amp.autocast(enabled=p.device.type != 'cpu'):
            # Inference
            y = self.model(x, augment, profile)[0]  # forward
            t.append(time_sync())

            # Post-process
            y = non_max_suppression(y, self.conf, iou_thres=self.iou, classes=self.classes,
                                    multi_label=self.multi_label, max_det=self.max_det)  # NMS
            for i in range(n):
                scale_coords(shape1, y[i][:, :4], shape0[i])

            t.append(time_sync())
            return Detections(imgs, y, files, t, self.names, x.shape)

'''===========3.Detections：对推理结果进行处理================'''
class Detections:
    # YOLOv5 detections class for inference results
    """用在AutoShape函数结尾
    detections class for YOLOv5 inference results
    """
    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):
        super().__init__()
        d = pred[0].device  # device
        gn = [torch.tensor([*(im.shape[i] for i in [1, 0, 1, 0]), 1, 1], device=d) for im in imgs]  # normalizations
        # imgs：原图
        self.imgs = imgs  # list of images as numpy arrays
        # pred：预测值(xyxy, conf, cls)
        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)
        # names： 类名
        self.names = names  # class names
        # files： 图像文件名
        self.files = files  # image filenames
        # xyxy：左上角+右下角格式
        self.xyxy = pred  # xyxy pixels
        # xywh：中心点+宽长格式
        self.xywh = [xyxy2xywh(x) for x in pred]  # xywh pixels
        # xyxyn：xyxy标准化
        self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # xyxy normalized
        # xywhn：xywhn标准化
        self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # xywh normalized
        self.n = len(self.pred)  # number of images (batch size)
        self.t = tuple((times[i + 1] - times[i]) * 1000 / self.n for i in range(3))  # timestamps (ms)
        self.s = shape  # inference BCHW shape

    def display(self, pprint=False, show=False, save=False, crop=False, render=False, save_dir=Path('')):
        crops = []
        for i, (im, pred) in enumerate(zip(self.imgs, self.pred)):
            s = f'image {i + 1}/{len(self.pred)}: {im.shape[0]}x{im.shape[1]} '  # string
            if pred.shape[0]:
                for c in pred[:, -1].unique():
                    n = (pred[:, -1] == c).sum()  # detections per class
                    s += f"{n} {self.names[int(c)]}{'s' * (n &gt; 1)}, "  # add to string
                if show or save or render or crop:
                    annotator = Annotator(im, example=str(self.names))
                    for *box, conf, cls in reversed(pred):  # xyxy, confidence, class
                        label = f'{self.names[int(cls)]} {conf:.2f}'
                        if crop:
                            file = save_dir / 'crops' / self.names[int(cls)] / self.files[i] if save else None
                            crops.append({'box': box, 'conf': conf, 'cls': cls, 'label': label,
                                          'im': save_one_box(box, im, file=file, save=save)})
                        else:  # all others
                            annotator.box_label(box, label, color=colors(cls))
                    im = annotator.im
            else:
                s += '(no detections)'

            im = Image.fromarray(im.astype(np.uint8)) if isinstance(im, np.ndarray) else im  # from np
            if pprint:
                LOGGER.info(s.rstrip(', '))
            if show:
                im.show(self.files[i])  # show
            if save:
                f = self.files[i]
                im.save(save_dir / f)  # save
                if i == self.n - 1:
                    LOGGER.info(f"Saved {self.n} image{'s' * (self.n &gt; 1)} to {colorstr('bold', save_dir)}")
            if render:
                self.imgs[i] = np.asarray(im)
        if crop:
            if save:
                LOGGER.info(f'Saved results to {save_dir}\n')
            return crops

    def print(self):
        self.display(pprint=True)  # print results
        LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {tuple(self.s)}' %
                    self.t)

    def show(self):
        self.display(show=True)  # show results

    def save(self, save_dir='runs/detect/exp'):
        save_dir = increment_path(save_dir, exist_ok=save_dir != 'runs/detect/exp', mkdir=True)  # increment save_dir
        self.display(save=True, save_dir=save_dir)  # save results

    def crop(self, save=True, save_dir='runs/detect/exp'):
        save_dir = increment_path(save_dir, exist_ok=save_dir != 'runs/detect/exp', mkdir=True) if save else None
        return self.display(crop=True, save=save, save_dir=save_dir)  # crop results

    def render(self):
        self.display(render=True)  # render results
        return self.imgs

    def pandas(self):
        # return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])
        new = copy(self)  # return copy
        ca = 'xmin', 'ymin', 'xmax', 'ymax', 'confidence', 'class', 'name'  # xyxy columns
        cb = 'xcenter', 'ycenter', 'width', 'height', 'confidence', 'class', 'name'  # xywh columns
        for k, c in zip(['xyxy', 'xyxyn', 'xywh', 'xywhn'], [ca, ca, cb, cb]):
            a = [[x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()] for x in getattr(self, k)]  # update
            setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
        return new

    def tolist(self):
        # return a list of Detections objects, i.e. 'for result in results.tolist():'
        x = [Detections([self.imgs[i]], [self.pred[i]], self.names, self.s) for i in range(self.n)]
        for d in x:
            for k in ['imgs', 'pred', 'xyxy', 'xyxyn', 'xywh', 'xywhn']:
                setattr(d, k, getattr(d, k)[0])  # pop out of list
        return x

    def __len__(self):
        return self.n

'''===========5.Classify：二级分类模块================'''
class Classify(nn.Module):
    # Classification head, i.e. x(b,c1,20,20) to x(b,c2)
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1):  # ch_in, ch_out, kernel, stride, padding, groups
        """
                这是一个二级分类模块, 什么是二级分类模块? 比如做车牌的识别, 先识别出车牌, 如果想对车牌上的字进行识别, 就需要二级分类进一步检测.
                如果对模型输出的分类再进行分类, 就可以用这个模块. 不过这里这个类写的比较简单, 若进行复杂的二级分类, 可以根据自己的实际任务可以改写, 这里代码不唯一.
                Classification head, i.e. x(b,c1,20,20) to x(b,c2)
                用于第二级分类   可以根据自己的任务自己改写，比较简单
                比如车牌识别 检测到车牌之后还需要检测车牌在哪里，如果检测到侧拍后还想对车牌上的字再做识别的话就要进行二级分类
                """
        super().__init__()
        self.aap = nn.AdaptiveAvgPool2d(1)  # to x(b,c1,1,1)
        # 自适应平均池化操作
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g)  # to x(b,c2,1,1)
        # 展平
        self.flat = nn.Flatten()

    def forward(self, x):
        # 先自适应平均池化操作， 然后拼接
        z = torch.cat([self.aap(y) for y in (x if isinstance(x, list) else [x])], 1)  # cat if list
        # 对z进行展平操作
        return self.flat(self.conv(z))  # flatten to x(b,c2)
</code ></pre> 
         <hr> 
         <blockquote> 
          <p><strong>本文参考：</strong></p> 
          <p><a href="https://blog.csdn.net/qq_38253797/article/details/119684388?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=yolov5%20common.py%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-119684388.142%5Ev76%5Epc_search_v2,201%5Ev4%5Eadd_ask,239%5Ev2%5Einsert_chatgpt&amp;spm=1018.2226.3001.4187" title="【YOLOV5-5.x 源码解读】common.py_满船清梦压星河HK的博客-CSDN博客">【YOLOV5-5.x 源码解读】common.py_满船清梦压星河HK的博客-CSDN博客</a></p> 
          <p><a href="https://blog.csdn.net/XiaoGShou/article/details/117351971?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162919967016780269827948%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=162919967016780269827948&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-3-117351971.first_rank_v2_pc_rank_v29&amp;utm_term=common.py&amp;spm=1018.2226.3001.4187" title="yolov5 代码解读 --common.py_XiaoGShou的博客-CSDN博客">yolov5 代码解读 --common.py_XiaoGShou的博客-CSDN博客</a></p> 
         </blockquote> 
         <p style="text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/9171f300d63af5b21958cdbbb2e48333.gif">&nbsp;&nbsp;</p> 
        </div> 
       </div> 
      </article>  
     </div> 
     <div class="directory-boxshadow-dialog" style="display:none;"> 
      <div class="directory-boxshadow-dialog-box"> 
      </div> 
      <div class="vip-limited-time-offer-box-new" id="vip-limited-time-offer-box-new"> 
       <img class="limited-img limited-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close-newWhite.png"> 
       <div class="vip-limited-time-top">
         确定要放弃本次机会？ 
       </div> 
       <span class="vip-limited-time-text">福利倒计时</span> 
       <div class="limited-time-box-new"> 
        <span class="time-hour"></span> 
        <i>:</i> 
        <span class="time-minite"></span> 
        <i>:</i> 
        <span class="time-second"></span> 
       </div> 
       <div class="limited-time-vip-box"> 
        <p> <img class="coupon-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close-roup.png"> <span class="def">立减 ¥</span> <span class="active limited-num"></span> </p> 
        <span class="">普通VIP年卡可用</span> 
       </div> 
       <a class="limited-time-btn-new" href="https://mall.csdn.net/vip" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.9621&quot;}" data-report-query="spm=1001.2101.3001.9621">立即使用</a> 
      </div> 
     </div> 
     <div class="more-toolbox-new more-toolbar" id="toolBarBox"> 
      <div class="left-toolbox"> 
       <div class="toolbox-left"> 
        <div class="profile-box"> 
         <a class="profile-href" target="_blank" href="https://jrs0511.blog.csdn.net"><img class="profile-img" src="https://profile-avatar.csdnimg.cn/da983c398fca4f14a19ea48d137f6ca3_weixin_43334693.jpg!1"> <span class="profile-name"> 路人贾'ω' </span> </a> 
        </div> 
        <div class="profile-attend"> 
         <a class="tool-attend tool-bt-button tool-unbt-attend" href="javascript:;" data-report-view="{&quot;mod&quot;:&quot;1592215036_002&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4232&quot;,&quot;extend1&quot;:&quot;已关注&quot;}">已关注</a> 
         <a class="tool-item-follow active-animation" style="display:none;">关注</a> 
        </div> 
       </div> 
       <div class="toolbox-middle"> 
        <ul class="toolbox-list"> 
         <li class="tool-item tool-item-size tool-active is-like" id="is-like"> <a class="tool-item-href"> <img style="display:none;" id="is-like-imgactive-animation-like" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarThumbUpactive.png" alt=""> <img class="isactive" style="display:none" id="is-like-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/like-active.png" alt=""> <img class="isdefault" style="display:block" id="is-like-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/like.png" alt=""> <span id="spanCount" class="count "> 39 </span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">点赞</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active is-unlike" id="is-unlike"> <a class="tool-item-href"> <img class="isactive" style="margin-right:0px;display:none" id="is-unlike-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/unlike-active.png" alt=""> <img class="isdefault" style="margin-right:0px;display:block" id="is-unlike-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/unlike.png" alt=""> <span id="unlikeCount" class="count "></span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">踩</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active is-collection "> <a class="tool-item-href" href="javascript:;" data-report-click="{&quot;mod&quot;:&quot;popu_824&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4130&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img style="display:none" id="is-collection-img-collection" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/collect-active.png" alt=""> <img class="isdefault" id="is-collection-img" style="display:block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/collect.png" alt=""> <img class="isactive" id="is-collection-imgactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCollectActive.png" alt=""> <span class="count get-collection " data-num="72" id="get-collection"> 72 </span> </a> 
          <div class="tool-hover-tip collect"> 
           <div class="collect-operate-box"> 
            <span class="collect-text" id="is-collection"> 收藏 </span> 
           </div> 
          </div> 
          <div class="tool-active-list"> 
           <div class="text">
             觉得还不错? 
            <span class="collect-text" id="tool-active-list-collection"> 一键收藏 </span> 
            <img id="tool-active-list-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/collectionCloseWhite.png" alt=""> 
           </div> 
          </div> </li> 
         <li class="tool-item tool-item-size tool-active tool-item-comment"> 
          <div class="guide-rr-first"> 
           <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward01.png" alt=""> 
           <button class="btn-guide-known">知道了</button> 
          </div> <a class="tool-item-href go-side-comment" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7009&quot;}"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/comment.png" alt=""> <span class="count"> 20 </span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">评论</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active tool-QRcode" data-type="article" id="tool-share"> <a class="tool-item-href" href="javascript:;" data-report-view="{&quot;spm&quot;:&quot;3001.4129&quot;,&quot;extra&quot;:{&quot;type&quot;:&quot;blogdetail&quot;}}"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/share.png" alt=""> <span class="count">分享</span> </a> 
          <div class="QRcode" id="tool-QRcode"> 
           <div class="share-bg-box"> 
            <div class="share-content"> 
             <a id="copyPosterUrl" data-type="link" class="btn-share">复制链接</a> 
            </div> 
            <div class="share-content"> 
             <a class="btn-share" data-type="qq">分享到 QQ</a> 
            </div> 
            <div class="share-content"> 
             <a class="btn-share" data-type="weibo">分享到新浪微博</a> 
            </div> 
            <div class="share-code"> 
             <div class="share-code-box" id="shareCode"></div> 
             <div class="share-code-text"> 
              <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/share/icon-wechat.png" alt="">扫一扫 
             </div> 
            </div> 
           </div> 
          </div> </li> 
         <li class="tool-item tool-item-size tool-active tool-item-reward"> <a class="tool-item-href" href="javascript:;" data-report-click="{&quot;mod&quot;:&quot;popu_830&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4237&quot;,&quot;dest&quot;:&quot;&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img class="isdefault reward-bt" id="rewardBtNew" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/reward.png" alt="打赏"> <span class="count">打赏</span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">打赏</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active is-more" id="is-more"> <a class="tool-item-href"> <img class="isdefault" style="margin-right:0px;display:block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/more.png" alt=""> <span class="count"></span> </a> 
          <div class="more-opt-box"> 
           <div class="mini-box"> 
            <a class="tool-item-href" id="rewardBtNewHide" data-report-click="{&quot;spm&quot;:&quot;3001.4237&quot;,&quot;extra&quot;:&quot;{\&quot;type\&quot;:\&quot;hide\&quot;}&quot;}"> <img class="isdefault reward-bt" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/reward.png" alt="打赏"> <span class="count">打赏</span> </a> 
            <a class="tool-item-href" id="toolReportBtnHide"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/report.png" alt=""> <span class="count">举报</span> </a> 
           </div> 
           <div class="normal-box"> 
            <a class="tool-item-href" id="toolReportBtnHideNormal"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/report.png" alt=""> <span class="count">举报</span> </a> 
           </div> 
          </div> </li> 
        </ul> 
       </div> 
       <div class="toolbox-right"> 
        <div class="tool-directory"> 
         <a class="bt-columnlist-show" data-id="12233704" data-free="false" data-description="全网最详细的手把手带你从0开始学习YOLOv5教程。文章平均质量分97！专栏内含网络结构解读+源代码逐行解析+入门实践+各种最新改进算法等等。持续更新，欢迎订阅！" data-subscribe="true" data-title="YOLOv5入门＋实践＋改进" data-img="https://i-blog.csdnimg.cn/blog_column_migrate/2d39764ecc8e8d41d72673a523e05b4b.png?x-oss-process=image/resize,m_fixed,h_224,w_224" data-url="https://blog.csdn.net/weixin_43334693/category_12233704.html" data-sum="47" data-people="1123" data-price="99.90" data-hotrank="76" data-status="true" data-oldprice="299.90" data-join="true" data-studyvip="true" data-studysubscribe="true" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.6334&quot;,&quot;extend1&quot;:&quot;专栏目录&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.6334&quot;,&quot;extend1&quot;:&quot;专栏目录&quot;}">专栏目录</a> 
        </div> 
        <div class="tool-column"> 
         <a class="tool-bt-button tool-unbt-subscribe" href="javascript:;" data-report-view="{&quot;mod&quot;:&quot;1592215036_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4405&quot;,&quot;extend1&quot;:&quot;已订阅&quot;}" data-report-click="{&quot;mod&quot;:&quot;1592215036_001&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4405&quot;,&quot;extend1&quot;:&quot;已订阅&quot;}">已订阅</a> 
        </div> 
       </div> 
      </div> 
     </div>   
     <a id="commentBox" name="commentBox"></a> 
     <div id="pcCommentBox" class="comment-box comment-box-new2 login-comment-box-new" style="display:none"> 
      <div class="has-comment" style="display:block"> 
       <div class="one-line-box"> 
        <div class="has-comment-tit go-side-comment"> 
         <span class="count">20</span>&nbsp;条评论 
        </div> 
        <div class="has-comment-con comment-operate-item"></div> 
        <a class="has-comment-bt-right go-side-comment focus">写评论</a> 
       </div> 
      </div> 
     </div> 
     <div class="first-recommend-box recommend-box recommend-highlight-default"> 
      <div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/ali1174/article/details/129766023" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6661.1&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-129766023-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/ali1174/article/details/129766023&quot;}"> 
       <div class="content-box"> 
        <div class="content-blog display-flex"> 
         <div class="title-box"> 
          <span class="type"> <img src="https://csdnimg.cn/release/blogv2/dist/components/img/blogType.png" alt=""> <span class="tip">博客</span> </span> 
          <a href="https://blog.csdn.net/ali1174/article/details/129766023" class="tit" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6661.1&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-129766023-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/ali1174/article/details/129766023&quot;}" data-report-query="spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-129766023-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-129766023-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
           <div class="left ellipsis-online ellipsis-online-1">
            （四）
            <em>yolov5</em>--
            <em>common</em>.
            <em>py</em>文件
            <em>解读</em>
           </div> </a> 
         </div> 
         <div class="info-box display-flex"> 
          <div class="info"> 
           <a href="https://blog.csdn.net/ali1174" target="_blank"><span class="blog-title">ali1174的专栏</span></a> 
          </div> 
          <div class="info display-flex"> 
           <span class="info-block time">03-25</span> 
           <span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> 3001 </span> 
          </div> 
         </div> 
        </div> 
        <div class="desc-box"> 
         <a href="https://blog.csdn.net/ali1174/article/details/129766023" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6661.1&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-129766023-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/ali1174/article/details/129766023&quot;}" data-report-query="spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-129766023-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-129766023-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
          <div class="desc ellipsis-online ellipsis-online-1">
           参考网址：https://blog.csdn.net/qq_38251616/article/details/124665998上次对
           <em>yolov5</em>s.yaml文件进行了
           <em>解读</em>，这次在对
           <em>common</em>.
           <em>py</em>文件
           <em>解读</em>之前，先放上
           <em>yolov5</em>s.yaml对应的
           <em>网络结构</em>图，如下图所示。对于
           <em>网络结构</em>图中的各个模块，其定义则在
           <em>common</em>.
           <em>py</em>文件中。
          </div> </a> 
        </div> 
       </div> 
      </div> 
     </div>  
     <div class="second-recommend-box recommend-box recommend-highlight-default"> 
      <div class="recommend-item-box type_blog clearfix" data-url="https://wendao.blog.csdn.net/article/details/107590851" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.1&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-107590851-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://wendao.blog.csdn.net/article/details/107590851&quot;}"> 
       <div class="content-box"> 
        <div class="content-blog display-flex"> 
         <div class="title-box"> 
          <span class="type"> <img src="https://csdnimg.cn/release/blogv2/dist/components/img/blogType.png" alt=""> <span class="tip">博客</span> </span> 
          <a href="https://wendao.blog.csdn.net/article/details/107590851" class="tit" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.1&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-107590851-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://wendao.blog.csdn.net/article/details/107590851&quot;}" data-report-query="spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-107590851-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-107590851-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
           <div class="left ellipsis-online ellipsis-online-1">
            <em>YOLOv5</em>代码详解（
            <em>common</em>.
            <em>py</em>部分）
           </div> </a> 
         </div> 
         <div class="info-box display-flex"> 
          <div class="info"> 
           <a href="https://blog.csdn.net/qq_36387683" target="_blank"><span class="blog-title">云中寻雾的博客</span></a> 
          </div> 
          <div class="info display-flex"> 
           <span class="info-block time">07-26</span> 
           <span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> 8841 </span> 
          </div> 
         </div> 
        </div> 
        <div class="desc-box"> 
         <a href="https://wendao.blog.csdn.net/article/details/107590851" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.1&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-107590851-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://wendao.blog.csdn.net/article/details/107590851&quot;}" data-report-query="spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-107590851-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-107590851-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
          <div class="desc ellipsis-online ellipsis-online-1">
           目录 4. 
           <em>common</em>.
           <em>py</em> 4.1 卷积层 4.1.1 深度分离卷积层 4.1.1 标准卷积层 4.2 标准Bottleneck 4.3 BottleneckCSP 4.4 SPP 4.5 Flatten 4.6 Focus​ 4.7 Concat 4. 
           <em>common</em>.
           <em>py</em> 该部分是backbone各个模块参数讲解。 4.1 卷积层 4.1.1 深度分离卷积层 深度分离(DepthWise)卷积层，是GCONV的极端情况，分组数量等于输入通道数量，即每个通道作为一.
          </div> </a> 
        </div> 
       </div> 
      </div> 
     </div> 
     <div class="recommend-box insert-baidu-box  recommend-highlight-default"> 
      <div class="recommend-item-box no-index" style="display:none"></div> 
      <div class="recommend-item-box type_blog clearfix" data-url="https://mtyjkh.blog.csdn.net/article/details/131677896" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.2&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-131677896-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://mtyjkh.blog.csdn.net/article/details/131677896&quot;}"> 
       <div class="content-box"> 
        <div class="content-blog display-flex"> 
         <div class="title-box"> 
          <span class="type"> <img src="https://csdnimg.cn/release/blogv2/dist/components/img/blogType.png" alt=""> <span class="tip">博客</span> </span> 
          <a href="https://mtyjkh.blog.csdn.net/article/details/131677896" class="tit" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.2&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-131677896-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://mtyjkh.blog.csdn.net/article/details/131677896&quot;}" data-report-query="spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-131677896-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-131677896-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
           <div class="left ellipsis-online ellipsis-online-1">
            <em>YOLOv5</em>解析 | 第四篇：
            <em>common</em>.
            <em>py</em>文件详解
           </div> 
           <div class="tag">
            最新发布
           </div> </a> 
         </div> 
         <div class="info-box display-flex"> 
          <div class="info"> 
           <a href="https://blog.csdn.net/qq_38251616" target="_blank"><span class="blog-title">“365天深度学习训练营”报名进行中～</span></a> 
          </div> 
          <div class="info display-flex"> 
           <span class="info-block time">07-12</span> 
           <span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> 533 </span> 
          </div> 
         </div> 
        </div> 
        <div class="desc-box"> 
         <a href="https://mtyjkh.blog.csdn.net/article/details/131677896" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.2&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-131677896-blog-129854764.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743597247530_65521\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743597247530_65521&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://mtyjkh.blog.csdn.net/article/details/131677896&quot;}" data-report-query="spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-131677896-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-131677896-blog-129854764.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
          <div class="desc ellipsis-online ellipsis-online-1">
           该文件是实现
           <em>YOLO</em>算法中各个模块的地方，如果我们需要修改某一模块（例如C3），那么就需要修改这个文件中对应模块的的定义。这里我先围绕代码，带大家过一遍各个模块的定义，
           <em>详细</em>介绍我将在后续的教案中逐步展开。由于
           <em>YOLOv5</em>版本问题，同一个模块你可能会看到不同的版本，这都是正常的，以官网为主即可。
          </div> </a> 
        </div> 
       </div> 
      </div> 
     </div> 
     <div class="blog-footer-bottom" style="margin-top:10px;"></div>   
    </main> 
    <aside class="blog_container_aside"> 
     <div id="asideProfile" class="aside-box active"> 
      <div class="profile-intro d-flex"> 
       <div class="avatar-box d-flex justify-content-center flex-column"> 
        <a href="https://jrs0511.blog.csdn.net" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;spm&quot;:&quot;3001.4121&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img src="https://profile-avatar.csdnimg.cn/da983c398fca4f14a19ea48d137f6ca3_weixin_43334693.jpg!1" class="avatar_pic"> </a>
        <a href="https://jrs0511.blog.csdn.net" data-report-click="{&quot;spm&quot;:&quot;3001.9180&quot;}" target="_blank"><img class="identity" src="https://csdnimg.cn/release/blogv2/dist/mobile/img/vipIcon.png" alt=""></a>  
       </div> 
       <div class="user-info d-flex flex-column profile-intro-name-box"> 
        <div class="profile-intro-name-boxTop"> 
         <a href="https://jrs0511.blog.csdn.net" target="_blank" class="" id="uid" title="路人贾'ω'" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;spm&quot;:&quot;3001.4122&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net&quot;,&quot;ab&quot;:&quot;new&quot;}"> <span class="name" username="weixin_43334693">路人贾'ω'</span> </a> 
        </div> 
        <div class="profile-intro-name-boxFooter-new"> 
         <p class="profile-intro-name-leve"> <span> 博客等级 </span> <img class="level" src="https://csdnimg.cn/identity/blog7.png"> </p> 
         <span class="profile-intro-name-years" title="已加入 CSDN 7年">码龄7年</span> 
        </div> 
       </div> 
      </div> 
      <div class="profile-intro-Identity-information"> 
       <p class="profile-information-box"> <img class="information-img" data-report-click="{&quot;spm&quot;:&quot;3001.4296&quot;}" src="https://img-home.csdnimg.cn/images/20210412060958.png" alt=""> <span>人工智能领域优质创作者</span> </p> 
      </div> 
      <div class="profile-intro-rank-information"> 
       <dl> 
        <a href="https://jrs0511.blog.csdn.net" data-report-click="{&quot;mod&quot;:&quot;1598321000_001&quot;,&quot;spm&quot;:&quot;3001.4310&quot;}" data-report-query="t=1"> 
         <dd>
          <span>120</span>
         </dd> 
         <dt>
          原创
         </dt> </a> 
       </dl> 
       <dl title="9103"> 
        <dd>
         9103
        </dd> 
        <dt>
         点赞
        </dt> 
       </dl> 
       <dl title="36278"> 
        <dd>
         3万+
        </dd> 
        <dt>
         收藏
        </dt> 
       </dl> 
       <dl id="fanBox" title="158544"> 
        <dd>
         <span id="fan">15万+</span>
        </dd> 
        <dt>
         粉丝
        </dt> 
       </dl> 
      </div> 
      <div class="profile-intro-name-boxOpration"> 
       <div class="opt-letter-watch-box"> 
        <a class="attented personal-watch bt-button" id="btnAttent">已关注</a> 
       </div> 
       <div class="opt-letter-watch-box"> 
        <a rel="noopener" class="bt-button personal-letter" href="https://im.csdn.net/chat/weixin_43334693" target="_blank">私信</a> 
       </div> 
      </div> 
     </div> 
     <div class="swiper-slide-box-remuneration"> 
      <a data-report-click="{&quot;spm&quot;:&quot;3001.9728&quot;,&quot;extra&quot;:{&quot;index&quot;:&quot;0&quot;}}" data-report-view="{&quot;spm&quot;:&quot;3001.9728&quot;,&quot;extra&quot;:{&quot;index&quot;:&quot;0&quot;}}" href="https://ai.csdn.net/" target="_blank"> <img src="https://i-operation.csdnimg.cn/images/2dd892a9769b4cce9c086db94eab887f.png" alt=""> </a> 
     </div> 
     <div id="asideHotArticle" class="aside-box"> 
      <h3 class="aside-title">热门文章</h3> 
      <div class="aside-content"> 
       <ul class="hotArticle-list"> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/129312409" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129312409&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【YOLO系列】YOLOv5超详细解读（源码详解＋入门实践＋改进） <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">191050</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/130189238" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/130189238&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【Transformer系列（2）】注意力机制、自注意力机制、多头注意力机制、通道注意力机制、空间注意力机制超详细讲解 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">132906</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/129356033" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129356033&quot;,&quot;ab&quot;:&quot;new&quot;}"> YOLOv5源码逐行超详细注释与解读（1）——项目目录结构解析 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">84049</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/136383022" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/136383022&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【YOLO系列】YOLOv9论文超详细解读（翻译 ＋学习笔记） <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">53110</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/129011644" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129011644&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【YOLO系列】YOLOv1论文超详细解读（翻译 ＋学习笔记） <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">47685</span> </a> </li> 
       </ul> 
      </div> 
     </div> 
     <div id="asideCategory" class="aside-box flexible-box"> 
      <h3 class="aside-title">分类专栏</h3> 
      <div class="aside-content"> 
       <ul> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12233704.html" data-report-click="{&quot;mod&quot;:&quot;popu_826&quot;,&quot;spm&quot;:&quot;3001.4230&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12233704.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/2d39764ecc8e8d41d72673a523e05b4b.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> YOLOv5入门＋实践＋改进 </span> <span class="pay-tag">付费</span> </a> <span class="special-column-num">47篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12534739.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12534739.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/9c2589275bee6d84a2f42be4f7fdd306.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 低照度图像增强 </span> </a> <span class="special-column-num">14篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12202773.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12202773.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/31534c7b408a58aa373bf5f58c00bf44.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 目标检测论文 </span> </a> <span class="special-column-num">18篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12127342.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12127342.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/4cc3e83223e8d0023a6303cdd4658cce.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 图像分类经典论文 </span> </a> <span class="special-column-num">9篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12462707.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12462707.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/columns/default/20201014180756930.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 论文必备 </span> </a> <span class="special-column-num">4篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12288776.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12288776.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/892c3e48b8251069b7506e1e68c5355a.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> transformer </span> </a> <span class="special-column-num">9篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12186888.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12186888.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/8cc13d2259e721c3b070257331ba2fcf.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> Pytorch </span> </a> <span class="special-column-num">9篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12151162.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12151162.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar special-column-bar-second"></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/b9346faac8287efffed28c8b2d898da7.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 论文代码复现 </span> </a> <span class="special-column-num">6篇</span> </li> 
       </ul> 
      </div> 
      <p class="text-center"> <a class="flexible-btn" data-fbox="aside-archive"><img class="look-more" src="https://csdnimg.cn/release/blogv2/dist/pc/img/arrowDownWhite.png" alt=""></a> </p> 
     </div> 
     <div id="asideNewComments" class="aside-box"> 
      <h3 class="aside-title">最新评论</h3> 
      <div class="aside-content"> 
       <ul class="newcomment-list"> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/129349094#comments_36790608" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129349094#comments_36790608&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129349094#comments_36790608&quot;,&quot;ab&quot;:&quot;new&quot;}">YOLOv5源码逐行超详细注释与解读（2）——推理部分detect.py</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/qq_58411487" class="user-name" target="_blank">qq_58411487: </a> <span class="code-comments">下个插件就行了</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/130208816#comments_36778242" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/130208816#comments_36778242&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/130208816#comments_36778242&quot;,&quot;ab&quot;:&quot;new&quot;}">【Transformer系列（3）】 《Attention Is All You Need》论文超详细解读（翻译＋精读）</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/m0_64252296" class="user-name" target="_blank">荷西、: </a> <span class="code-comments">这篇论文从哪找</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/133516890#comments_36767793" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36767793&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36767793&quot;,&quot;ab&quot;:&quot;new&quot;}">[论文必备]最强科研绘图分析工具Origin（1）——安装教程</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/X224513" class="user-name" target="_blank">X224513: </a> <span class="code-comments">求安装包链接，谢谢！</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/133516890#comments_36722559" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36722559&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36722559&quot;,&quot;ab&quot;:&quot;new&quot;}">[论文必备]最强科研绘图分析工具Origin（1）——安装教程</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/ant_c2" class="user-name" target="_blank">ant_c2: </a> <span class="code-comments">求安装包链接，谢谢！</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/133516890#comments_36710842" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36710842&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36710842&quot;,&quot;ab&quot;:&quot;new&quot;}">[论文必备]最强科研绘图分析工具Origin（1）——安装教程</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/sdtzlxx" class="user-name" target="_blank">sdtzlxx: </a> <span class="code-comments">求安装包链接！！！！！谢谢大佬！</span> </p> </li> 
       </ul> 
      </div> 
     </div> 
     <div id="asideHotArticle" class="aside-box"> 
      <h3 class="aside-title">大家在看</h3> 
      <div class="aside-content"> 
       <ul class="hotArticle-list"> 
        <li> <a href="https://blog.csdn.net/qq_40230003/article/details/146798445" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_40230003/article/details/146798445&quot;,&quot;strategy&quot;:&quot;202_1052723-2643749_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_40230003/article/details/146798445&quot;,&quot;strategy&quot;:&quot;202_1052723-2643749_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【Nova UI】一、探秘 Vue 组件库搭建：从技术选型到持续迭代 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">858</span> </a> </li> 
        <li> <a href="https://blog.csdn.net/m0_72763148/article/details/146963537" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/m0_72763148/article/details/146963537&quot;,&quot;strategy&quot;:&quot;202_1052723-2643743_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/m0_72763148/article/details/146963537&quot;,&quot;strategy&quot;:&quot;202_1052723-2643743_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> jQuery - AJAX get() 和 post() 方法 </a> </li> 
        <li> <a href="https://blog.csdn.net/2301_80067496/article/details/146962599" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/2301_80067496/article/details/146962599&quot;,&quot;strategy&quot;:&quot;202_1052723-2643649_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/2301_80067496/article/details/146962599&quot;,&quot;strategy&quot;:&quot;202_1052723-2643649_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 内存映射与共享内存完全指南：从入门到实战 </a> </li> 
        <li> <a href="https://blog.csdn.net/2301_79893878/article/details/146962696" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/2301_79893878/article/details/146962696&quot;,&quot;strategy&quot;:&quot;202_1052723-2643672_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/2301_79893878/article/details/146962696&quot;,&quot;strategy&quot;:&quot;202_1052723-2643672_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 玛卡巴卡的k8s知识点问答题（七） </a> </li> 
        <li> <a href="https://blog.csdn.net/tony2yy/article/details/146866459" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/tony2yy/article/details/146866459&quot;,&quot;strategy&quot;:&quot;202_1052723-2643640_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/tony2yy/article/details/146866459&quot;,&quot;strategy&quot;:&quot;202_1052723-2643640_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 写 Python 到底能不能乱缩进？带你一次搞懂 Python 缩进规范 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">791</span> </a> </li> 
       </ul> 
      </div> 
     </div> 
     <div id="asideArchive" class="aside-box" style="display:block!important; width:300px;"> 
      <h3 class="aside-title">最新文章</h3> 
      <div class="aside-content"> 
       <ul class="inf_list clearfix"> 
        <li class="clearfix"> <a href="https://jrs0511.blog.csdn.net/article/details/140203276" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;3001.4136&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140203276&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140203276&quot;,&quot;ab&quot;:&quot;new&quot;}">【低照度图像增强系列（8）】URetinex-Net算法详解与代码实现（2022|CVPR）</a> </li> 
        <li class="clearfix"> <a href="https://jrs0511.blog.csdn.net/article/details/140229971" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;3001.4136&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140229971&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140229971&quot;,&quot;ab&quot;:&quot;new&quot;}">CVPR|《URetinex-Net: Retinex-based Deep Unfolding Network for Low-light Image Enhance》论文超详细解读（翻译＋精读）</a> </li> 
        <li class="clearfix"> <a href="https://jrs0511.blog.csdn.net/article/details/139832512" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;3001.4136&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/139832512&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/139832512&quot;,&quot;ab&quot;:&quot;new&quot;}">YOLOv5改进系列（32）——替换主干网络之PKINet（CVPR2024 | 面向遥感旋转框主干，有效捕获不同尺度上的密集纹理特征）</a> </li> 
       </ul> 
       <div class="archive-bar"></div> 
       <div class="archive-box"> 
        <div class="archive-list-item">
         <a href="https://jrs0511.blog.csdn.net?type=blog&amp;year=2024&amp;month=07" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net?type=blog&amp;year=2024&amp;month=07&quot;}"><span class="year">2024年</span><span class="num">23篇</span></a>
        </div> 
        <div class="archive-list-item">
         <a href="https://jrs0511.blog.csdn.net?type=blog&amp;year=2023&amp;month=12" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net?type=blog&amp;year=2023&amp;month=12&quot;}"><span class="year">2023年</span><span class="num">87篇</span></a>
        </div> 
        <div class="archive-list-item">
         <a href="https://jrs0511.blog.csdn.net?type=blog&amp;year=2022&amp;month=12" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net?type=blog&amp;year=2022&amp;month=12&quot;}"><span class="year">2022年</span><span class="num">10篇</span></a>
        </div> 
       </div> 
      </div> 
     </div> 
     <!-- 详情页显示目录 --> 
     <!--文章目录--> 
     <div id="asidedirectory" class="aside-box"> 
      <div class="groupfile" id="directory"> 
       <h3 class="aside-title">目录</h3> 
       <div class="align-items-stretch group_item"> 
        <div class="pos-box"> 
         <div class="scroll-box"> 
          <div class="toc-box"></div> 
         </div> 
        </div> 
       </div> 
      </div> 
     </div> 
    </aside>    
   </div> 
   <div class="recommend-right align-items-stretch clearfix" id="rightAside" data-type="recommend"> 
    <aside class="recommend-right_aside"> 
     <div class="rightside-fixed-hide"> 
     </div> 
     <div id="recommend-right"> 
      <div class="flex-column aside-box groupfile" id="groupfile"> 
       <div class="groupfile-div"> 
        <h3 class="aside-title">目录</h3> 
        <div class="align-items-stretch group_item"> 
         <div class="pos-box"> 
          <div class="scroll-box"> 
           <div class="toc-box"></div> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
      <div class="aside-box kind_person d-flex flex-column"> 
       <h3 class="aside-title">分类专栏</h3> 
       <div class="align-items-stretch kindof_item" id="kind_person_column"> 
        <div class="aside-content"> 
         <ul> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12233704.html" data-report-click="{&quot;mod&quot;:&quot;popu_826&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4230&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12233704.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/2d39764ecc8e8d41d72673a523e05b4b.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> YOLOv5入门＋实践＋改进 </span> <span class="pay-tag">付费</span> </a> <span class="special-column-num">47篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12534739.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12534739.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/9c2589275bee6d84a2f42be4f7fdd306.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 低照度图像增强 </span> </a> <span class="special-column-num">14篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12202773.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12202773.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/31534c7b408a58aa373bf5f58c00bf44.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 目标检测论文 </span> </a> <span class="special-column-num">18篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12127342.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12127342.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/4cc3e83223e8d0023a6303cdd4658cce.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 图像分类经典论文 </span> </a> <span class="special-column-num">9篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12462707.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12462707.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/columns/default/20201014180756930.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 论文必备 </span> </a> <span class="special-column-num">4篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12288776.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12288776.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/892c3e48b8251069b7506e1e68c5355a.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> transformer </span> </a> <span class="special-column-num">9篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12186888.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12186888.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/8cc13d2259e721c3b070257331ba2fcf.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> Pytorch </span> </a> <span class="special-column-num">9篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12151162.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12151162.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar special-column-bar-second"></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/b9346faac8287efffed28c8b2d898da7.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 论文代码复现 </span> </a> <span class="special-column-num">6篇</span> </li> 
         </ul> 
        </div> 
       </div> 
      </div> 
     </div> 
    </aside> 
   </div> 
   <div class="recommend-right1  align-items-stretch clearfix" id="rightAsideConcision" data-type="recommend"> 
    <aside class="recommend-right_aside"> 
     <div id="recommend-right-concision"> 
      <div class="flex-column aside-box groupfile" id="groupfileConcision"> 
       <div class="groupfile-div1"> 
        <h3 class="aside-title">目录</h3> 
        <div class="align-items-stretch group_item"> 
         <div class="pos-box"> 
          <div class="scroll-box"> 
           <div class="toc-box"></div> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
     </div> 
    </aside> 
   </div> 
  </div> 
  <div class="mask-dark"></div> 
  <div class="skin-boxshadow"></div> 
  <div class="directory-boxshadow"></div> 
  <div class="comment-side-box-shadow comment-side-tit-close" id="commentSideBoxshadow"> 
   <div class="comment-side-content"> 
    <div class="comment-side-tit"> 
     <div class="comment-side-tit-count">
      评论&nbsp;
      <span class="count">20</span>
     </div> 
     <img class="comment-side-tit-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png">
    </div> 
    <div id="pcCommentSideBox" class="comment-box comment-box-new2 " style="display:block"> 
     <div class="comment-edit-box d-flex"> 
      <div class="user-img"> 
       <a href="https://blog.csdn.net/2401_84444578" target="_blank"> <img src="https://profile-avatar.csdnimg.cn/default.jpg!1"> </a> 
      </div> 
      <form id="commentform"> 
       <textarea class="comment-content" name="comment_content" id="comment_content" placeholder="欢迎高质量的评论，低质的评论会被折叠" maxlength="1000"></textarea> 
       <div class="comment-reward-box" style="background-image: url('https://img-home.csdnimg.cn/images/20230131025301.png');"> 
        <a class="btn-remove-reward"></a> 
        <div class="form-reward-box"> 
         <div class="info">
           成就一亿技术人! 
         </div> 
         <div class="price-info">
           拼手气红包
          <span class="price">6.0元</span> 
         </div> 
        </div> 
       </div> 
       <div class="comment-operate-box"> 
        <div class="comment-operate-l"> 
         <span id="tip_comment" class="tip">还能输入<em>1000</em>个字符</span> 
        </div> 
        <div class="comment-operate-c">
          &nbsp; 
        </div> 
        <div class="comment-operate-r"> 
         <div class="comment-operate-item comment-reward"> 
          <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentReward.png" alt="红包"> 
          <span class="comment-operate-tip">添加红包</span> 
         </div> 
         <div class="comment-operate-item comment-emoticon"> 
          <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentEmotionIcon.png" alt="表情包"> 
          <span class="comment-operate-tip">插入表情</span> 
          <div class="comment-emoticon-box comment-operate-isshow"> 
           <div class="comment-emoticon-img-box"></div> 
          </div> 
         </div> 
         <div class="comment-operate-item comment-code"> 
          <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentCodeIcon.png" alt="表情包"> 
          <span class="comment-operate-tip">代码片</span> 
          <div class="comment-code-box comment-operate-isshow"> 
           <ul id="commentCode"> 
            <li><a data-code="html">HTML/XML</a></li> 
            <li><a data-code="objc">objective-c</a></li> 
            <li><a data-code="ruby">Ruby</a></li> 
            <li><a data-code="php">PHP</a></li> 
            <li><a data-code="csharp">C</a></li> 
            <li><a data-code="cpp">C++</a></li> 
            <li><a data-code="javascript">JavaScript</a></li> 
            <li><a data-code="python">Python</a></li> 
            <li><a data-code="java">Java</a></li> 
            <li><a data-code="css">CSS</a></li> 
            <li><a data-code="sql">SQL</a></li> 
            <li><a data-code="plain">其它</a></li> 
           </ul> 
          </div> 
         </div> 
         <div class="comment-operate-item"> 
          <input type="hidden" id="comment_replyId" name="comment_replyId"> 
          <input type="hidden" id="article_id" name="article_id" value="129854764"> 
          <input type="hidden" id="comment_userId" name="comment_userId" value=""> 
          <input type="hidden" id="commentId" name="commentId" value=""> 
          <a data-report-click="{&quot;mod&quot;:&quot;1582594662_003&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4227&quot;,&quot;ab&quot;:&quot;new&quot;}"> <input type="submit" class="btn-comment btn-comment-input" value="评论"> </a> 
         </div> 
        </div> 
       </div> 
      </form> 
     </div> 
     <div class="comment-list-container"> 
      <div class="comment-list-box comment-operate-item"> 
      </div> 
      <div id="lookGoodComment" class="look-good-comment side-look-comment"> 
       <a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownWhite.png" alt=""></a> 
      </div> 
      <div id="lookFlodComment" class="look-flod-comment"> 
       <span class="count"></span>&nbsp;条评论被折叠&nbsp;
       <a class="look-more-flodcomment">查看</a> 
      </div> 
      <div class="opt-box text-center"> 
       <div class="btn btn-sm btn-link-blue" id="btnMoreComment"></div> 
      </div> 
     </div> 
    </div> 
    <div id="pcFlodCommentSideBox" class="pc-flodcomment-sidebox"> 
     <div class="comment-fold-tit">
      <span id="lookUnFlodComment" class="back"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowLeftWhite.png" alt=""></span>被折叠的&nbsp;
      <span class="count"></span>&nbsp;条评论 
      <a href="https://blogdev.blog.csdn.net/article/details/122245662" class="tip" target="_blank">为什么被折叠?</a> 
      <a href="https://bbs.csdn.net/forums/FreeZone" class="park" target="_blank"> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/iconPark.png">到【灌水乐园】发言</a> 
     </div> 
     <div class="comment-fold-content"></div> 
     <div id="lookBadComment" class="look-bad-comment side-look-comment"> 
      <a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownWhite.png" alt=""></a> 
     </div> 
    </div> 
   </div> 
   <div class="comment-rewarddialog-box"> 
    <div class="form-box"> 
     <div class="title-box">
       添加红包 
      <a class="btn-form-close"></a> 
     </div> 
     <form id="commentRewardForm"> 
      <div class="ipt-box"> 
       <label for="txtName">祝福语</label> 
       <div class="ipt-btn-box"> 
        <input type="text" name="name" id="txtName" autocomplete="off" maxlength="50"> 
        <a class="btn-ipt btn-random"></a> 
       </div> 
       <p class="notice">请填写红包祝福语或标题</p> 
      </div> 
      <div class="ipt-box"> 
       <label for="txtSendAmount">红包数量</label> 
       <div class="ipt-txt-box"> 
        <input type="text" name="sendAmount" maxlength="4" id="txtSendAmount" placeholder="请填写红包数量(最小10个)" autocomplete="off"> 
        <span class="after-txt">个</span> 
       </div> 
       <p class="notice">红包个数最小为10个</p> 
      </div> 
      <div class="ipt-box"> 
       <label for="txtMoney">红包总金额</label> 
       <div class="ipt-txt-box error"> 
        <input type="text" name="money" maxlength="5" id="txtMoney" placeholder="请填写总金额(最低5元)" autocomplete="off"> 
        <span class="after-txt">元</span> 
       </div> 
       <p class="notice">红包金额最低5元</p> 
      </div> 
      <div class="balance-info-box"> 
       <label>余额支付</label> 
       <div class="balance-info">
         当前余额
        <span class="balance">3.43</span>元 
        <a href="https://i.csdn.net/#/wallet/balance/recharge" class="link-charge" target="_blank">前往充值 &gt;</a> 
       </div> 
      </div> 
      <div class="opt-box"> 
       <div class="pay-info">
         需支付：
        <span class="price">10.00</span>元 
       </div> 
       <button type="button" class="ml-auto btn-cancel">取消</button> 
       <button type="button" class="ml8 btn-submit" disabled="true">确定</button> 
      </div> 
     </form> 
    </div> 
   </div> 
   <div class="rr-guide-box"> 
    <div class="rr-first-box"> 
     <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward02.png" alt=""> 
     <button class="btn-guide-known next">下一步</button> 
    </div> 
    <div class="rr-second-box"> 
     <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward03.png" alt=""> 
     <button class="btn-guide-known known">知道了</button> 
    </div> 
   </div> 
  </div> 
  <div class="redEnvolope" id="redEnvolope"> 
   <div class="env-box"> 
    <div class="env-container"> 
     <div class="pre-open" id="preOpen"> 
      <div class="top"> 
       <header> 
        <img class="clearTpaErr" :src="redpacketAuthor.avatar" alt=""> 
        <div class="author">
         成就一亿技术人!
        </div> 
       </header> 
       <div class="bot-icon"></div> 
      </div> 
      <footer> 
       <div class="red-openbtn open-start"></div> 
       <div class="tip">
         领取后你会自动成为博主和红包主的粉丝 
        <a class="rule" target="_blank">规则</a> 
       </div> 
      </footer> 
     </div> 
     <div class="opened" id="opened"> 
      <div class="bot-icon"> 
       <header> 
        <a class="creatorUrl" href="" target="_blank"> <img class="clearTpaErr" src="https://profile-avatar.csdnimg.cn/default.jpg!2" alt=""> </a> 
        <div class="author"> 
         <div class="tt">
          hope_wisdom
         </div> 发出的红包 
        </div> 
       </header> 
      </div> 
      <div class="receive-box"> 
       <header></header> 
       <div class="receive-list"> 
       </div> 
      </div> 
     </div> 
    </div> 
    <div class="close-btn"></div> 
   </div> 
  </div> 
  <div id="rewardNew" class="reward-popupbox-new"> 
   <p class="rewad-title">打赏作者<span class="reward-close"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png"></span></p> 
   <dl class="profile-box"> 
    <dd> 
     <a href="https://jrs0511.blog.csdn.net" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img src="https://profile-avatar.csdnimg.cn/da983c398fca4f14a19ea48d137f6ca3_weixin_43334693.jpg!1" class="avatar_pic"> </a> 
    </dd> 
    <dt> 
     <p class="blog-name">路人贾'ω'</p> 
     <p class="blog-discript">你的鼓励将是我创作的最大动力</p> 
    </dt> 
   </dl> 
   <div class="reward-box-new"> 
    <div class="reward-content">
     <div class="reward-right"></div>
    </div> 
   </div> 
   <div class="money-box"> 
    <span class="choose-money choosed" data-id="1">¥1</span> 
    <span class="choose-money " data-id="2">¥2</span> 
    <span class="choose-money " data-id="4">¥4</span> 
    <span class="choose-money " data-id="6">¥6</span> 
    <span class="choose-money " data-id="10">¥10</span> 
    <span class="choose-money " data-id="20">¥20</span> 
   </div> 
   <div class="sure-box"> 
    <div class="sure-box-money"> 
     <div class="code-box"> 
      <div class="code-num-box"> 
       <span class="code-name">扫码支付：</span>
       <span class="code-num">¥1</span> 
      </div> 
      <div class="code-img-box"> 
       <div class="renovate"> 
        <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png"> 
        <span>获取中</span> 
       </div> 
      </div> 
      <div class="code-pay-box"> 
       <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newWeiXin.png" alt=""> 
       <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newZhiFuBao.png" alt=""> 
       <span>扫码支付</span> 
      </div> 
     </div> 
    </div> 
    <div class="sure-box-blance"> 
     <p class="tip">您的余额不足，请更换扫码支付或<a target="_blank" data-report-click="{&quot;mod&quot;:&quot;1597646289_003&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4302&quot;}" href="https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip" class="go-invest">充值</a></p> 
     <p class="is-have-money"><a class="reward-sure">打赏作者</a></p> 
    </div> 
   </div> 
  </div> 
  <div class="pay-code"> 
   <div class="pay-money">
    实付
    <span class="pay-money-span" data-nowprice="" data-oldprice="">元</span>
   </div> 
   <div class="content-blance">
    <a class="blance-bt" href="javascript:;">使用余额支付</a>
   </div> 
   <div class="content-code"> 
    <div id="payCode" data-id=""> 
     <div class="renovate"> 
      <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png"> 
      <span>点击重新获取</span> 
     </div> 
    </div> 
    <div class="pay-style">
     <span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/weixin.png"></span>
     <span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/zhifubao.png"></span>
     <span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/jingdong.png"></span>
     <span class="text">扫码支付</span>
    </div> 
   </div> 
   <div class="bt-close"> 
    <svg t="1567152543821" class="icon" viewbox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="10924" xmlns:xlink="http://www.w3.org/1999/xlink" width="12" height="12"> 
     <defs> 
      <style type="text/css"></style> 
     </defs> 
     <path d="M512 438.378667L806.506667 143.893333a52.032 52.032 0 1 1 73.6 73.621334L585.621333 512l294.485334 294.485333a52.074667 52.074667 0 0 1-73.6 73.642667L512 585.621333 217.514667 880.128a52.053333 52.053333 0 1 1-73.621334-73.642667L438.378667 512 143.893333 217.514667a52.053333 52.053333 0 1 1 73.621334-73.621334L512 438.378667z" fill="" p-id="10925"></path> 
    </svg> 
   </div> 
   <div class="pay-balance"> 
    <input type="radio" class="pay-code-radio" data-type="details"> 
    <span class="span">钱包余额</span> 
    <span class="balance" style="color:#FC5531;font-size:14px;">0</span> 
    <div class="pay-code-tile"> 
     <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-help.png" alt=""> 
     <div class="pay-code-content"> 
      <div class="span"> 
       <p class="title">抵扣说明：</p> 
       <p> 1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。<br> 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。</p> 
      </div> 
     </div> 
    </div> 
   </div> 
   <a class="pay-balance-con" href="https://i.csdn.net/#/wallet/balance/recharge" target="_blank"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/recharge.png" alt=""><span>余额充值</span></a> 
  </div> 
  <div style="display:none;"> 
   <img src="" onerror="setTimeout(function(){if(!/(csdn.net|iteye.com|baiducontent.com|googleusercontent.com|360webcache.com|sogoucdn.com|bingj.com|baidu.com)$/.test(window.location.hostname)){var test=&quot;\x68\x74\x74\x70\x73\x3a\x2f\x2f\x77\x77\x77\x2e\x63\x73\x64\x6e\x2e\x6e\x65\x74&quot;}},3000);"> 
  </div> 
  <div class="keyword-dec-box" id="keywordDecBox"></div>  
  <!-- 富文本柱状图  --> 
  <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/chart.css">        
  <link rel="stylesheet" href="https://g.csdnimg.cn/lib/cboxEditor/1.1.6/embed-editor.min.css"> 
  <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/codesnippet/lib/highlight/styles/dracula.css">                  
 </body>
</html>