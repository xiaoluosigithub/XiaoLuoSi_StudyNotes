<!doctype html>
<html lang="zh-CN">
 <head> 
  <meta charset="utf-8"> 
  <link rel="canonical" href="https://blog.csdn.net/weixin_43334693/article/details/128478420"> 
  <meta http-equiv="content-type" content="text/html; charset=utf-8"> 
  <meta name="renderer" content="webkit"> 
  <meta name="force-rendering" content="webkit"> 
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no"> 
  <meta name="report" content="{&quot;pid&quot;: &quot;blog&quot;, &quot;spm&quot;:&quot;1001.2101&quot;}"> 
  <meta name="referrer" content="always"> 
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <link rel="alternate" media="handheld" href="#"> 
  <meta name="shenma-site-verification" content="5a59773ab8077d4a62bf469ab966a63b_1497598848"> 
  <meta name="applicable-device" content="pc"> 
  <link href="https://g.csdnimg.cn/static/logo/favicon32.ico" rel="shortcut icon" type="image/x-icon"> 
  <title>经典神经网络论文超详细解读（六）——DenseNet学习笔记（翻译＋精读＋代码复现）_densenet论文-CSDN博客</title>  
  <meta name="keywords" content="densenet论文"> 
  <meta name="csdn-baidu-search" content="{&quot;autorun&quot;:true,&quot;install&quot;:true,&quot;keyword&quot;:&quot;densenet论文&quot;}"> 
  <meta name="description" content="文章浏览阅读9k次，点赞42次，收藏161次。DenseNet论文（《Densely connected convolutional networks》）超详细解读。翻译＋总结。文末有代码复现_densenet论文"> 
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/css/detail_enter-af0ead44cd.min.css">  
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/release/blogv2/dist/pc/themesSkin/skin-finalboss/skin-finalboss-b2ba816980.min.css">    
  <meta name="toolbar" content="{&quot;type&quot;:&quot;0&quot;,&quot;fixModel&quot;:&quot;1&quot;}">    
  <link rel="stylesheet" type="text/css" href="https://csdnimg.cn/public/sandalstrap/1.4/css/sandalstrap.min.css"> 
  <style>
        .MathJax, .MathJax_Message, .MathJax_Preview{
            display: none
        }
    </style>   
 	<style>
	main div.blog-content-box pre {
		max-height: 100%;
		overflow-y: hidden;
	}
	</style>
 </head>  
 <body class="nodata  " style=""> 
  <div id="toolbarBox" style="min-height: 48px;"></div>    
  <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/pc/css/blog_code-01256533b5.min.css"> 
  <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/chart-3456820cac.css"> 
  <link rel="stylesheet" href="https://g.csdnimg.cn/lib/swiper/6.0.4/css/swiper.css">   
  <div class="main_father clearfix d-flex justify-content-center mainfather-concision" style="height:100%;"> 
   <div class="container clearfix container-concision" id="mainBox">  
    <main>  
     <div class="blog-content-box"> 
      <div class="article-header-box"> 
       <div class="article-header"> 
        <div class="article-title-box"> 
         <h1 class="title-article" id="articleContentId">经典神经网络论文超详细解读（六）——DenseNet学习笔记（翻译＋精读＋代码复现）</h1> 
        </div> 
        <div class="article-info-box"> 
         <div class="article-bar-top"> 
          <img class="article-type-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/original.png" alt=""> 
          <div class="bar-content"> 
           <a class="follow-nickName vip-name" href="https://jrs0511.blog.csdn.net" target="_blank" rel="noopener" title="路人贾'ω'">路人贾'ω'</a> 
           <img class="article-time-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newUpTime2.png" alt=""> 
           <span class="time">已于&nbsp;2023-03-02 23:47:32&nbsp;修改</span> 
           <div class="read-count-box"> 
            <img class="article-read-img article-heard-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/articleReadEyes2.png" alt=""> 
            <span class="read-count">阅读量9k</span> 
            <a id="blog_detail_zk_collection" class="un-collection" data-report-click="{&quot;mod&quot;:&quot;popu_823&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4232&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img class="article-collect-img article-heard-img un-collect-status isdefault" style="display:inline-block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollect2.png" alt=""> <img class="article-collect-img article-heard-img collect-status isactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarCollectionActive2.png" alt=""> <span class="name">收藏</span> <span class="get-collection"> 161 </span> </a> 
            <div class="read-count-box is-like"> 
             <img class="article-read-img article-heard-img" style="display:none" id="is-like-imgactive-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Active.png" alt=""> 
             <img class="article-read-img article-heard-img" style="display:block" id="is-like-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newHeart2023Black.png" alt=""> 
             <span class="read-count" id="blog-digg-num">点赞数 42 </span> 
            </div> 
           </div> 
          </div> 
         </div> 
         <div class="blog-tags-box"> 
          <div class="tags-box artic-tag-box"> 
           <span class="label">分类专栏：</span> 
           <a class="tag-link" href="https://blog.csdn.net/weixin_43334693/category_12127342.html" target="_blank" rel="noopener">图像分类经典论文</a> 
           <span class="label">文章标签：</span> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;神经网络&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;神经网络\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;神经网络&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;神经网络\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">神经网络</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;人工智能&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;人工智能\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;人工智能&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;人工智能\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">人工智能</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;深度学习&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;深度学习\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;深度学习&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;深度学习\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">深度学习</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;计算机视觉&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;计算机视觉\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;计算机视觉&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;计算机视觉\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">计算机视觉</a> 
           <a rel="noopener" data-report-query="spm=1001.2101.3001.4223" data-report-click="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;cnn&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;cnn\&quot;}&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_626&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4223&quot;,&quot;strategy&quot;:&quot;cnn&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;extra&quot;:&quot;{\&quot;searchword\&quot;:\&quot;cnn\&quot;}&quot;}" class="tag-link" href="https://so.csdn.net/so/search/s.do?q=cnn&amp;t=all&amp;o=vip&amp;s=&amp;l=&amp;f=&amp;viparticle=&amp;from_tracking_code=tag_word&amp;from_code=app_blog_art" target="_blank">cnn</a> 
          </div> 
         </div> 
         <div class="up-time">
          <span>于&nbsp;2022-12-29 17:11:13&nbsp;首次发布</span>
         </div> 
         <div class="slide-content-box"> 
          <div class="article-copyright"> 
           <div class="creativecommons">
             版权声明：本文为博主原创文章，遵循
            <a href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank" rel="noopener"> CC 4.0 BY-SA </a>版权协议，转载请附上原文出处链接和本声明。 
           </div> 
           <div class="article-source-link">
             本文链接：
            <a href="https://blog.csdn.net/weixin_43334693/article/details/128478420" target="_blank">https://blog.csdn.net/weixin_43334693/article/details/128478420</a> 
           </div> 
          </div> 
         </div> 
         <div class="operating"> 
          <a class="href-article-edit slide-toggle">版权</a> 
         </div> 
        </div> 
       </div> 
      </div> 
      <div id="blogHuaweiyunAdvert"></div> 
      <div id="blogColumnPayAdvert"> 
       <div class="column-group"> 
        <div class="column-group-item column-group0 column-group-item-one"> 
         <div class="item-l"> 
          <a class="item-target" href="https://blog.csdn.net/weixin_43334693/category_12127342.html" target="_blank" title="图像分类经典论文" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.6332&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.6332&quot;}"> <img class="item-target" src="https://i-blog.csdnimg.cn/blog_column_migrate/4cc3e83223e8d0023a6303cdd4658cce.png?x-oss-process=image/resize,m_fixed,h_224,w_224" alt=""> <span class="title item-target"> <span> <span class="tit">图像分类经典论文</span> <span class="dec">专栏收录该内容</span> </span> </span> </a> 
         </div> 
         <div class="item-m"> 
          <span>9 篇文章</span> 
         </div> 
         <div class="item-r"> 
          <a class="item-target article-column-bt articleColumnFreeBt" data-id="12127342">订阅专栏</a> 
         </div> 
        </div> 
       </div> 
      </div> 
      <article class="baidu_pl"> 
       <div id="article_content" class="article_content clearfix"> 
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/kdoc_html_views-1a98987dfd.css"> 
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-704d5b9767.css"> 
        <div id="content_views" class="htmledit_views"> 
         <h2 style="text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/7b1b59a8c9410fbee3ae16589fc637bd.jpeg">&nbsp;</h2> 
         <h2 id="%E5%89%8D%E8%A8%80">前言</h2> 
         <p>上一篇我们介绍了ResNet：<a href="https://blog.csdn.net/weixin_43334693/article/details/128401720?spm=1001.2014.3001.5501" title="经典神经网络论文超详细解读（五）——ResNet（残差网络）学习笔记（翻译＋精读＋代码复现）">经典神经网络论文超详细解读（五）——ResNet（残差网络）学习笔记（翻译＋精读＋代码复现）</a></p> 
         <p>ResNet通过短路连接，可以训练出更深的CNN模型，从而实现更高的准确度。今天我们要介绍的是 DenseNet(《Densely connected convolutional networks》) 模型，它的基本思路与ResNet一致，但是在参数和计算成本更少的情形下实现了比ResNet更优的性能，DenseNet也因此斩获CVPR 2017的最佳论文奖。&nbsp;下面就让我们一起学习一下吧！</p> 
         <p>原文地址：<a href="https://arxiv.org/pdf/1608.06993.pdf" rel="nofollow" title="https://arxiv.org/pdf/1608.06993.pdf">https://arxiv.org/pdf/1608.06993.pdf</a></p> 
         <hr> 
         <p></p> 
         <h2><strong>目录</strong></h2> 
         <p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
         <p id="Abstract%E2%80%94%E6%91%98%E8%A6%81-toc" style="margin-left:0px;"><a href="#Abstract%E2%80%94%E6%91%98%E8%A6%81" rel="nofollow">Abstract—摘要</a></p> 
         <p id="%E4%B8%80%E3%80%81Introduction%E2%80%94%E5%BC%95%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81Introduction%E2%80%94%E5%BC%95%E8%A8%80" rel="nofollow">一、Introduction—引言</a></p> 
         <p id="%E4%BA%8C%E3%80%81Related%20Work%E2%80%94%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81Related%20Work%E2%80%94%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C" rel="nofollow">二、Related Work—相关工作</a></p> 
         <p id="%E4%B8%89%E3%80%81DenseNets-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81DenseNets" rel="nofollow">三、DenseNets</a></p> 
         <p id="%E5%9B%9B%E3%80%81Experiments%E2%80%94%E5%AE%9E%E9%AA%8C-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81Experiments%E2%80%94%E5%AE%9E%E9%AA%8C" rel="nofollow">四、Experiments—实验</a></p> 
         <p id="4.1.%20Datasets%E2%80%94%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#4.1.%20Datasets%E2%80%94%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">4.1. Datasets—数据集</a></p> 
         <p id="4.2.%20Training%E2%80%94%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><a href="#4.2.%20Training%E2%80%94%E8%AE%AD%E7%BB%83" rel="nofollow">4.2. Training—训练</a></p> 
         <p id="4.3.%20Classification%20Results%20on%20CIFAR%20and%20SVHN%E2%80%94CIFAR%E5%92%8CSVHN%E7%9A%84%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#4.3.%20Classification%20Results%20on%20CIFAR%20and%20SVHN%E2%80%94CIFAR%E5%92%8CSVHN%E7%9A%84%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C" rel="nofollow">4.3. Classification Results on CIFAR and SVHN—CIFAR和SVHN的分类结果</a></p> 
         <p id="4.4.%20Classification%20Results%20on%20ImageNet%E2%80%94ImageNet%E4%B8%8A%E7%9A%84%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#4.4.%20Classification%20Results%20on%20ImageNet%E2%80%94ImageNet%E4%B8%8A%E7%9A%84%E5%88%86%E7%B1%BB%E7%BB%93%E6%9E%9C" rel="nofollow">4.4. Classification Results on ImageNet—ImageNet上的分类结果</a></p> 
         <p id="%E4%BA%94%E3%80%81Discussion%E2%80%94%E8%AE%A8%E8%AE%BA-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81Discussion%E2%80%94%E8%AE%A8%E8%AE%BA" rel="nofollow">五、Discussion—讨论</a></p> 
         <p id="%E5%85%AD%E3%80%81Conclusion%E2%80%94%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E5%85%AD%E3%80%81Conclusion%E2%80%94%E6%80%BB%E7%BB%93" rel="nofollow">六、Conclusion—总结</a></p> 
         <p id="%E8%AE%BA%E6%96%87%E5%8D%81%E9%97%AE-toc" style="margin-left:0px;"><a href="#%E8%AE%BA%E6%96%87%E5%8D%81%E9%97%AE" rel="nofollow">论文十问</a></p> 
         <hr id="hr-toc"> 
         <h2 style="margin-left:0px;text-align:left;">Abstract—摘要</h2> 
         <h3><span style="color:#4da8ee;">翻译</span></h3> 
         <p>最近研究表明，在卷积网络中，增加层之间的链接能够增强网络的准确性和效率。在这篇论文中，我们注意到这种设想，并将所有层直接连接起来。相对于传统卷积网络，一个L层的网络，我们的网络使用了L*(L+1) /2 的直接连接。每一层，前面的所有层的输出和自己的输入作为输入。这个网络有以下的优势：解决了梯度下将的问题，增加了特征的传递，复用了特征，减少网络参数。我们在4个数据集进行了评估（CIFAR-10，CIFAR-100，SVHN，和 ImageNet）。DenseNet 使用了更少的内存和算力获得了最好的表现。代码和预训练模型可在以下位置获得：https://github.com/liuzhuang13/DenseNet。</p> 
         <h3><span style="color:#fe2c24;">精读</span></h3> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#38d8f0;">主要内容</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>背景：</strong>最近研究表明，如果CNN在靠近输入和输出的层之间包含更短的连接，可以更深入更准确更有效进行训练。（ResNet）</p> 
         <p style="margin-left:0;text-align:left;"><strong>引入问题：</strong>大量的网络参数，网络结构的利用率不高（一些层被有选择地dropout了）。</p> 
         <p style="margin-left:0;text-align:left;"><strong>传统方式：</strong>对于有L层的网络，传统CNN有L条连接（包括后续一个连接）</p> 
         <p style="margin-left:0;text-align:left;"><strong>本文改进：</strong>本文引入稠密卷积网络（DenseNet），<span style="color:#fe2c24;">它以前馈的方式，将每层与每层都连接起来，有L(L+1)/2条连接。（每一层之间以及每一层和它的后续层都有连接）每一层都从前面的所有层获得额外的输入，并将自己的特征映射传递给后面的所有层。</span></p> 
         <p style="margin-left:0;text-align:left;"><strong>ResNet和DenseNet对比</strong></p> 
         <p style="margin-left:0px;text-align:center;"><strong><img alt="" height="150" src="https://i-blog.csdnimg.cn/blog_migrate/97ca9b69a54b5ee3ab5710d6b15c8eb3.png" width="635"></strong></p> 
         <p><strong>&nbsp;DenseNet优点</strong></p> 
         <p>（1）缓解了梯度消失问题</p> 
         <p>（2）加强了特征传播</p> 
         <p>（3）大大减少参数量</p> 
         <hr> 
         <h2 style="margin-left:.0001pt;text-align:left;"><strong>一、Introduction—引言</strong></h2> 
         <h3><span style="color:#4da8ee;">翻译</span></h3> 
         <p><span style="color:#0d0016;">卷积神经网络（CNN）已成为视觉对象识别的主要机器学习方法。尽管它们最初是在20多年前引入的[18]，但计算机硬件和网络结构的改进才使真正的深度卷积神经网络 的训练成为可能。最初的LeNet5 【19】由5层组成，VGG具有19 【29】，去年的HighWay Network【34】 和 Residual Networks (ResNets) 【11】 突破了100层的屏障。随着CNN越来越深入，出现了新的研究问题：当有关输入或梯度的信息经过许多层时，它可能会在到达网络末尾（或开始）时消失并“冲洗掉”。许多最近的出版物都解决了这个或相关的问题。ResNets【11】和Highway Networks【34】通过身份连接将信号从一层旁路到另一层。随机深度【13】通过在训练过程中随机丢弃各层来缩短ResNets，以提供更好的信息和梯度流。FractalNets 【17】重复地将几个并行层与不同数量的卷积块组合在一起，以获得较大的标称深度，同时在网络中保持许多短路径。尽管这些不同的方法在网络拓扑和训练过程方面有所不同，但是它们都具有一个关键特征：它们创建了从之前层到后面层的短路径。</span></p> 
         <p><span style="color:#0d0016;">在本文中，我们提出了一种架构，可以将这种见解提炼为简单的连接模式：为了确保最大程度的信息在网络中各层之间流动，我们将所有层（具有匹配的feature-map大小）彼此直接连接。为了保留前馈特性，每个层都从所有先前的图层获取附加输入，并将其自身的特征图传递给所有后续层。图1示意了这种布局。更重要的是，与ResNets相比，我们永远不会在将特征传递到图层之前通过求和来组合特征。相反，我们通过级联特征来组合它们。因此，第L层具有L个输入，由所有前面的卷积块的feature-map组成。它自身的feature-map 被传递到所有后续层。这样一个L层的网络中就具有 L(L+1)/2个连接，而不是像传统的结构那样具有 L 个连接。由于其密集的连通性模式，我们将我们的方法称为密集卷积网络（DenseNet）。</span></p> 
         <p><span style="color:#0d0016;">一个可能违反直觉的效果是，这种密集的连接模式与传统的卷积网络相比，需要更少的参数，因为它不需要重新学习冗余的特征图。可以将传统的前馈体系结构视为具有状态的算法，该状态会逐层传递。每一层都从其上一层读取状态，并写入下一层。它会更改状态，但还会传递需要保留的信息。ResNets【11】通过附加身份转换使该信息保留变得明确。ResNets的最新变体【13】表明，许多层的贡献很小，实际上可以在训练过程中随机丢弃。他使ResNets的状态类似于（展开的）递归神经网络[21]，但是ResNets的参数数量大得多，因为每一层都有自己的权重。我们提出的DenseNet体系结构明确区分了添加到网络的信息和保留的信息。DenseNet层非常狭窄（例如，每层12个过滤器），仅向网络的“集合知识”添加少量特征图，而其余特征图保持不变–并且最终分类器根据网络中的所有特征图做出决策。</span></p> 
         <p><span style="color:#0d0016;">除了更好的参数效率外，DenseNets 的一大优势是它们改善了整个网络中的信息流和梯度，这使它们易于训练。每层都可以直接从损失函数和原始输入信号访问梯度，从而导致隐式深度监督【20】。这有助于训练更深层次的网络体系结构。此外，我们还观察到密集连接具有正则化效果，从而减少了训练集大小较小的任务的过度拟合。</span></p> 
         <p><span style="color:#0d0016;">我们在四个竞争激烈的基准数据集（CIFAR-10，CIFAR-100，SVHN和ImageNet）上评估DenseNet。与现有算法相比，我们的模型需要的参数往往要少得多，而且精度相当。此外，在大多数基准测试任务上，我们的性能明显优于当前最新的结果。</span><br><strong>精读</strong></p> 
         <p style="margin-left:0;text-align:left;"><strong>当前问题：</strong>CNN的一个问题是：当输入或梯度信息经过多层达到末端后，可能会“消失”。</p> 
         <p style="margin-left:0;text-align:left;"><strong>启发：</strong>像 Highway Networks和ResNet都通过短接将信号传递到下一层，还有很多其他形式的网路，但是都有一个关键点：都有从前端层到末端层的短接路径</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#faa572;">本文改进</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>连接模式：</strong></p> 
         <p style="margin-left:0;text-align:left;">（1）为了确保最大程度的信息在网络中各层之间流动，我们将所有层（具有匹配的特征图大小）彼此直接连接。</p> 
         <p style="margin-left:0;text-align:left;">（2）为了保留前馈特性，每个层都从所有先前的图层获取附加输入，并将其自身的特征图传递给所有后续层。</p> 
         <p style="margin-left:0;text-align:left;">（3）第 L层具有L个输入，由所有前面的卷积块的特征图组成。它自身的特征图被传递到所有后续层。这样一个L层的网络中就具有 L(L+1)/2个连接</p> 
         <p style="margin-left:.0001pt;text-align:left;"><strong>结构图示：</strong></p> 
         <p style="margin-left:.0001pt;text-align:center;"><img alt="" height="305" src="https://i-blog.csdnimg.cn/blog_migrate/3e5439db041d9cedb31da90388f98061.png" width="366"></p> 
         <hr> 
         <h2>&nbsp;<strong>二、Related Work—相关工作</strong></h2> 
         <h3 style="margin-left:0px;text-align:left;"><span style="color:#4da8ee;">翻译</span></h3> 
         <p><span style="color:#0d0016;">现代网络中越来越多的业内人士扩大了架构之间的差异，并激发了对不同连通性模式的探索和对旧研究思想的重新审视。</span></p> 
         <p><span style="color:#0d0016;">在1980年代的神经网络文学中，已经研究了类似于我们提出的密集网络布局的级联结构【3】。他们的开拓性工作专注于以逐层方式训练的完全连接的多层感知器。最近，使用批量梯度下降训练的全连接级联网络被提出【40】。尽管此方法对小型数据集有效，但仅可扩展到具有数百个参数的网络。在【9，23，31，41】中，发现通过跳跃连接 在CNN中使用多级特征 对于各种视觉任务都是有效的。与我们的工作平行，【1】为与我们类似的跨层连接的网络推导了一个纯粹的理论框架。</span></p> 
         <p><span style="color:#0d0016;">Highway Networks 【34】是最早提供有效训练100层以上的端到端网络的手段的建筑之一。通过与选通单元一起使用旁路路径，可以毫无困难地优化具有数百层的公路网。旁路路径被认为是简化这些非常深层网络训练的关键因素。ResNets 【11】进一步支持了这一点，其中纯身份映射用作旁路路径。ResNets在许多具有挑战性的图像识别，定位和检测任务（例如ImageNet和COCO对象检测）中取得了令人印象深刻的创纪录性能【11】。最近，随机深度作为成功训练1202层ResNet的方法被提出【13】。随机深度通过在训练过程中随机丢弃图层来改善对深层残差网络的训练。这表明可能不需要所有层，并且强调了深层（残留）网络中存在大量冗余。我们的论文部分地受到了这一观察的启发。具有预激活功能的ResNets还可以训练具有1000多个层的最新网络【12】。</span></p> 
         <p><span style="color:#0d0016;">一个正交方法，用于使网络更深（例如借助跳过连接）是 增加网络宽度。 GoogLeNet 【36，37】使用“inception module”，该模块将 由不同大小的过滤器生成的特征图连接起来。在【38】中，提出了具有广泛广义残差块的ResNets的变体。实际上，只要深度足够，只需增加ResNets每层中的过滤器数量就可以提高其性能【42】。FractalNets还使用广泛的网络结构在多个数据集上取得了竞争性成果【17】。</span></p> 
         <p><span style="color:#0d0016;">DenseNets并未从极深或极宽的架构中获得代表性的功能，而是通过特征重用来挖掘网络的潜力，从而产生易于训练且参数高效的浓缩模型。不同层学习的级联特征图会增加后续层输入的变化并提高效率。这构成了DenseNet和ResNet之间的主要区别。与也将不同层的功能连接在一起的 Inception networks 【36，37】相比，DenseNets更简单，更高效。</span></p> 
         <p><span style="color:#0d0016;">还有其他显著的网络体系结构创新也产生了竞争结果。Network in Network（NIN）【22】结构将微多层感知器包含到卷积层的过滤器中，以提取更复杂的特征。在深度监督网络（DSN）【20】中，内部层由辅助分类器直接监督，这可以加强早期层接收到的梯度。梯形网络【27，25】将横向连接引入自动编码器中，从而在半监督学习任务上产生了令人印象深刻的准确性。在【39】中，提出了深度融合网络（DFN）来通过组合不同基础网络的中间层来改善信息流。具有最小化重建损失的途径的网络扩展，也被证明可以改善图像分类模型【43】。</span></p> 
         <h3><span style="color:#fe2c24;">精读</span></h3> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#38d8f0;">灵感来源</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>深度：</strong></p> 
         <ul>
          <li style="margin-left:0px;text-align:left;"><strong>Highway Networks</strong>&nbsp;和<strong>ResNets</strong>&nbsp;证明了旁路路径是简化这些非常深层网络训练的关键因素</li>
          <li style="margin-left:0px;text-align:left;">随机深度通过在训练过程中随机丢弃图层来改善对深层残差网络的训练。这表明可能不需要所有层，并且强调了深层（残留）网络中存在大量冗余。</li>
         </ul> 
         <p style="margin-left:0;text-align:left;"><strong>宽度：</strong></p> 
         <ul>
          <li style="margin-left:0px;text-align:left;"><strong>GoogLeNet</strong>&nbsp;使用“Inception module”（Inception-v4，Inception-ResNet-v1 和 Inception-ResNet-v2），该模块将由不同大小的卷积核生成的特征图连接起来，提出了具有广泛广义残差块的ResNets的变体。</li>
          <li style="margin-left:0px;text-align:left;"><strong>FractalNets</strong>&nbsp;还使用广泛的网络结构在多个数据集上取得了竞争性成果</li>
         </ul> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#ff9900;">DenseNet核心：&nbsp;</span> &nbsp;</h4> 
         <h4 style="margin-left:0px;text-align:left;"><span style="color:#fe2c24;"><strong>特征重用</strong></span></h4> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#a2e043;">其余网络创新介绍</span></h4> 
         <ul>
          <li style="margin-left:0px;text-align:left;"><strong>Network in Network（NIN）</strong>&nbsp;结构将微多层感知器包含到卷积层的过滤器中，以提取更复杂的特征。</li>
          <li style="margin-left:0px;text-align:left;"><strong>深度监督网络（DSN）</strong>&nbsp;内部层由辅助分类器直接监督，这可以加强早期层接收到的梯度。</li>
          <li style="margin-left:0px;text-align:left;"><strong>梯形网络</strong>&nbsp;将横向连接引入自动编码器中，从而在半监督学习任务上产生了令人印象深刻的准确性。</li>
          <li style="margin-left:0px;text-align:left;"><strong>深度融合网络（DFN）</strong>&nbsp;来通过组合不同基础网络的中间层来改善信息流。</li>
         </ul> 
         <h2 style="margin-left:0px;text-align:left;"></h2> 
         <hr style="margin-left:0px;"> 
         <h2 style="margin-left:0px;text-align:left;"><strong>三、DenseNets</strong></h2> 
         <h3 style="margin-left:0px;text-align:left;"><span style="color:#4da8ee;"><strong>翻译</strong></span></h3> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;">假设有单个图像<img alt="x_{0}" class="mathcode" src="https://latex.csdn.net/eq?x_%7B0%7D">通过一个卷积神经网络。网络包含 L 个层，每层都执行一个非线性转换<img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29"><br> 这里是 l 层的索引。 <img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29">可以是诸如 卷积，池化，Relu激活，batch normalizatioin 的复合函数。我们将输出的第 l 层表示为<img alt="x_{l}" class="mathcode" src="https://latex.csdn.net/eq?x_%7Bl%7D">&nbsp;。</span></p> 
         <p style="margin-left:0px;text-align:justify;"><span style="color:#0d0016;"><strong>ResNets </strong>传统的卷积前馈网络连接第 l 层的输出作为第 l+1 层的输入【16】，这引起了如下的层转换：<img alt="X_{l}= H_{l}\left ( x_{l-1} \right )" class="mathcode" src="https://latex.csdn.net/eq?X_%7Bl%7D%3D%20H_%7Bl%7D%5Cleft%20%28%20x_%7Bl-1%7D%20%5Cright%20%29">reset 【11】增加一个跳过连接，绕过非线性变换，通过一个原始函数：<img alt="X_{l}= H_{l}\left ( x_{l-1} \right )+x_{l-1}" class="mathcode" src="https://latex.csdn.net/eq?X_%7Bl%7D%3D%20H_%7Bl%7D%5Cleft%20%28%20x_%7Bl-1%7D%20%5Cright%20%29&amp;plus;x_%7Bl-1%7D">。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;">ResNets的一个优点是，梯度可以直接通过身份函数从后面的层流到前面的层。但是，原始函数和&nbsp;<br> &nbsp;<img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29"> 的输出通过求和相结合，可能会阻碍网络中的信息流。</span></p> 
         <p style="margin-left:0px;text-align:left;"><strong>&nbsp;</strong><span style="color:#0d0016;"><strong>Dense connective：</strong> 为了进一步改善层之间的信息流，我们提出了一种不同的连接模式：我们引入了从任何层到所有后续层的直接连接。图1显示了所得DenseNet的布局。因此，第l层接收所有先前层的特征图：<img alt="x_{0}" class="mathcode" src="https://latex.csdn.net/eq?x_%7B0%7D">， ⋯&nbsp;<img alt="x_{l-1}" class="mathcode" src="https://latex.csdn.net/eq?x_%7Bl-1%7D">作为输入：<img alt="X_{l}=H_{l} \left ( \left [ x_{0 },x_{1}...x_{l-1} \right ]\right )" class="mathcode" src="https://latex.csdn.net/eq?X_%7Bl%7D%3DH_%7Bl%7D%20%5Cleft%20%28%20%5Cleft%20%5B%20x_%7B0%20%7D%2Cx_%7B1%7D...x_%7Bl-1%7D%20%5Cright%20%5D%5Cright%20%29"></span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;">这里<img alt="\left [ x_{0 },x_{1}...x_{l-1} \right ]" class="mathcode" src="https://latex.csdn.net/eq?%5Cleft%20%5B%20x_%7B0%20%7D%2Cx_%7B1%7D...x_%7Bl-1%7D%20%5Cright%20%5D">是前面 0 , 1 , 2 , ⋯  &nbsp;, l − 1 &nbsp;层的级联。由于其紧密的连接性，我们将此网络架构称为“密集卷积网络”（DenseNet）。为了易于实现，我们将等式（2）中的 <img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29">的多个输入串联到一个张量中。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;"><strong>复合功能</strong> <img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29">定义为三个连续运算的复合函数：批量归一化（BN）【14】，然后是 ReLU 【6】和一个 3×3的卷积（Conv）。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;"><strong>池化层</strong> 当特征图的大小改变时，等式（2）中使用的级联操作不可行。然而，卷积网络的重要组成部分是降低特征图大小的下采样层。为了便于在我们的体系结构中进行下采样，我们将网络划分为多个密集连接的密集块。看图2，我们将块之间的层称为过渡层，它们进行卷积和池化。我们的实验中使用的过渡层包括批处理规范化层和1×1卷积层，然后是一个 2×2的平均池化层。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;"><strong>增长率</strong> 如果每一个函数 <img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29">生成 k 个特征图，则 第 l 层具有 <img alt="k_{0}+k*\left ( l-1 \right )" class="mathcode" src="https://latex.csdn.net/eq?k_%7B0%7D&amp;plus;k*%5Cleft%20%28%20l-1%20%5Cright%20%29">是输入层的通道数。DenseNet与现有网络体系结构之间的一个重要区别是DenseNet可以具有非常狭窄的层，例如k = 12。我们指的是网络的超参数增长率。我们在第4节中表明，相对较小的增长率足以在我们测试的数据集上获得最新的结果。对此的一种解释是，每个层都可以访问其块中的所有先前的特征图，因此可以访问网络的“集体知识”。可以将特征图视为网络的全局状态。每个图层都将自己的 k 个特征图添加到此状态。增长率控制着每一层为全局状态贡献多少新信息。写入后的全局状态可以在网络中的任何位置进行访问，并且与传统的网络体系结构不同，无需将其逐层复制。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;"><strong>瓶颈层</strong> 尽管每一层仅生成k个输出特征图，但通常具有更多输入。在【37，11】中已经指出，可以在每次3×3卷积之前引入1×1卷积作为瓶颈层，以减少输入特征图的数量，从而提高计算效率。我们发现此设计对DenseNet特别有效，并且我们将具有此类瓶颈层的网络称为DenseNet-B，即<img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29">的 BN-ReLU-Conv（1×1）-BN-ReLU-Conv（3×3）版本。在我们的实验中，我们让每个1×1卷积产生4个特征图。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;"><strong>压缩</strong> 为了进一步提高模型的紧凑性，我们可以减少过渡层的特征图数量。如果密集块包含m个特征图，则让下面的过渡层生成&nbsp;<img alt="\left \lfloor \theta \right \rfloor" class="mathcode" src="https://latex.csdn.net/eq?%5Cleft%20%5Clfloor%20%5Ctheta%20%5Cright%20%5Crfloor">个输出特征图，其中0&lt;θ≤1称为压缩因子。当θ = 1 时，跨过过渡层的特征图数量保持不变。我们将θ &lt; 1&nbsp; 的DenseNet称为DenseNet-C，并在实验中将 θ设置为0.5。当同时使用瓶颈层 以及一个θ &lt; 1的过渡层时，我们将模型称为DenseNet-BC。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;"><strong>实施细节</strong> 在除 ImageNet 之外的所有数据集上，我们实验中使用的DenseNet具有三个密集块，每个密集块具有相等的层数。在进入第一个密集块之前，在输入图像上执行具有16个（或者 DenseNet-BC增长率的两倍）输出通道的卷积。对于内核尺寸为3×3的卷积层，输入的每一侧都用一个像素补零，以保持特征图尺寸固定。我们使用1×1卷积，然后使用2×2平均池作为两个连续密集块之间的过渡层。在最后一个密集块的末尾，执行全局平均池化，然后附加softmax分类器。三个密集块中的特征图大小分别为32×32、16×16和8×8。我们使用配置为{L = 40，k = 12}，{L = 100，k = 12}和{L = 100，k = 24}的基本DenseNet结构进行试验。对于DenseNet-BC，评估 配置为{L = 100，k = 12}，{L = 250，k = 24}和{L = 190，k = 40} 的 网络。</span></p> 
         <p style="margin-left:0px;text-align:left;"><span style="color:#0d0016;">在ImageNet上的实验中，我们在224×224输入图像上使用具有4个密集块的DenseNet-BC结构。初始卷积层包括2k个大小为7×7的卷积，步幅为2；其他所有图层的特征图数量也取自设置k。表1显示了我们在ImageNet上使用的确切网络配置。</span></p> 
         <h3 style="margin-left:0px;text-align:left;"><span style="color:#fe2c24;"><strong>精读</strong></span></h3> 
         <p style="margin-left:0;text-align:left;">现在假设有输入图像X0，网络有L层，每层实现非线性变换Hℓ(⋅)，ℓ表示第几层。这里的Hℓ(⋅)是复合函数，也就是可以包含BN层、ReLU、Pooling或者Conv等操作。我们将第ℓ 层的输出表示为Xℓ 。</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#38d8f0;">（1）计算方式</span></h4> 
         <p style="margin-left:0;text-align:left;"><span style="color:#1c7331;"><strong>传统网络</strong></span></p> 
         <p style="margin-left:0;text-align:left;">&nbsp;最原始的前馈卷积神经网络，将第ℓ层的输出作为第ℓ+1层的输入。</p> 
         <p style="margin-left:0;text-align:left;"><strong>&nbsp;公式：</strong>&nbsp;Xℓ =Hℓ (Xℓ −1)</p> 
         <p style="margin-left:0;text-align:left;"><span style="color:#e6b223;"><strong>ResNet</strong></span></p> 
         <p style="margin-left:0;text-align:left;">&nbsp; ResNet除了本层与下一层的连接之外添加了一个短路连接，即将ℓ 层和ℓ -1层的输出共同作为ℓ +1&nbsp; 层的输入: 也就是说第 ℓ 层会从它之前的所有层中接受特征图。</p> 
         <p style="margin-left:0;text-align:left;"><strong>&nbsp; 公式：</strong>&nbsp;Xℓ =Hℓ (Xℓ−1 )+Xℓ−1 ​</p> 
         <p style="margin-left:0;text-align:left;">&nbsp; 优点：梯度可以直接通过Identity函数从后面的层流到前面的层。</p> 
         <p style="margin-left:0;text-align:left;">&nbsp; 缺点：Identity函数和Hℓ的输出通过求和相结合，可能会阻碍网络中的信息流。</p> 
         <p style="margin-left:0;text-align:left;"><span style="color:#9c8ec1;"><strong>Dense connectivity</strong></span></p> 
         <p style="margin-left:0;text-align:left;">&nbsp; &nbsp;DenseNet则是让ℓ层的输入直接影响到之后的所有层，并且由于每一层都包含之前所有层的输出信息，因此其只需要很少的特征图就够了，这也是为什么DenseNet的参数量较其他模型大大减少的原因。</p> 
         <p style="margin-left:0;text-align:left;"><strong>&nbsp; 公式：</strong>&nbsp;Xℓ =Hℓ ([X0 ​ ,X1 ​ ,⋯,Xℓ−1 ​ ])</p> 
         <p style="margin-left:0;text-align:left;">&nbsp; [X0,X1,...]表示将第0,1..(ℓ-1)层的特征图进行组合.</p> 
         <hr> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#a2e043;">（2）网络结构</span></h4> 
         <p style="margin-left:0;text-align:left;">DenseNet的网络结构主要由<span style="color:#fe2c24;">Dense Block＋Transition</span>组成</p> 
         <p style="margin-left:0;text-align:left;"><strong>DenseBlock（定义了输入输出如何连接）</strong>&nbsp;是包含很多层的模块，每个层的特征图大小相同，层与层之间采用稠密连接方式。</p> 
         <p style="margin-left:0;text-align:left;"><strong>Transition模块（控制通道数）</strong>&nbsp;是连接两个相邻的Dense Block，并且通过Pooling使特征图大小降低。</p> 
         <p style="margin-left:0;text-align:left;"></p> 
         <h4 style="margin-left:0px;text-align:left;"><strong><span style="background-color:#ffd900;">Dense Block</span></strong></h4> 
         <p style="margin-left:0;text-align:left;"><strong><span style="color:#faa572;">Composite function—复合功能</span></strong></p> 
         <p style="margin-left:0;text-align:left;">为了方便，我们将Hℓ(⋅)定义为三个连续操作的符合函数：<span style="color:#fe2c24;">BN+ReLU+一个3×3的Conv</span></p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="277" src="https://i-blog.csdnimg.cn/blog_migrate/fb1d48687d16839971c1a051ea5c1054.png" width="502"></p> 
         <p><strong><span style="color:#79c6cd;">&nbsp;Growth rate—增长率</span></strong></p> 
         <p style="margin-left:0;text-align:left;">假定输入层的特征图的channel数为k0，Dense Block中各个层卷积之后均输出K个特征图，即得到的特征图的channel数为K，那么ℓ层输入的channel数为K0​+(ℓ−1)K, 我们将K称之为网络的增长率（growth rate）</p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="257" src="https://i-blog.csdnimg.cn/blog_migrate/5b5bb62ce036840c6009ffffc28bf508.png" width="495"></p> 
         <p><strong>&nbsp;解释：</strong>每一层都可以访问其块中的所有前面的特征图，即可以访问网络的全局知识。可以将特征图视为网络的全局状态，每一层都将自己的K个特征图添加到全局状态中。增长率控制了每一层向全局状态贡献的新信息的数量。一旦写入全局状态，就可以从网络中的任何地方访问它，并且与传统的网络体系结构不同，无需将其逐层复制。</p> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q：为什么DenseNet参数量很少，在有限卷积个数通过特征重用也能够有大量的特征数？</span></p> 
          <p style="margin-left:0;text-align:left;">因为Dense连接的缘故，每个块的输出channel都是固定为K的，但是输出channel却在不断变多。每个块的卷积的个数都可以固定为K，而不用像其他网络指定卷积核的个数为128、256、512、1024等特别多。</p> 
         </blockquote> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#dad5e9;">Bottleneck层</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong><span style="color:#6eaad7;">Bottleneck layers—瓶颈层</span></strong></p> 
         <p style="margin-left:0;text-align:left;"><strong>目的：</strong>尽管每个层（H(⋅)）都只能产生K个输出特征，但是因为累计原因输入特征却有很多。由于后面层的输入会非常大，Dense Block内部可以采用bottleneck层来减少计算。</p> 
         <p style="margin-left:0;text-align:left;"><strong>方法：</strong>可以在每个3×3卷积之前引入1×1卷积作为bottleneck层，以减少输入特征映射的数量，从而提高计算效率。即Hℓ()中包含的操作<span style="color:#fe2c24;">BN＋Relu＋1×1conv＋BN＋Relu＋3×3conv</span>，把这样的网络结构叫做<strong>DenseNet-B</strong>。</p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="183" src="https://i-blog.csdnimg.cn/blog_migrate/88a23eb97b862d3de2e583ec060b27e7.png" width="541"></p> 
         <p></p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#79c6cd;">Transition层</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong><span style="color:#e6b223;">Pooling layers—池化层</span></strong></p> 
         <p style="margin-left:0;text-align:left;"><strong>原因：</strong>特征图在各层的尺寸不同，不能直接concat。如果直接横跨整个也确实不方便。</p> 
         <p style="margin-left:0;text-align:left;"><strong>方法：</strong>将DenseNet划分为多个Dense Blocks，而块之间的称为<strong>转换层</strong>，用于卷积和池化，在本文中<span style="color:#fe2c24;">转换层=BN+1×1Conv+2×2AveragePooling</span></p> 
         <p style="margin-left:0px;text-align:center;"><span style="color:#fe2c24;"><img alt="" height="125" src="https://i-blog.csdnimg.cn/blog_migrate/b626b419aadf20467aace9ce01efb483.png" width="600"></span></p> 
         <p><span style="color:#be191c;"><strong>&nbsp;Compression—压缩</strong></span></p> 
         <p><strong>目的：</strong>为了进一步提高模型的紧凑性，可以减少转换层的特征图数量。</p> 
         <p><strong>方法：</strong>引入一个压缩因子θ(0 &lt; θ ≤1)，当θ=1时转换层的输入和输出特征数不变，也就是经过转换层后特征数不变；当θ &lt;1时，输入特征图数为m时，输出为⌊θm⌋。将θ&lt;1的DenseNet称为<strong>DenseNet-C</strong>&nbsp;（在实验中我们设置θ=0.5）。</p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <p style="margin-left:0;text-align:left;">将Dense Block+bottleneck+Translation的模型称为<strong>DenseNet-BC</strong></p> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q：DenseNet-B已经压缩了，为啥还要提出个DenseNet-C?</span></p> 
          <p style="margin-left:0;text-align:left;">瓶颈层是指用于dense block内的H(⋅)压缩，而压缩是指在转换层进行压缩。</p> 
         </blockquote> 
         <hr> 
         <h4><span style="background-color:#ff9900;">（3）Implementation Details—实施细节</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>实验操作</strong></p> 
         <ul>
          <li style="margin-left:0px;text-align:left;">在进入第一个Dense Block时，对输入图像进行16（或为DenseNet-BC增长率的两倍）输出通道的卷积</li>
          <li style="margin-left:0px;text-align:left;">对于3x3卷积，使用zero-padding，以保证特征图的大小不变</li>
          <li style="margin-left:0px;text-align:left;">使用1x1卷积＋2x2平均池化作为两个Dense Block的转换层</li>
          <li style="margin-left:0px;text-align:left;">在最后一个Dense Block的末端，执行一个全局平均池化＋一个softmax分类器。</li>
         </ul> 
         <p style="margin-left:0;text-align:left;"><strong>实验数据</strong></p> 
         <p style="margin-left:0;text-align:left;">DenseNet共包含三个Dense Block，各个模块的特征图大小分别为 32 × 32，16×16和8×8，每个Dense Block里面的层数相同（Dense Block本身不会改变特征图尺寸，所以是转换层导致的尺寸变化）</p> 
         <p style="margin-left:0;text-align:left;">在这几个基础DenseNet上实验：</p> 
         <ul>
          <li style="margin-left:0px;text-align:left;">L = 40 ， K = 12</li>
          <li style="margin-left:0px;text-align:left;">L = 100 ，K = 12</li>
          <li style="margin-left:0px;text-align:left;">L = 100 ，K = 24</li>
         </ul> 
         <p style="margin-left:0;text-align:left;">对于DenseNet-BC：</p> 
         <ul>
          <li style="margin-left:0px;text-align:left;">L = 100 ， K = 12</li>
          <li style="margin-left:0px;text-align:left;">L = 250 ， K = 24</li>
          <li style="margin-left:0px;text-align:left;">L = 190 ， K = 40</li>
         </ul> 
         <p style="margin-left:0;text-align:left;"><strong>实验图示</strong></p> 
         <p style="margin-left:0;text-align:left;">在ImageNet上的实验中，使用了DenseNet-BC结构，它包含4个Dense Blocks。初始卷积层包括大小为7×7的卷积，步长为2。详细网络配置如下表所示。</p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="272" src="https://i-blog.csdnimg.cn/blog_migrate/7cb083ed2b9779ac387973300edf0d3a.png" width="575"></p> 
         <hr> 
         <h4><span style="background-color:#ed7976;">&nbsp;（4）DenseNet的优势</span></h4> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <p style="margin-left:0;text-align:left;">（1）需要更少的参数，DenseNet结构明确区分了添加到网络的信息和保留的信息，不需要重新学习冗余的特征图。</p> 
         <p style="margin-left:.0001pt;text-align:center;"><img alt="" height="401" src="https://i-blog.csdnimg.cn/blog_migrate/77e78e1d9fa447cbf5815a7cdeecde5f.png" width="530"></p> 
         <p style="text-align:center;">&nbsp;（2）改善了整个网络中的信息流和梯度，由于稠密连接方式，DenseNet提升了梯度的反向传播，使得网络更容易训练。每一层都可以直接访问损失函数和初始输入的梯度，减轻梯度消失现象<img alt="" height="152" src="https://i-blog.csdnimg.cn/blog_migrate/0a39cc722d86d439d1741df79a903824.png" width="472"></p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <p style="margin-left:0px;">（3）密集链接具有正则化效应，保存了低维度的特征，可以减少训练集规模较小的任务的过拟合风险。</p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="310" src="https://i-blog.csdnimg.cn/blog_migrate/8b26b5e7dc2519e79439b1630c011d04.png" width="546"></p> 
         <hr> 
         <h2 style="margin-left:0px;text-align:left;"><strong>四、Experiments—实验</strong></h2> 
         <h3>4.1. Datasets—数据集</h3> 
         <h3><span style="color:#4da8ee;"><strong>翻译</strong></span></h3> 
         <p><strong>CIFAR. </strong>两个CIFAR数据集【15】包含32×32像素的彩色自然图像。CIFAR-10（C10）包含从10类和100种CIFAR-100（C100）中绘制的图像。训练集和测试集分别包含50,000张和10,000张图像，我们保留5,000张训练图像作为验证集。我们采用了标准的数据扩展方案（镜像/移位），该方案被广泛用于这两个数据集【11、13、17、22、28、20、32、34】。我们在数据集名称（例如C10 +）的末尾用“ +”号表示此数据扩充方案。对于预处理，我们使用通道均值和标准偏差对数据进行归一化。对于最终运行，我们使用所有50,000张训练图像，并在训练结束时报告最终测试错误。</p> 
         <p><strong>SVHN.</strong> 街景门牌号码（SVHN）数据集[24]包含32×32彩色数字图像。训练集中有73,257张图像，测试集中有26,032张图像，其他训练有531,131张图像。遵循常规做法[7、13、20、22、30]，我们使用所有训练数据，不进行任何数据扩充，并从训练集中分割出具有6,000个图像的验证集。我们选择训练期间验证误差最小的模型，并报告测试误差。我们遵循[42]并将像素值除以255，因此它们在[0,1]范围内。</p> 
         <p><strong>ImageNet. </strong>ILSVRC 2012分类数据集[2]包含来自1,000个类别的120万张用于训练的图像和50,000张用于验证的图像。我们采用与[8、11、12]中相同的数据增强方案来训练图像，并在测试时应用大小为224×224的单作物或10作物。根据[11，12，13]，我们报告验证集的分类错误。</p> 
         <h3><span style="color:#fe2c24;"><strong>精读</strong></span></h3> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#38d8f0;">CIFAR</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>介绍：</strong>32x32的彩色图。CIFAR-10(C10)是10类，CIFAR-100(C100)是100类。训练集50000、测试集10000，训练集中选5000为验证集。</p> 
         <p style="margin-left:0;text-align:left;"><strong>数据集增强：</strong>采用广泛应用于这两个数据集的标准数据增强方法—（翻转+随机裁剪）</p> 
         <p style="margin-left:0;text-align:left;"><strong>预处理：</strong>使用各通道的均值和标准差对数据进行归一化。</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#ffd900;">SVHN</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>介绍：</strong>一个类似于MNIST的街道门牌号数字识别数据集。32x32的彩色图。训练集73257，测试集26032，有531131张作为额外的训练。训练集中选取6000为验证集。</p> 
         <p style="margin-left:0;text-align:left;"><strong>预处理：</strong>将像素值除以255，使它们在[0,1]范围内</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#a2e043;">ImageNet</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>介绍：</strong>目前世界上图像识别最大的数据库。ILSVARC 2012分类数据集有1.2百万张训练集，50000张验证集，共1000类。</p> 
         <p style="margin-left:0;text-align:left;"><strong>测试图片：</strong>使用尺寸为224*224的single-crop和10-crop</p> 
         <hr> 
         <h3 style="margin-left:0px;text-align:left;">4.2. Training—训练</h3> 
         <h3 style="margin-left:.0001pt;text-align:left;"><span style="color:#4da8ee;">翻译</span></h3> 
         <p><span style="color:#0d0016;">所有网络均使用随机梯度下降（SGD）进行训练。在CIFAR和SVHN上，我们使用批量大小64 分别训练300和40个 epochs 。初始学习率设置为0.1，然后除以训练时期总数的50％和75％的10。在ImageNet上，我们训练了90个 epoch 的模型，批量大小为256。最初将学习率设置为0.1，然后在epoch 30和60的时候降低10倍。请注意，DenseNet的简单实现可能会导致内存效率低下。要减少GPU上的内存消耗，请参阅我们关于DenseNets的内存高效实现的技术报告【26】。</span></p> 
         <p><span style="color:#0d0016;">根据【8】，我们使用<img alt="10^{-4}" class="mathcode" src="https://latex.csdn.net/eq?10%5E%7B-4%7D">的权重衰减和0.9的奈斯特洛夫动量【35】而没有衰减。我们采用【10】引入的权重初始化。对于没有数据增强的三个数据集，即C10，C100和SVHN，我们在每个卷积层（第一个卷积层除外）之后添加一个dropout 层【33】，并将dropout 概率设置为0.2。对于每个任务和模型设置，仅对测试错误进行一次评估。</span><br><strong>精读</strong></p> 
         <h4 style="margin-left:0px;text-align:left;"><strong><span style="background-color:#38d8f0;">CIFAR和SVHN</span></strong></h4> 
         <p style="margin-left:0;text-align:left;"><strong>batchsize：</strong>64。</p> 
         <p style="margin-left:0;text-align:left;"><strong>epochs：</strong>分别训练300轮、40轮</p> 
         <p style="margin-left:0;text-align:left;"><strong>初始学习率：</strong>0.1，分别在训练总轮数的50%和75%时，学习率变为原来的0.1</p> 
         <h4 style="margin-left:0px;text-align:left;"><strong><span style="background-color:#ffd900;">ImageNet</span></strong></h4> 
         <p style="margin-left:0;text-align:left;"><strong>batchsize：</strong>256</p> 
         <p style="margin-left:0;text-align:left;"><strong>epochs：</strong>训练90轮</p> 
         <p style="margin-left:0;text-align:left;"><strong>初始学习率：</strong>0.1，在30和40轮学习率分别变为原来的0.1</p> 
         <p style="margin-left:0;text-align:left;">另外：受GPU的内存的限制，最大的模型(DenseNet-161)的batchsize=128。训练100轮并在90轮将学习率变为原来的0.1</p> 
         <p style="margin-left:0;text-align:left;"><strong>优化器：</strong>SGD</p> 
         <p style="margin-left:0;text-align:left;"><strong>权重衰减：</strong><span style="color:#0d0016;"><img alt="10^{-4}" class="mathcode" src="https://latex.csdn.net/eq?10%5E%7B-4%7D"></span></p> 
         <p style="margin-left:0;text-align:left;"><strong>动量：</strong>0.9</p> 
         <p style="margin-left:0;text-align:left;"><strong>Droupout：</strong>对于三种没有使用数据增强的数据，如C10、C100和SVHN，在每个卷积层（除了第一层）之后增加了一层dropout层，并且设置失活率为0.2</p> 
         <hr> 
         <h3 style="margin-left:0px;text-align:left;">4.3. Classification Results on CIFAR and SVHN—CIFAR和SVHN的分类结果</h3> 
         <h3 style="margin-left:.0001pt;text-align:left;"><span style="color:#4da8ee;">翻译</span></h3> 
         <p><span style="color:#0d0016;">我们使用不同的深度 L 和 增长率 k 来训练 DenseNet 。表2显示了CIFAR和SVHN的主要结果。为了突出总体趋势，我们将所有结果标记为优于现有的最新粗体显示，而总体最佳结果显示为蓝色。</span></p> 
         <p><span style="color:#0d0016;"><strong>准确性. </strong>可能最明显的趋势可能来自表2的最后一行，这表明在所有CIFAR数据集上，L = 190和k = 40的DenseNet-BC均优于现有的最新技术。它在C10 +上的错误率为3.46％，在C100 +上的错误率为17.18％，远低于广泛的ResNet架构所实现的错误率【42】。我们在C10和C100上获得的最佳结果（不进行数据增强）甚至更令人鼓舞：两者均比使用分路路径正则化的Fractal-Net低近30％【17】。在SVHN上，具有 dropout 层的时候，L = 100andk = 24的DenseNet也超过了广泛的ResNet所获得的当前最佳结果。但是，250层的DenseNet-BC不能比较短的DenseNet-BC进一步提高性能。可以用SVHN解释这是一个相对容易的任务，而极深的模型可能会过拟合训练集。</span></p> 
         <p><span style="color:#0d0016;"><strong>容量</strong>. 在没有压缩或瓶颈层的情况下，DenseNets的总体趋势是随着L 和 k 的增加而表现更好。我们将此主要归因于模型容量的相应增长。这个通过C10 +和C100 +列更好的进行了演示。在C10 +上，随着参数数量从1.0M增加到7.0M到27.2M，错误从5.24％下降到4.10％，最后下降到3.74％。在C100 +上，我们观察到了类似的趋势。这表明DenseNets可以利用更大和更深层模型的增强表示能力。这也表明它们没有残留网络的过度拟合或优化困难【11】。</span></p> 
         <p><span style="color:#0d0016;"><strong>参数效率.</strong> 表2中的结果表明，DenseNets比其他体系结构（尤其是ResNets）更有效地利用参数。具有瓶颈结构并在过渡层减小尺寸的DenseNet-BC特别有效。例如，我们的250层模型仅具有1530万个参数，但始终优于其他具有超过3000万个参数的模型（例如FractalNet和Wide ResNets）。我们还着重指出，L = 100和k = 12的DenseNet-BC的性能（例如，C10 +的误差为4.51％vs 4.62％，C100 +的误差为22.27％vs 22.71％）可与使用90％的参数的1001层预激活ResNet媲美。</span></p> 
         <p><span style="color:#0d0016;"><strong>过度拟合. </strong>更有效地使用参数的一个积极副作用是DenseNets不太容易过度拟合。我们观察到，在不进行数据扩充的数据集上，DenseNet体系结构相对于先前工作的改进尤其明显。在C10上，改善表示相对误差降低了29％，从7.33％降低到5.19％。在C100上，减少幅度约为30％，从28.20％降至19.64％。在我们的实验中，我们观察到了在单个设置中的潜在过度拟合：在C10上，通过将k = 12增加到k = 24产生的参数的4倍增长导致误差从5.77％到5.83％的适度增加。DenseNet-BC瓶颈和压缩层似乎是应对这种趋势的有效方法。</span></p> 
         <h3 style="margin-left:.0001pt;text-align:left;"><span style="color:#fe2c24;">精读</span></h3> 
         <p style="margin-left:0;text-align:left;">我们使用不同的深度 L 和 增长率 k 来训练 DenseNet 。表2显示了CIFAR和SVHN的主要结果。为了突出总体趋势，粗体代表超越以往最佳，蓝色代表最佳结果。</p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="349" src="https://i-blog.csdnimg.cn/blog_migrate/fdfc1045fab2590dd525c2133ff0f477.png" width="534"></p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#38d8f0;">Accuracy—准确率</span></h4> 
         <ul>
          <li style="margin-left:0px;text-align:left;">【CIFAR】表格最后一行，L=190、k=40的DenseNet-BC网络的结果，性能超过先存在的所有模型</li>
          <li style="margin-left:0px;text-align:left;">【SVHM】L=100、k=24的DenseNet(使用dropout)也远超wideResNet的最好结果。但是250层DenseNet-BC并没有进一步改善性能，分析是因为SVHM是一个相对容易的任务，过深的模型可能会过拟合。</li>
         </ul> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#a2e043;">Capacity—容量</span></h4> 
         <p style="margin-left:0;text-align:left;">在没有压缩或瓶颈层的情况下，DenseNets的总体趋势是随着L 和 k 的增加而表现更好。我们将此主要归因于模型容量的相应增长。</p> 
         <p style="margin-left:0;text-align:left;">这表明DenseNets可以利用更大和更深层模型的增强表示能力。这也表明它们没有残留网络的过度拟合或优化困难</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#ffd900;">Parameter Efficiency—参数效率</span></h4> 
         <p style="margin-left:0;text-align:left;">DenseNets比其他体系结构（尤其是ResNets）更有效地利用参数。具有瓶颈结构并在转换层减小尺寸的DenseNet-BC特别有效。</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#dad5e9;">Overfitting—过拟合</span></h4> 
         <p style="margin-left:0;text-align:left;">DenseNet-BC的压缩和瓶颈层是抑制过拟合趋势的有效方式</p> 
         <hr> 
         <h3 style="margin-left:.0001pt;text-align:left;">4.4. Classification Results on ImageNet—ImageNet上的分类结果</h3> 
         <h3 style="margin-left:.0001pt;text-align:left;"><span style="color:#4da8ee;">翻译</span></h3> 
         <p><span style="color:#0d0016;">我们在ImageNet分类任务中评估了具有不同深度和增长率的DenseNet-BC，并将其与最新的ResNet架构进行了比较。为了确保两种架构之间的公平比较，我们采用了【8】的ResNet采用公开可用的Torch实施方案，从而消除了所有其他因素，例如数据预处理和优化设置的差异。我们仅用DenseNet-BC网络替换ResNet模型，并使所有实验设置与用于ResNet的设置完全相同。</span></p> 
         <p><span style="color:#0d0016;">我们在表3中报告了ImageNet上DenseNets的单次裁剪和10次裁剪验证错误。图3显示了DenseNets和ResNets的top-1验证错误与参数数量（左）和FLOP（右）的关系。图中的结果表明，DenseNets的性能与最新的ResNets相当，而所需的参数和计算量却大大减少，以实现可比的性能。例如，具有20M参数模型的DenseNet-201产生的验证错误与参数超过40M的101层ResNet产生相似的验证错误。从右面板可以观察到类似的趋势，该图将验证误差绘制为FLOP数量的函数：DenseNet的计算量与ResNet-50相当，而ResNet-101的计算量却是ResNet-50的两倍。</span></p> 
         <p><span style="color:#0d0016;">值得注意的是，我们的实验设置暗示我们使用针对ResNets优化的超参数设置，但不适用于DenseNets。可以想象，更广泛的超参数搜索可以进一步提高DenseNet在ImageNet上的性能。</span></p> 
         <h3 style="margin-left:.0001pt;text-align:left;"><span style="color:#fe2c24;">精读</span></h3> 
         <p style="margin-left:0;text-align:left;">采用了ResNet公开可用的Torch实施方案，从而消除了所有其他因素，例如数据预处理和优化设置的差异。我们仅用DenseNet-BC网络替换ResNet模型，并使所有实验设置与用于ResNet的设置完全相同。</p> 
         <p style="margin-left:.0001pt;text-align:center;"><img alt="" height="177" src="https://i-blog.csdnimg.cn/blog_migrate/4465bea5d2da72ee30e884f0f0086781.png" width="610"></p> 
         <p style="margin-left:0;text-align:left;">从上面的折线图可以看出，两种网络在同等误差率时，DenseNet-BC比Resnet有更低的参数和计算量。&nbsp;</p> 
         <hr> 
         <h2></h2> 
         <h2 style="margin-left:0px;text-align:left;"><strong>五、Discussion—讨论</strong></h2> 
         <h3 style="margin-left:0px;text-align:left;"><span style="color:#4da8ee;">翻译</span></h3> 
         <p><span style="color:#0d0016;">从表面上看，DenseNets与ResNets非常相似：ResNets：等式（2）不同于式（1）仅在于将<img alt="H_{l}\left ( \cdot \right )" class="mathcode" src="https://latex.csdn.net/eq?H_%7Bl%7D%5Cleft%20%28%20%5Ccdot%20%5Cright%20%29">的输入串联起来而不是求和。但是，这种看似很小的修改的含义导致两种网络体系结构的行为实质上不同。</span></p> 
         <p><span style="color:#0d0016;"><strong>模型紧凑度</strong> 输入级联的直接结果是，所有随后的层都可以访问通过DenseNet层中的任何一层学习的特征图。这鼓励了整个网络中功能的重用，并导致了更紧凑的模型。图4的左两图显示了一个实验的结果，该实验旨在比较DenseNets所有变体的参数效率（左）和可比较的ResNet体系结构（中）。我们在C10 +上训练多个具有不同深度的小型网络，并绘制它们的测试精度作为网络参数的函数。与其他流行的网络体系结构（例如AlexNet [16]或VGG-net [29]）相比，具有预激活功能的ResNet使用较少的参数，而通常可以获得更好的结果[12]。因此，我们将DenseNet（k = 12）与该架构进行比较。DenseNet的培训设置与上一节相同。</span></p> 
         <p><span style="color:#0d0016;"><strong>隐式深度监督</strong> 密集卷积网络精度提高的一种解释可能是各个层通过较短的连接而受到损耗函数的额外监视。可以解释DenseNets来执行一种“深度监督”。深度监督的好处以前已经在深度监督的网络（DSN; [20]）中得到了证明，该网络的每个隐含层都有分类器，从而迫使中间层学习判别特征。</span></p> 
         <p><span style="color:#0d0016;"><strong>DenseNets以隐式方式执行类似的深度监控</strong>：网络顶部的单个分类器通过最多两个或三个过渡层对所有层提供直接监控。但是，DenseNets的损失函数和梯度实际上不那么复杂，因为在所有层之间共享相同的损失函数。</span></p> 
         <p><span style="color:#0d0016;"><strong>随机 vs 确定连接</strong> 密集卷积网络与剩余网络的随机深度正则化之间存在有趣的联系[13]。在随机深度中，残留网络中的各层会随机掉落，从而在周围各层之间建立直接连接。由于池化层从未被丢弃，因此网络会产生与DenseNet类似的连接模式：如果所有中间层都被随机丢弃，则在同一池化层之间的任何两层都将直接连接的可能性很小。尽管这些方法最终会完全不同，但是DenseNet对随机深度的解释可能会为这种正则化工具的成功提供见识。</span></p> 
         <p><span style="color:#0d0016;"><strong>特征重用</strong> 根据设计，DenseNets允许各层访问其先前所有层的特征图（尽管有时通过过渡层）。我们进行了一项实验，以调查受过训练的网络是否利用了这一机会。我们首先在C10 +上训练DenseNet，L = 40 并且 k = 12。对于一个块内的每个卷积层L，我们计算分配给各层连接的平均（绝对）权重。图5显示了所有三个密集块的热图。平均绝对重量用作卷积层与其先前层之间依赖性的替代。位置（L，S）中的红点表示，平均而言，层L充分利用了之前生成的S层的特征图。可以从图中得出几个观察结果：</span></p> 
         <ol>
          <li><span style="color:#0d0016;">所有层将权重分布在同一块内的许多输入上。这表明，由非常早的层提取的特征确实确实被深层在同一密集块中直接使用。</span></li>
          <li><span style="color:#0d0016;">过渡层的权重也将其权重分布在前一个密集块内的所有层上，指示信息通过少量间接从DenseNet的第一层流向最后一层。</span></li>
          <li><span style="color:#0d0016;">第二个和第三个密集块内的层始终将最小的权重分配给过渡层（三角形的最上一行）的输出，表明过渡层输出许多冗余特征（平均权重较低）。这与DenseNet-BC的出色结果保持了一致，这些输出正是经过压缩的。</span></li>
          <li><span style="color:#0d0016;">尽管最右边显示的最终分类层也使用了整个密集块的权重，但似乎对最终特征图的关注程度很高，这表明网络后期可能会产生一些更高级的特征</span></li>
         </ol> 
         <h3 style="margin-left:0px;text-align:left;"><span style="color:#fe2c24;">精读</span></h3> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#38d8f0;">Model compactness—模型紧凑度</span></h4> 
         <p style="margin-left:0;text-align:left;">输入连接的一个直接结果是，任何DenseNet层学习到的特征图都可以被随后的所有层访问。这鼓励在整个网络中重用特性，并导致更紧凑的模型。</p> 
         <p style="margin-left:0;text-align:left;">图4的左两图显示了一个实验的结果，该实验旨在比较DenseNets所有变体的参数效率（左）和可比较的ResNet体系结构（中）。</p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="223" src="https://i-blog.csdnimg.cn/blog_migrate/c5cccb5f63d902e3d5dab74fb13e0da4.png" width="534"></p> 
         <p>从图中可以看出，为了达到同样的精度水平，DenseNet-BC只需要ResNets(中间图)大约1/3的参数。</p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <p style="margin-left:0;text-align:left;">图4中的右图显示，仅具有0.8M可训练参数的DenseNet-BC能够达到与具有10.2M参数的1001层（预激活）ResNet 相当的精度。</p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" src="https://i-blog.csdnimg.cn/blog_migrate/72097e57bbf51bc04aedd344295e87c7.png"></p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#a2e043;">Implicit Deep Supervision—隐式深度监督</span></h4> 
         <p style="margin-left:0;text-align:left;">稠密连接使每一层到达最终输出，都有快速通道（通道上会有少量的转换层），每一层都可以从损失函数中获得监督信息（理解为一种“深度监督”），迫使中间层也学习判断特征。</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#ffd900;">Stochastic vs. deterministic connection—随机 vs 确定连接</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>残差网络的随机深度正则化：</strong>在深度随机中，残差网络随机丢弃一些层，让该层前后层直接相连，池化层保留。</p> 
         <p style="margin-left:0;text-align:left;"><strong>DenseNet：</strong>模块内部的稠密连接，使每两层之间都存在直连通道。两种方式，都起到了正则效果</p> 
         <h4 style="margin-left:0px;text-align:left;"><span style="background-color:#ff9900;">Feature Reuse—特征重用</span></h4> 
         <p style="margin-left:0;text-align:left;"><strong>原理：</strong>DenseNets允许各层获得之前的所有层(尽管有时通过转换层)的feature map</p> 
         <p style="margin-left:0;text-align:left;"><strong>设计实验：</strong>做一个实验来判断训练的网络是否有效的特征复用：在C10+数据上训练了L=40、k=12的DenseNet。block内部的每个卷积 l，我们计算与其s层连接的平均权重。三个dense block的热量图如下图：</p> 
         <p style="margin-left:0px;text-align:center;"><img alt="" height="289" src="https://i-blog.csdnimg.cn/blog_migrate/79ff3d5194c59259468d59f1fee41fb6.png" width="595"></p> 
         <p>&nbsp;<strong>结论：</strong></p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
         <ol>
          <li style="margin-left:0px;text-align:left;">在同一个block中，所有层都将它的权重传递给前面层作为输入。这表明：block内部，每个浅层的特征会被高层卷积不同程度上的成功利用；</li>
          <li style="margin-left:0px;text-align:left;">转换层的权重也可以传递给前面的dense block的所有层。这表明：信息从DenseNet的第一层到最后一层通过很少的间接流动；</li>
          <li style="margin-left:0px;text-align:left;">第二个和第三个dense block内的所有层分配最少的权重给转换层的输出，这表明：转换层输出很多冗余特征；</li>
          <li style="margin-left:0px;text-align:left;">第三个分类器也使用通过整个dense block的权重，但更关注最后的特征图，这表明：网络的最后也会产生一些高级的特征。</li>
         </ol> 
         <hr> 
         <h2 style="margin-left:0px;text-align:left;"><strong>六、Conclusion—总结</strong></h2> 
         <h3><span style="color:#4da8ee;"><strong>翻译</strong></span></h3> 
         <p><span style="color:#0d0016;">我们提出了一种新的卷积网络架构，我们称之为密集卷积网络（DenseNet）。它引入了具有相同要素图大小的任何两个图层之间的直接连接。我们表明，DenseNets自然可以扩展到数百层，而没有任何优化困难。在我们的实验中，随着参数数量的增加，DenseNets往往会不断提高精度，而不会出现性能下降或过度拟合的迹象。在多个环境下，它在多个高度竞争的数据集上均取得了最先进的结果。此外，DenseNets需要更少的参数和更少的计算来实现最新性能。由于我们在研究中采用了针对残留网络优化的超参数设置，因此我们认为，可以通过更详细地调整超参数和学习率时间表来进一步提高DenseNets的准确性。</span></p> 
         <p><span style="color:#0d0016;">在遵循简单的连接规则的同时，DenseNets自然地集成了身份映射，深度监督和多样化深度的属性。它们允许在整个网络中重复使用功能，因此可以学习更紧凑的模型，并且根据我们的实验，可以得到更准确的模型。由于其紧凑的内部表示形式和减少的功能冗余，DenseNets可能是基于卷积特征（例如[4、5]）的各种计算机视觉任务的良好特征提取器。我们计划在以后的工作中使用DenseNets研究这种特征转移。</span></p> 
         <h3><span style="color:#fe2c24;">精读</span></h3> 
         <p>本文提出了一种新的卷积神经网络结构，命名为DenseNet。提出了将网络中相同特征图大小的任意两层直接相连，在多个数据集上达到了最佳效果。</p> 
         <p>DenseNet主要有如下优点：</p> 
         <ol>
          <li>省参数：达到同样的准确率需要更少的参数量；</li>
          <li>省计算：较少的参数，更高的计算效率；</li>
          <li>抗过拟合：由于参数重用性大， 所以拥有一定的抗过拟合性能；</li>
          <li>由于密集连接的存在，减缓了梯度消失问题，增强了信息的传播。&nbsp;</li>
          <li>缺陷：特别消耗显存！</li>
         </ol> 
         <hr> 
         <h2 style="margin-left:0px;text-align:left;"><strong>论文十问</strong></h2> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q1：论文试图解决什么问题？</span></p> 
          <p style="margin-left:0;text-align:left;">现阶段大量的网络参数，网络结构的利用率不高。本文提出了一种新的卷积神经网络结构，命名为DenseNet。提出了将网络中相同特征图大小的任意两层直接相连，在多个数据集上达到了最佳效果。</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q2：这是否是一个新的问题？</span></p> 
          <p style="margin-left:0;text-align:left;">不是，这是在ResNet基础上进一步进行优化</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q3：这篇文章要验证一个什么科学假设？</span></p> 
          <p style="margin-left:0;text-align:left;">它建立的是前面所有层与后面层的密集连接（dense connection）</p> 
          <p style="margin-left:0;text-align:left;">通过特征在channel上的连接来实现特征重用（feature reuse）。这些特点让DenseNet在参数和计算成本更少的情形下实现比ResNet更优的性能</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q4：有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？</span></p> 
          <p style="margin-left:0;text-align:left;">ResNet</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q5：论文中提到的解决方案之关键是什么？</span></p> 
          <p style="margin-left:0;text-align:left;">以前馈的方式，将每层与每层都连接起来</p> 
          <p style="margin-left:0;text-align:left;">特征重用</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q6：论文中的实验是如何设计的？</span></p> 
          <p style="margin-left:0;text-align:left;">在多个数据集上和原有的网络结构进行对比，比较分类结果</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q7：用于定量评估的数据集是什么？代码有没有开源？</span></p> 
          <p style="margin-left:0;text-align:left;">CIFAR10、100</p> 
          <p style="margin-left:0;text-align:left;">SVHN</p> 
          <p style="margin-left:0;text-align:left;">ImageNet</p> 
          <p style="margin-left:0;text-align:left;">有开源</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q8：论文中的实验及结果有没有很好地支持需要验证的科学假设？</span></p> 
          <p style="margin-left:0;text-align:left;">证明了，在三个数据集上的分类结果都取得了比以往更好的成绩</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q9：这篇论文到底有什么贡献？</span></p> 
          <p style="margin-left:0;text-align:left;">DenseNet不是从极深或极宽的架构中提取表征能力，而是通过特征重用来开发网络的潜力，引入了具有相同特征图大小的任意两层之间的直接连接，产生易于训练和高效的参数压缩模型。将不同层学习的feature-map串联起来，增加了后续层输入的变化，提高了效率。</p> 
         </blockquote> 
         <blockquote> 
          <p style="margin-left:0;text-align:left;"><span style="color:#ff9900;">Q10：下一步呢？有什么工作可以继续深入？</span></p> 
          <p style="margin-left:0;text-align:left;">（1）可以通过更详细地调整超参数和学习率时间表来进一步提高DenseNets的准确性。</p> 
          <p style="margin-left:0;text-align:left;">（2）训练时消耗内存。因为后面的特征要用到前面的特征，所以前面的特征会一直被保存在内存中，所以占用内存是很大的。</p> 
          <p style="margin-left:0;text-align:left;">（3）由于其紧凑的内部表示形式和减少的功能冗余，DenseNets可能是基于卷积特征的各种计算机视觉任务的良好特征提取器。我们计划在以后的工作中使用DenseNets研究这种特征转移。</p> 
         </blockquote> 
         <p></p> 
         <hr> 
         <p>代码复现：<a href="https://blog.csdn.net/weixin_43334693/article/details/128485184?spm=1001.2014.3001.5502" title="DenseNet代码复现＋超详细注释（PyTorch）">DenseNet代码复现＋超详细注释（PyTorch）</a></p> 
         <p>下期预告：SeNet</p> 
         <p style="margin-left:.0001pt;text-align:left;"></p> 
        </div> 
       </div> 
      </article>  
     </div> 
     <div class="directory-boxshadow-dialog" style="display:none;"> 
      <div class="directory-boxshadow-dialog-box"> 
      </div> 
      <div class="vip-limited-time-offer-box-new" id="vip-limited-time-offer-box-new"> 
       <img class="limited-img limited-img-new" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close-newWhite.png"> 
       <div class="vip-limited-time-top">
         确定要放弃本次机会？ 
       </div> 
       <span class="vip-limited-time-text">福利倒计时</span> 
       <div class="limited-time-box-new"> 
        <span class="time-hour"></span> 
        <i>:</i> 
        <span class="time-minite"></span> 
        <i>:</i> 
        <span class="time-second"></span> 
       </div> 
       <div class="limited-time-vip-box"> 
        <p> <img class="coupon-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/vip-limited-close-roup.png"> <span class="def">立减 ¥</span> <span class="active limited-num"></span> </p> 
        <span class="">普通VIP年卡可用</span> 
       </div> 
       <a class="limited-time-btn-new" href="https://mall.csdn.net/vip" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.9621&quot;}" data-report-query="spm=1001.2101.3001.9621">立即使用</a> 
      </div> 
     </div> 
     <div class="more-toolbox-new more-toolbar" id="toolBarBox"> 
      <div class="left-toolbox"> 
       <div class="toolbox-left"> 
        <div class="profile-box"> 
         <a class="profile-href" target="_blank" href="https://jrs0511.blog.csdn.net"><img class="profile-img" src="https://profile-avatar.csdnimg.cn/da983c398fca4f14a19ea48d137f6ca3_weixin_43334693.jpg!1"> <span class="profile-name"> 路人贾'ω' </span> </a> 
        </div> 
        <div class="profile-attend"> 
         <a class="tool-attend tool-bt-button tool-unbt-attend" href="javascript:;" data-report-view="{&quot;mod&quot;:&quot;1592215036_002&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4232&quot;,&quot;extend1&quot;:&quot;已关注&quot;}">已关注</a> 
         <a class="tool-item-follow active-animation" style="display:none;">关注</a> 
        </div> 
       </div> 
       <div class="toolbox-middle"> 
        <ul class="toolbox-list"> 
         <li class="tool-item tool-item-size tool-active is-like" id="is-like"> <a class="tool-item-href"> <img style="display:none;" id="is-like-imgactive-animation-like" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/tobarThumbUpactive.png" alt=""> <img class="isactive" style="display:none" id="is-like-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/like-active.png" alt=""> <img class="isdefault" style="display:block" id="is-like-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/like.png" alt=""> <span id="spanCount" class="count "> 42 </span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">点赞</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active is-unlike" id="is-unlike"> <a class="tool-item-href"> <img class="isactive" style="margin-right:0px;display:none" id="is-unlike-imgactive" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/unlike-active.png" alt=""> <img class="isdefault" style="margin-right:0px;display:block" id="is-unlike-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/unlike.png" alt=""> <span id="unlikeCount" class="count "></span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">踩</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active is-collection "> <a class="tool-item-href" href="javascript:;" data-report-click="{&quot;mod&quot;:&quot;popu_824&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4130&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img style="display:none" id="is-collection-img-collection" class="animation-dom active-animation" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/collect-active.png" alt=""> <img class="isdefault" id="is-collection-img" style="display:block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/collect.png" alt=""> <img class="isactive" id="is-collection-imgactive" style="display:none" src="https://csdnimg.cn/release/blogv2/dist/pc/img/newCollectActive.png" alt=""> <span class="count get-collection " data-num="161" id="get-collection"> 161 </span> </a> 
          <div class="tool-hover-tip collect"> 
           <div class="collect-operate-box"> 
            <span class="collect-text" id="is-collection"> 收藏 </span> 
           </div> 
          </div> 
          <div class="tool-active-list"> 
           <div class="text">
             觉得还不错? 
            <span class="collect-text" id="tool-active-list-collection"> 一键收藏 </span> 
            <img id="tool-active-list-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/collectionCloseWhite.png" alt=""> 
           </div> 
          </div> </li> 
         <li class="tool-item tool-item-size tool-active tool-item-comment"> 
          <div class="guide-rr-first"> 
           <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward01.png" alt=""> 
           <button class="btn-guide-known">知道了</button> 
          </div> <a class="tool-item-href go-side-comment" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.7009&quot;}"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/comment.png" alt=""> <span class="count"> 9 </span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">评论</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active tool-QRcode" data-type="article" id="tool-share"> <a class="tool-item-href" href="javascript:;" data-report-view="{&quot;spm&quot;:&quot;3001.4129&quot;,&quot;extra&quot;:{&quot;type&quot;:&quot;blogdetail&quot;}}"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/share.png" alt=""> <span class="count">分享</span> </a> 
          <div class="QRcode" id="tool-QRcode"> 
           <div class="share-bg-box"> 
            <div class="share-content"> 
             <a id="copyPosterUrl" data-type="link" class="btn-share">复制链接</a> 
            </div> 
            <div class="share-content"> 
             <a class="btn-share" data-type="qq">分享到 QQ</a> 
            </div> 
            <div class="share-content"> 
             <a class="btn-share" data-type="weibo">分享到新浪微博</a> 
            </div> 
            <div class="share-code"> 
             <div class="share-code-box" id="shareCode"></div> 
             <div class="share-code-text"> 
              <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/share/icon-wechat.png" alt="">扫一扫 
             </div> 
            </div> 
           </div> 
          </div> </li> 
         <li class="tool-item tool-item-size tool-active tool-item-reward"> <a class="tool-item-href" href="javascript:;" data-report-click="{&quot;mod&quot;:&quot;popu_830&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4237&quot;,&quot;dest&quot;:&quot;&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img class="isdefault reward-bt" id="rewardBtNew" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/reward.png" alt="打赏"> <span class="count">打赏</span> </a> 
          <div class="tool-hover-tip">
           <span class="text space">打赏</span>
          </div> </li> 
         <li class="tool-item tool-item-size tool-active is-more" id="is-more"> <a class="tool-item-href"> <img class="isdefault" style="margin-right:0px;display:block" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/more.png" alt=""> <span class="count"></span> </a> 
          <div class="more-opt-box"> 
           <div class="mini-box"> 
            <a class="tool-item-href" id="rewardBtNewHide" data-report-click="{&quot;spm&quot;:&quot;3001.4237&quot;,&quot;extra&quot;:&quot;{\&quot;type\&quot;:\&quot;hide\&quot;}&quot;}"> <img class="isdefault reward-bt" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/reward.png" alt="打赏"> <span class="count">打赏</span> </a> 
            <a class="tool-item-href" id="toolReportBtnHide"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/report.png" alt=""> <span class="count">举报</span> </a> 
           </div> 
           <div class="normal-box"> 
            <a class="tool-item-href" id="toolReportBtnHideNormal"> <img class="isdefault" src="https://csdnimg.cn/release/blogv2/dist/pc/img/toolbar/report.png" alt=""> <span class="count">举报</span> </a> 
           </div> 
          </div> </li> 
        </ul> 
       </div> 
       <div class="toolbox-right"> 
        <div class="tool-directory"> 
         <a class="bt-columnlist-show" data-id="12127342" data-free="true" data-description="AlexNet/VGG/Inception/ResNet/DenseNet/SENet/ReXtNet" data-subscribe="false" data-title="图像分类经典论文" data-img="https://i-blog.csdnimg.cn/blog_column_migrate/4cc3e83223e8d0023a6303cdd4658cce.png?x-oss-process=image/resize,m_fixed,h_224,w_224" data-url="https://blog.csdn.net/weixin_43334693/category_12127342.html" data-sum="9" data-people="375" data-price="0" data-hotrank="0" data-status="true" data-oldprice="0" data-join="false" data-studyvip="true" data-studysubscribe="false" data-report-view="{&quot;spm&quot;:&quot;1001.2101.3001.6334&quot;,&quot;extend1&quot;:&quot;专栏目录&quot;}" data-report-click="{&quot;spm&quot;:&quot;1001.2101.3001.6334&quot;,&quot;extend1&quot;:&quot;专栏目录&quot;}">专栏目录</a> 
        </div> 
       </div> 
      </div> 
     </div>   
     <a id="commentBox" name="commentBox"></a> 
     <div id="pcCommentBox" class="comment-box comment-box-new2 login-comment-box-new" style="display:none"> 
      <div class="has-comment" style="display:block"> 
       <div class="one-line-box"> 
        <div class="has-comment-tit go-side-comment"> 
         <span class="count">9</span>&nbsp;条评论 
        </div> 
        <div class="has-comment-con comment-operate-item"></div> 
        <a class="has-comment-bt-right go-side-comment focus">写评论</a> 
       </div> 
      </div> 
     </div> 
     <div class="first-recommend-box recommend-box recommend-highlight-default"> 
      <div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_52053775/article/details/124821692" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6661.1&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-124821692-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_52053775/article/details/124821692&quot;}"> 
       <div class="content-box"> 
        <div class="content-blog display-flex"> 
         <div class="title-box"> 
          <span class="type"> <img src="https://csdnimg.cn/release/blogv2/dist/components/img/blogType.png" alt=""> <span class="tip">博客</span> </span> 
          <a href="https://blog.csdn.net/qq_52053775/article/details/124821692" class="tit" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6661.1&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-124821692-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_52053775/article/details/124821692&quot;}" data-report-query="spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-124821692-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-124821692-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
           <div class="left ellipsis-online ellipsis-online-1">
            <em>论文</em>
            <em>精读</em>：
            <em>DenseNet</em>：Densely Connected Convolutional Networks
           </div> </a> 
         </div> 
         <div class="info-box display-flex"> 
          <div class="info"> 
           <a href="https://blog.csdn.net/qq_52053775" target="_blank"><span class="blog-title">qq_52053775的博客</span></a> 
          </div> 
          <div class="info display-flex"> 
           <span class="info-block time">05-17</span> 
           <span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> 2179 </span> 
          </div> 
         </div> 
        </div> 
        <div class="desc-box"> 
         <a href="https://blog.csdn.net/qq_52053775/article/details/124821692" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6661.1&quot;,&quot;mod&quot;:&quot;popu_871&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant_t0.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-124821692-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_52053775/article/details/124821692&quot;}" data-report-query="spm=1001.2101.3001.6661.1&amp;utm_medium=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-124821692-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-124821692-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
          <div class="desc ellipsis-online ellipsis-online-1">
           1.核心思想 最近的研究表明，如果在卷积网络的输入与输出之间添加短连接（shorter connections），那么可以使得网络变得更深、更准，并且可以更有效的训练。本文，我们围绕短连接思想，提出密集卷积网络（
           <em>DenseNet</em>）：前向传播中，每一层都与其前面的所有层连接。传统的L层卷积网络有L个连接（每层都有一个连接），而我们的网络有L(L+1)/2个连接。对于网络的每一层，前面所有层的网络都作为该层的输入，那么本身的特征图作为后续所有层的输入。 2.优势 
           <em>DenseNet</em>具有几...
          </div> </a> 
        </div> 
       </div> 
      </div> 
     </div>  
     <div class="second-recommend-box recommend-box recommend-highlight-default"> 
      <div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/qq_41295976/article/details/88249740" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.1&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-88249740-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_41295976/article/details/88249740&quot;}"> 
       <div class="content-box"> 
        <div class="content-blog display-flex"> 
         <div class="title-box"> 
          <span class="type"> <img src="https://csdnimg.cn/release/blogv2/dist/components/img/blogType.png" alt=""> <span class="tip">博客</span> </span> 
          <a href="https://blog.csdn.net/qq_41295976/article/details/88249740" class="tit" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.1&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-88249740-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_41295976/article/details/88249740&quot;}" data-report-query="spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-88249740-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-88249740-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
           <div class="left ellipsis-online ellipsis-online-1">
            <em>论文</em>
            <em>翻译</em>:
            <em>Densenet</em> 网络 Densely Connect Convolutional Networks
           </div> </a> 
         </div> 
         <div class="info-box display-flex"> 
          <div class="info"> 
           <a href="https://blog.csdn.net/qq_41295976" target="_blank"><span class="blog-title">qq_41295976的博客</span></a> 
          </div> 
          <div class="info display-flex"> 
           <span class="info-block time">03-06</span> 
           <span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> 2819 </span> 
          </div> 
         </div> 
        </div> 
        <div class="desc-box"> 
         <a href="https://blog.csdn.net/qq_41295976/article/details/88249740" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.1&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-1-88249740-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;1&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_41295976/article/details/88249740&quot;}" data-report-query="spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-88249740-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-1-88249740-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
          <div class="desc ellipsis-online ellipsis-online-1">
           转载知乎https://zhuanlan.zhihu.com/p/31647627 摘要 最近的研究表明，如果在靠近输入层与输出层之间的地方使用短连接（shorter connections），就可以训练更深、更准确、更有效的卷积网络。在这篇文章中，我们基于这个观点，介绍了稠密卷积网络（
           <em>DenseNet</em>），该网络在前馈时将每一层都与其他的任一层进行了连接。传统的层卷积网络有个连接——每...
          </div> </a> 
        </div> 
       </div> 
      </div> 
     </div> 
     <div class="recommend-box insert-baidu-box  recommend-highlight-default"> 
      <div class="recommend-item-box no-index" style="display:none"></div> 
      <div class="recommend-item-box type_blog clearfix" data-url="https://blog.csdn.net/weixin_39615182/article/details/110929655" data-report-view="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.2&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-110929655-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_39615182/article/details/110929655&quot;}"> 
       <div class="content-box"> 
        <div class="content-blog display-flex"> 
         <div class="title-box"> 
          <span class="type"> <img src="https://csdnimg.cn/release/blogv2/dist/components/img/blogType.png" alt=""> <span class="tip">博客</span> </span> 
          <a href="https://blog.csdn.net/weixin_39615182/article/details/110929655" class="tit" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.2&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-110929655-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_39615182/article/details/110929655&quot;}" data-report-query="spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-110929655-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-110929655-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
           <div class="left ellipsis-online ellipsis-online-1">
            【
            <em>深度学习</em>原理第9篇】
            <em>DenseNet</em>模型详解
           </div> </a> 
         </div> 
         <div class="info-box display-flex"> 
          <div class="info"> 
           <a href="https://blog.csdn.net/weixin_39615182" target="_blank"><span class="blog-title">小样yx的博客</span></a> 
          </div> 
          <div class="info display-flex"> 
           <span class="info-block time">12-09</span> 
           <span class="info-block read"><img class="read-img" src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> 4075 </span> 
          </div> 
         </div> 
        </div> 
        <div class="desc-box"> 
         <a href="https://blog.csdn.net/weixin_39615182/article/details/110929655" target="_blank" data-report-click="{&quot;ab&quot;:&quot;new&quot;,&quot;spm&quot;:&quot;1001.2101.3001.6650.2&quot;,&quot;mod&quot;:&quot;popu_387&quot;,&quot;extra&quot;:&quot;{\&quot;highlightScore\&quot;:0.0,\&quot;utm_medium\&quot;:\&quot;distribute.pc_relevant.none-task-blog-2~default~BlogCommendFromBaidu~Rate-2-110929655-blog-128478420.235^v43^pc_blog_bottom_relevance_base9\&quot;,\&quot;dist_request_id\&quot;:\&quot;1743598761995_22256\&quot;}&quot;,&quot;dist_request_id&quot;:&quot;1743598761995_22256&quot;,&quot;ab_strategy&quot;:&quot;vipdefault&quot;,&quot;index&quot;:&quot;2&quot;,&quot;strategy&quot;:&quot;2~default~BlogCommendFromBaidu~Rate&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_39615182/article/details/110929655&quot;}" data-report-query="spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-110929655-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-110929655-blog-128478420.235%5Ev43%5Epc_blog_bottom_relevance_base9"> 
          <div class="desc ellipsis-online ellipsis-online-1">
           一、背景概述 
           <em>DenseNet</em>是2017年CVPR的最佳
           <em>论文</em>，它不同于ResNet中的残差结构，也不同于GoogLetNet中的Inception网络结构。
           <em>DenseNet</em>提出了一种新的提升性能的思路，即作者通过对特征层的极致利用使模型有了更好的性能，并且相比ResNet进一步减少了参数，提高了性能，特征层的极致利用表现在更密集的特征连接，密集连接也是本篇文章的核心。让我们一起来
           <em>学习</em>它吧。 二、
           <em>DenseNet</em> 
           <em>论文</em>地址：https://arxiv.org/pdf/1608.06993.pdf 下图为De
          </div> </a> 
        </div> 
       </div> 
      </div> 
     </div> 
     <div class="blog-footer-bottom" style="margin-top:10px;"></div>   
    </main> 
    <aside class="blog_container_aside"> 
     <div id="asideProfile" class="aside-box active"> 
      <div class="profile-intro d-flex"> 
       <div class="avatar-box d-flex justify-content-center flex-column"> 
        <a href="https://jrs0511.blog.csdn.net" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;spm&quot;:&quot;3001.4121&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img src="https://profile-avatar.csdnimg.cn/da983c398fca4f14a19ea48d137f6ca3_weixin_43334693.jpg!1" class="avatar_pic"> </a>
        <a href="https://jrs0511.blog.csdn.net" data-report-click="{&quot;spm&quot;:&quot;3001.9180&quot;}" target="_blank"><img class="identity" src="https://csdnimg.cn/release/blogv2/dist/mobile/img/vipIcon.png" alt=""></a>  
       </div> 
       <div class="user-info d-flex flex-column profile-intro-name-box"> 
        <div class="profile-intro-name-boxTop"> 
         <a href="https://jrs0511.blog.csdn.net" target="_blank" class="" id="uid" title="路人贾'ω'" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;spm&quot;:&quot;3001.4122&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net&quot;,&quot;ab&quot;:&quot;new&quot;}"> <span class="name" username="weixin_43334693">路人贾'ω'</span> </a> 
        </div> 
        <div class="profile-intro-name-boxFooter-new"> 
         <p class="profile-intro-name-leve"> <span> 博客等级 </span> <img class="level" src="https://csdnimg.cn/identity/blog7.png"> </p> 
         <span class="profile-intro-name-years" title="已加入 CSDN 7年">码龄7年</span> 
        </div> 
       </div> 
      </div> 
      <div class="profile-intro-Identity-information"> 
       <p class="profile-information-box"> <img class="information-img" data-report-click="{&quot;spm&quot;:&quot;3001.4296&quot;}" src="https://img-home.csdnimg.cn/images/20210412060958.png" alt=""> <span>人工智能领域优质创作者</span> </p> 
      </div> 
      <div class="profile-intro-rank-information"> 
       <dl> 
        <a href="https://jrs0511.blog.csdn.net" data-report-click="{&quot;mod&quot;:&quot;1598321000_001&quot;,&quot;spm&quot;:&quot;3001.4310&quot;}" data-report-query="t=1"> 
         <dd>
          <span>120</span>
         </dd> 
         <dt>
          原创
         </dt> </a> 
       </dl> 
       <dl title="9103"> 
        <dd>
         9103
        </dd> 
        <dt>
         点赞
        </dt> 
       </dl> 
       <dl title="36281"> 
        <dd>
         3万+
        </dd> 
        <dt>
         收藏
        </dt> 
       </dl> 
       <dl id="fanBox" title="158548"> 
        <dd>
         <span id="fan">15万+</span>
        </dd> 
        <dt>
         粉丝
        </dt> 
       </dl> 
      </div> 
      <div class="profile-intro-name-boxOpration"> 
       <div class="opt-letter-watch-box"> 
        <a class="attented personal-watch bt-button" id="btnAttent">已关注</a> 
       </div> 
       <div class="opt-letter-watch-box"> 
        <a rel="noopener" class="bt-button personal-letter" href="https://im.csdn.net/chat/weixin_43334693" target="_blank">私信</a> 
       </div> 
      </div> 
     </div> 
     <div class="swiper-slide-box-remuneration"> 
      <a data-report-click="{&quot;spm&quot;:&quot;3001.9728&quot;,&quot;extra&quot;:{&quot;index&quot;:&quot;0&quot;}}" data-report-view="{&quot;spm&quot;:&quot;3001.9728&quot;,&quot;extra&quot;:{&quot;index&quot;:&quot;0&quot;}}" href="https://ai.csdn.net/" target="_blank"> <img src="https://i-operation.csdnimg.cn/images/2dd892a9769b4cce9c086db94eab887f.png" alt=""> </a> 
     </div> 
     <div id="asideHotArticle" class="aside-box"> 
      <h3 class="aside-title">热门文章</h3> 
      <div class="aside-content"> 
       <ul class="hotArticle-list"> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/129312409" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129312409&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【YOLO系列】YOLOv5超详细解读（源码详解＋入门实践＋改进） <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">191050</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/130189238" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/130189238&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【Transformer系列（2）】注意力机制、自注意力机制、多头注意力机制、通道注意力机制、空间注意力机制超详细讲解 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">132906</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/129356033" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129356033&quot;,&quot;ab&quot;:&quot;new&quot;}"> YOLOv5源码逐行超详细注释与解读（1）——项目目录结构解析 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">84049</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/136383022" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/136383022&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【YOLO系列】YOLOv9论文超详细解读（翻译 ＋学习笔记） <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">53110</span> </a> </li> 
        <li> <a href="https://jrs0511.blog.csdn.net/article/details/129011644" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_541&quot;,&quot;spm&quot;:&quot;3001.4139&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129011644&quot;,&quot;ab&quot;:&quot;new&quot;}"> 【YOLO系列】YOLOv1论文超详细解读（翻译 ＋学习笔记） <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">47685</span> </a> </li> 
       </ul> 
      </div> 
     </div> 
     <div id="asideCategory" class="aside-box flexible-box"> 
      <h3 class="aside-title">分类专栏</h3> 
      <div class="aside-content"> 
       <ul> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12233704.html" data-report-click="{&quot;mod&quot;:&quot;popu_826&quot;,&quot;spm&quot;:&quot;3001.4230&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12233704.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/2d39764ecc8e8d41d72673a523e05b4b.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> YOLOv5入门＋实践＋改进 </span> <span class="pay-tag">付费</span> </a> <span class="special-column-num">47篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12534739.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12534739.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/9c2589275bee6d84a2f42be4f7fdd306.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 低照度图像增强 </span> </a> <span class="special-column-num">14篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12202773.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12202773.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/31534c7b408a58aa373bf5f58c00bf44.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 目标检测论文 </span> </a> <span class="special-column-num">18篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12127342.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12127342.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/4cc3e83223e8d0023a6303cdd4658cce.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 图像分类经典论文 </span> </a> <span class="special-column-num">9篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12462707.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12462707.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/columns/default/20201014180756930.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 论文必备 </span> </a> <span class="special-column-num">4篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12288776.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12288776.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/892c3e48b8251069b7506e1e68c5355a.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> transformer </span> </a> <span class="special-column-num">9篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12186888.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12186888.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/8cc13d2259e721c3b070257331ba2fcf.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> Pytorch </span> </a> <span class="special-column-num">9篇</span> </li> 
        <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12151162.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12151162.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
          <div class="special-column-bar special-column-bar-second"></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/b9346faac8287efffed28c8b2d898da7.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class="title oneline"> 论文代码复现 </span> </a> <span class="special-column-num">6篇</span> </li> 
       </ul> 
      </div> 
      <p class="text-center"> <a class="flexible-btn" data-fbox="aside-archive"><img class="look-more" src="https://csdnimg.cn/release/blogv2/dist/pc/img/arrowDownWhite.png" alt=""></a> </p> 
     </div> 
     <div id="asideNewComments" class="aside-box"> 
      <h3 class="aside-title">最新评论</h3> 
      <div class="aside-content"> 
       <ul class="newcomment-list"> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/129349094#comments_36790608" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129349094#comments_36790608&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/129349094#comments_36790608&quot;,&quot;ab&quot;:&quot;new&quot;}">YOLOv5源码逐行超详细注释与解读（2）——推理部分detect.py</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/qq_58411487" class="user-name" target="_blank">qq_58411487: </a> <span class="code-comments">下个插件就行了</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/130208816#comments_36778242" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/130208816#comments_36778242&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/130208816#comments_36778242&quot;,&quot;ab&quot;:&quot;new&quot;}">【Transformer系列（3）】 《Attention Is All You Need》论文超详细解读（翻译＋精读）</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/m0_64252296" class="user-name" target="_blank">荷西、: </a> <span class="code-comments">这篇论文从哪找</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/133516890#comments_36767793" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36767793&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36767793&quot;,&quot;ab&quot;:&quot;new&quot;}">[论文必备]最强科研绘图分析工具Origin（1）——安装教程</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/X224513" class="user-name" target="_blank">X224513: </a> <span class="code-comments">求安装包链接，谢谢！</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/133516890#comments_36722559" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36722559&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36722559&quot;,&quot;ab&quot;:&quot;new&quot;}">[论文必备]最强科研绘图分析工具Origin（1）——安装教程</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/ant_c2" class="user-name" target="_blank">ant_c2: </a> <span class="code-comments">求安装包链接，谢谢！</span> </p> </li> 
        <li> <a class="title text-truncate" target="_blank" href="https://jrs0511.blog.csdn.net/article/details/133516890#comments_36710842" data-report-click="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36710842&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_542&quot;,&quot;spm&quot;:&quot;3001.4231&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/133516890#comments_36710842&quot;,&quot;ab&quot;:&quot;new&quot;}">[论文必备]最强科研绘图分析工具Origin（1）——安装教程</a> <p class="comment ellipsis"> <a href="https://blog.csdn.net/sdtzlxx" class="user-name" target="_blank">sdtzlxx: </a> <span class="code-comments">求安装包链接！！！！！谢谢大佬！</span> </p> </li> 
       </ul> 
      </div> 
     </div> 
     <div id="asideHotArticle" class="aside-box"> 
      <h3 class="aside-title">大家在看</h3> 
      <div class="aside-content"> 
       <ul class="hotArticle-list"> 
        <li> <a href="https://blog.csdn.net/zhenggaoxiao232/article/details/146599998" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/zhenggaoxiao232/article/details/146599998&quot;,&quot;strategy&quot;:&quot;202_1052723-2643786_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/zhenggaoxiao232/article/details/146599998&quot;,&quot;strategy&quot;:&quot;202_1052723-2643786_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 鸿蒙开发0基础【拉起文件处理类应用（startAbility）】 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">688</span> </a> </li> 
        <li> <a href="https://blog.csdn.net/bendanrrj/article/details/146814051" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/bendanrrj/article/details/146814051&quot;,&quot;strategy&quot;:&quot;202_1052723-2643866_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/bendanrrj/article/details/146814051&quot;,&quot;strategy&quot;:&quot;202_1052723-2643866_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 三大库-NumPy <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">426</span> </a> </li> 
        <li> <a href="https://blog.csdn.net/cybersnow/article/details/146873941" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/cybersnow/article/details/146873941&quot;,&quot;strategy&quot;:&quot;202_1052723-2643852_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/cybersnow/article/details/146873941&quot;,&quot;strategy&quot;:&quot;202_1052723-2643852_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 系统调优分析师分析之优化职员业绩累计业绩提成计算optimize-数组模拟sql查询技术 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">232</span> </a> </li> 
        <li> <a href="https://blog.csdn.net/beijing_oracle/article/details/146923305" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/beijing_oracle/article/details/146923305&quot;,&quot;strategy&quot;:&quot;202_1052723-2643813_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/beijing_oracle/article/details/146923305&quot;,&quot;strategy&quot;:&quot;202_1052723-2643813_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> Java Spring 框架技术从入门到放弃：Spring生态之Spring Bean 的生命周期，Spring Bean生命周期四大阶段 <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/readCountWhite.png" alt=""> <span class="read">339</span> </a> </li> 
        <li> <a href="https://blog.csdn.net/beijing_oracle/article/details/146963455" target="_blank" data-report-click="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/beijing_oracle/article/details/146963455&quot;,&quot;strategy&quot;:&quot;202_1052723-2643805_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;spm&quot;:&quot;3001.10093&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/beijing_oracle/article/details/146963455&quot;,&quot;strategy&quot;:&quot;202_1052723-2643805_RCMD&quot;,&quot;ab&quot;:&quot;new&quot;}"> 编程自学指南：java程序设计开发，JavaWeb Servlet 与Filter 、Listener、SpringMVC协作学习笔记 </a> </li> 
       </ul> 
      </div> 
     </div> 
     <div id="asideArchive" class="aside-box" style="display:block!important; width:300px;"> 
      <h3 class="aside-title">最新文章</h3> 
      <div class="aside-content"> 
       <ul class="inf_list clearfix"> 
        <li class="clearfix"> <a href="https://jrs0511.blog.csdn.net/article/details/140203276" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;3001.4136&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140203276&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140203276&quot;,&quot;ab&quot;:&quot;new&quot;}">【低照度图像增强系列（8）】URetinex-Net算法详解与代码实现（2022|CVPR）</a> </li> 
        <li class="clearfix"> <a href="https://jrs0511.blog.csdn.net/article/details/140229971" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;3001.4136&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140229971&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/140229971&quot;,&quot;ab&quot;:&quot;new&quot;}">CVPR|《URetinex-Net: Retinex-based Deep Unfolding Network for Low-light Image Enhance》论文超详细解读（翻译＋精读）</a> </li> 
        <li class="clearfix"> <a href="https://jrs0511.blog.csdn.net/article/details/139832512" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;spm&quot;:&quot;3001.4136&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/139832512&quot;,&quot;ab&quot;:&quot;new&quot;}" data-report-view="{&quot;mod&quot;:&quot;popu_382&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net/article/details/139832512&quot;,&quot;ab&quot;:&quot;new&quot;}">YOLOv5改进系列（32）——替换主干网络之PKINet（CVPR2024 | 面向遥感旋转框主干，有效捕获不同尺度上的密集纹理特征）</a> </li> 
       </ul> 
       <div class="archive-bar"></div> 
       <div class="archive-box"> 
        <div class="archive-list-item">
         <a href="https://jrs0511.blog.csdn.net?type=blog&amp;year=2024&amp;month=07" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net?type=blog&amp;year=2024&amp;month=07&quot;}"><span class="year">2024年</span><span class="num">23篇</span></a>
        </div> 
        <div class="archive-list-item">
         <a href="https://jrs0511.blog.csdn.net?type=blog&amp;year=2023&amp;month=12" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net?type=blog&amp;year=2023&amp;month=12&quot;}"><span class="year">2023年</span><span class="num">87篇</span></a>
        </div> 
        <div class="archive-list-item">
         <a href="https://jrs0511.blog.csdn.net?type=blog&amp;year=2022&amp;month=12" target="_blank" data-report-click="{&quot;mod&quot;:&quot;popu_538&quot;,&quot;spm&quot;:&quot;3001.4138&quot;,&quot;ab&quot;:&quot;new&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net?type=blog&amp;year=2022&amp;month=12&quot;}"><span class="year">2022年</span><span class="num">10篇</span></a>
        </div> 
       </div> 
      </div> 
     </div> 
     <!-- 详情页显示目录 --> 
     <!--文章目录--> 
     <div id="asidedirectory" class="aside-box"> 
      <div class="groupfile" id="directory"> 
       <h3 class="aside-title">目录</h3> 
       <div class="align-items-stretch group_item"> 
        <div class="pos-box"> 
         <div class="scroll-box"> 
          <div class="toc-box"></div> 
         </div> 
        </div> 
       </div> 
      </div> 
     </div> 
    </aside>    
   </div> 
   <div class="recommend-right align-items-stretch clearfix" id="rightAside" data-type="recommend"> 
    <aside class="recommend-right_aside"> 
     <div class="rightside-fixed-hide"> 
      <div class="recommend-column-box aside-box"> 
       <h3 class="aside-title">相关专栏 </h3> 
       <div class="aside-content"> 
        <div class="recommend-column-itembox exp1"> 
         <a href="https://blog.csdn.net/qq_36584673/category_11691339.html" title="图像拼接论文源码精读" target="_blank" data-report-view="{&quot;spm&quot;:&quot;3001.10573&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_36584673/category_11691339.html&quot;,&quot;ab&quot;:&quot;exp1&quot;,&quot;extra&quot;:&quot;{\&quot;id\&quot;:\&quot;128478420\&quot;,\&quot;recommendCount\&quot;:\&quot;3\&quot;,\&quot;index\&quot;:\&quot;0\&quot;,\&quot;type\&quot;:\&quot;column\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;3001.10573&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_36584673/category_11691339.html&quot;,&quot;ab&quot;:&quot;exp1&quot;,&quot;extra&quot;:&quot;{\&quot;id\&quot;:\&quot;128478420\&quot;,\&quot;recommendCount\&quot;:\&quot;3\&quot;,\&quot;index\&quot;:\&quot;0\&quot;,\&quot;type\&quot;:\&quot;column\&quot;}&quot;}"> 
          <div class="info-box"> 
           <div class="img-box"> 
            <div class="column-img" style="background-image: url(https://i-blog.csdnimg.cn/blog_column_migrate/960984bfced28c62bbc6d417331d2050.jpeg?x-oss-process=image/resize,m_fixed,h_224,w_224)" alt="图像拼接论文源码精读" srcset=""></div> 
           </div> 
           <div class="info"> 
            <div class="title-box"> 
             <p class="title">图像拼接论文源码精读</p> 
             <p class="tag">专栏</p> 
            </div> 
            <p class="learn">28 人学习</p> 
           </div> 
          </div> <p class="desc" title="手把手教你跑通图像拼接论文源码，带你读代码，详细讲解实现思路与具体细节，附有对应的【论文精读】专栏，帮助图像拼接领域的科研工作者更好的理解论文源码，寻找创新点。论文包括主流的图像拼接算法APAP、AANAP、SPHP、ELA、SPW、LPC、基于拼接缝的算法、基于深度学习的算法UDIS、UDIS++">手把手教你跑通图像拼接论文源码，带你读代码，详细讲解实现思路与具体细节，附有对应的【论文精读】专栏，帮助图像拼接领域的科研工作者更好的理解论文源码，寻找创新点。论文包括主流的图像拼接算法APAP、AANAP、SPHP、ELA、SPW、LPC、基于拼接缝的算法、基于深度学习的算法UDIS、UDIS++</p> </a> 
        </div> 
        <div class="recommend-column-itembox exp1"> 
         <a href="https://blog.csdn.net/qq_36584673/category_12756147.html" title="Pytorch深度学习图像去噪算法100例（论文精读+复现）" target="_blank" data-report-view="{&quot;spm&quot;:&quot;3001.10573&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_36584673/category_12756147.html&quot;,&quot;ab&quot;:&quot;exp1&quot;,&quot;extra&quot;:&quot;{\&quot;id\&quot;:\&quot;128478420\&quot;,\&quot;recommendCount\&quot;:\&quot;3\&quot;,\&quot;index\&quot;:\&quot;1\&quot;,\&quot;type\&quot;:\&quot;column\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;3001.10573&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_36584673/category_12756147.html&quot;,&quot;ab&quot;:&quot;exp1&quot;,&quot;extra&quot;:&quot;{\&quot;id\&quot;:\&quot;128478420\&quot;,\&quot;recommendCount\&quot;:\&quot;3\&quot;,\&quot;index\&quot;:\&quot;1\&quot;,\&quot;type\&quot;:\&quot;column\&quot;}&quot;}"> 
          <div class="info-box"> 
           <div class="img-box"> 
            <div class="column-img" style="background-image: url(https://i-blog.csdnimg.cn/direct/d0a5e480c4f54f7b9a332011657fa317.jpeg?x-oss-process=image/resize,m_fixed,h_224,w_224)" alt="Pytorch深度学习图像去噪算法100例（论文精读+复现）" srcset=""></div> 
           </div> 
           <div class="info"> 
            <div class="title-box"> 
             <p class="title">Pytorch深度学习图像去噪算法100例（论文精读+复现）</p> 
             <p class="tag">专栏</p> 
            </div> 
            <p class="learn">114 人学习</p> 
           </div> 
          </div> <p class="desc" title="专栏内文章内容包括理论与实践两部分。理论为主流去噪算法论文精读，理解原理；实践为论文源码复现，跑通源码，得到去噪结果以及性能指标，助力学习科研。">专栏内文章内容包括理论与实践两部分。理论为主流去噪算法论文精读，理解原理；实践为论文源码复现，跑通源码，得到去噪结果以及性能指标，助力学习科研。</p> </a> 
        </div> 
        <div class="recommend-column-itembox exp1"> 
         <a href="https://blog.csdn.net/qq_36584673/category_12590966.html" title="超分辨率重建（理论+实战，科研+应用）" target="_blank" data-report-view="{&quot;spm&quot;:&quot;3001.10573&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_36584673/category_12590966.html&quot;,&quot;ab&quot;:&quot;exp1&quot;,&quot;extra&quot;:&quot;{\&quot;id\&quot;:\&quot;128478420\&quot;,\&quot;recommendCount\&quot;:\&quot;3\&quot;,\&quot;index\&quot;:\&quot;2\&quot;,\&quot;type\&quot;:\&quot;column\&quot;}&quot;}" data-report-click="{&quot;spm&quot;:&quot;3001.10573&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/qq_36584673/category_12590966.html&quot;,&quot;ab&quot;:&quot;exp1&quot;,&quot;extra&quot;:&quot;{\&quot;id\&quot;:\&quot;128478420\&quot;,\&quot;recommendCount\&quot;:\&quot;3\&quot;,\&quot;index\&quot;:\&quot;2\&quot;,\&quot;type\&quot;:\&quot;column\&quot;}&quot;}"> 
          <div class="info-box"> 
           <div class="img-box"> 
            <div class="column-img" style="background-image: url(https://i-blog.csdnimg.cn/direct/ae5621ed691449b99b5173ca304e5bb3.png?x-oss-process=image/resize,m_fixed,h_224,w_224)" alt="超分辨率重建（理论+实战，科研+应用）" srcset=""></div> 
           </div> 
           <div class="info"> 
            <div class="title-box"> 
             <p class="title">超分辨率重建（理论+实战，科研+应用）</p> 
             <p class="tag">专栏</p> 
            </div> 
            <p class="learn">179 人学习</p> 
           </div> 
          </div> <p class="desc" title="专栏内文章包含单图像超分和视频超分。跑通主流的超分论文源码，详细讲解原理和代码实现，训练自己的数据集，实际应用和涨点创新改进。算法包括：SRCNN、ESPCN、VDSR、DRCN、DRRN、EDSR、SRGAN、ESRGAN、RDN、WDSR、LapSRN、RCAN、SAN、IGNN、SwinIR等">专栏内文章包含单图像超分和视频超分。跑通主流的超分论文源码，详细讲解原理和代码实现，训练自己的数据集，实际应用和涨点创新改进。算法包括：SRCNN、ESPCN、VDSR、DRCN、DRRN、EDSR、SRGAN、ESRGAN、RDN、WDSR、LapSRN、RCAN、SAN、IGNN、SwinIR等</p> </a> 
        </div> 
       </div> 
      </div> 
     </div> 
     <div id="recommend-right"> 
      <div class="flex-column aside-box groupfile" id="groupfile"> 
       <div class="groupfile-div"> 
        <h3 class="aside-title">目录</h3> 
        <div class="align-items-stretch group_item"> 
         <div class="pos-box"> 
          <div class="scroll-box"> 
           <div class="toc-box"></div> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
      <div class="aside-box kind_person d-flex flex-column"> 
       <h3 class="aside-title">分类专栏</h3> 
       <div class="align-items-stretch kindof_item" id="kind_person_column"> 
        <div class="aside-content"> 
         <ul> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12233704.html" data-report-click="{&quot;mod&quot;:&quot;popu_826&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4230&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12233704.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/2d39764ecc8e8d41d72673a523e05b4b.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> YOLOv5入门＋实践＋改进 </span> <span class="pay-tag">付费</span> </a> <span class="special-column-num">47篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12534739.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12534739.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/9c2589275bee6d84a2f42be4f7fdd306.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 低照度图像增强 </span> </a> <span class="special-column-num">14篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12202773.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12202773.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/31534c7b408a58aa373bf5f58c00bf44.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 目标检测论文 </span> </a> <span class="special-column-num">18篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12127342.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12127342.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/4cc3e83223e8d0023a6303cdd4658cce.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 图像分类经典论文 </span> </a> <span class="special-column-num">9篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12462707.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12462707.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/columns/default/20201014180756930.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 论文必备 </span> </a> <span class="special-column-num">4篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12288776.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12288776.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/892c3e48b8251069b7506e1e68c5355a.jpeg?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> transformer </span> </a> <span class="special-column-num">9篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12186888.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12186888.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar "></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/8cc13d2259e721c3b070257331ba2fcf.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> Pytorch </span> </a> <span class="special-column-num">9篇</span> </li> 
          <li> <a class="clearfix special-column-name" href="https://blog.csdn.net/weixin_43334693/category_12151162.html" data-report-click="{&quot;mod&quot;:&quot;popu_537&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4137&quot;,&quot;strategy&quot;:&quot;pc付费专栏左侧入口&quot;,&quot;dest&quot;:&quot;https://blog.csdn.net/weixin_43334693/category_12151162.html&quot;,&quot;ab&quot;:&quot;new&quot;}"> 
            <div class="special-column-bar special-column-bar-second"></div> <img src="https://i-blog.csdnimg.cn/blog_column_migrate/b9346faac8287efffed28c8b2d898da7.png?x-oss-process=image/resize,m_fixed,h_64,w_64" alt="" onerror="this.src='https://i-blog.csdnimg.cn/columns/default/20201014180756922.png?x-oss-process=image/resize,m_fixed,h_64,w_64'"> <span class=""> 论文代码复现 </span> </a> <span class="special-column-num">6篇</span> </li> 
         </ul> 
        </div> 
       </div> 
      </div> 
     </div> 
    </aside> 
   </div> 
   <div class="recommend-right1  align-items-stretch clearfix" id="rightAsideConcision" data-type="recommend"> 
    <aside class="recommend-right_aside"> 
     <div id="recommend-right-concision"> 
      <div class="flex-column aside-box groupfile" id="groupfileConcision"> 
       <div class="groupfile-div1"> 
        <h3 class="aside-title">目录</h3> 
        <div class="align-items-stretch group_item"> 
         <div class="pos-box"> 
          <div class="scroll-box"> 
           <div class="toc-box"></div> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
     </div> 
    </aside> 
   </div> 
  </div> 
  <div class="mask-dark"></div> 
  <div class="skin-boxshadow"></div> 
  <div class="directory-boxshadow"></div> 
  <div class="comment-side-box-shadow comment-side-tit-close" id="commentSideBoxshadow"> 
   <div class="comment-side-content"> 
    <div class="comment-side-tit"> 
     <div class="comment-side-tit-count">
      评论&nbsp;
      <span class="count">9</span>
     </div> 
     <img class="comment-side-tit-close" src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png">
    </div> 
    <div id="pcCommentSideBox" class="comment-box comment-box-new2 " style="display:block"> 
     <div class="comment-edit-box d-flex"> 
      <div class="user-img"> 
       <a href="https://blog.csdn.net/2401_84444578" target="_blank"> <img src="https://profile-avatar.csdnimg.cn/default.jpg!1"> </a> 
      </div> 
      <form id="commentform"> 
       <textarea class="comment-content" name="comment_content" id="comment_content" placeholder="欢迎高质量的评论，低质的评论会被折叠" maxlength="1000"></textarea> 
       <div class="comment-reward-box" style="background-image: url('https://img-home.csdnimg.cn/images/20230131025301.png');"> 
        <a class="btn-remove-reward"></a> 
        <div class="form-reward-box"> 
         <div class="info">
           成就一亿技术人! 
         </div> 
         <div class="price-info">
           拼手气红包
          <span class="price">6.0元</span> 
         </div> 
        </div> 
       </div> 
       <div class="comment-operate-box"> 
        <div class="comment-operate-l"> 
         <span id="tip_comment" class="tip">还能输入<em>1000</em>个字符</span> 
        </div> 
        <div class="comment-operate-c">
          &nbsp; 
        </div> 
        <div class="comment-operate-r"> 
         <div class="comment-operate-item comment-reward"> 
          <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentReward.png" alt="红包"> 
          <span class="comment-operate-tip">添加红包</span> 
         </div> 
         <div class="comment-operate-item comment-emoticon"> 
          <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentEmotionIcon.png" alt="表情包"> 
          <span class="comment-operate-tip">插入表情</span> 
          <div class="comment-emoticon-box comment-operate-isshow"> 
           <div class="comment-emoticon-img-box"></div> 
          </div> 
         </div> 
         <div class="comment-operate-item comment-code"> 
          <img class="comment-operate-img" data-url="https://csdnimg.cn/release/blogv2/dist/pc/img/" src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentCodeIcon.png" alt="表情包"> 
          <span class="comment-operate-tip">代码片</span> 
          <div class="comment-code-box comment-operate-isshow"> 
           <ul id="commentCode"> 
            <li><a data-code="html">HTML/XML</a></li> 
            <li><a data-code="objc">objective-c</a></li> 
            <li><a data-code="ruby">Ruby</a></li> 
            <li><a data-code="php">PHP</a></li> 
            <li><a data-code="csharp">C</a></li> 
            <li><a data-code="cpp">C++</a></li> 
            <li><a data-code="javascript">JavaScript</a></li> 
            <li><a data-code="python">Python</a></li> 
            <li><a data-code="java">Java</a></li> 
            <li><a data-code="css">CSS</a></li> 
            <li><a data-code="sql">SQL</a></li> 
            <li><a data-code="plain">其它</a></li> 
           </ul> 
          </div> 
         </div> 
         <div class="comment-operate-item"> 
          <input type="hidden" id="comment_replyId" name="comment_replyId"> 
          <input type="hidden" id="article_id" name="article_id" value="128478420"> 
          <input type="hidden" id="comment_userId" name="comment_userId" value=""> 
          <input type="hidden" id="commentId" name="commentId" value=""> 
          <a data-report-click="{&quot;mod&quot;:&quot;1582594662_003&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4227&quot;,&quot;ab&quot;:&quot;new&quot;}"> <input type="submit" class="btn-comment btn-comment-input" value="评论"> </a> 
         </div> 
        </div> 
       </div> 
      </form> 
     </div> 
     <div class="comment-list-container"> 
      <div class="comment-list-box comment-operate-item"> 
      </div> 
      <div id="lookGoodComment" class="look-good-comment side-look-comment"> 
       <a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownWhite.png" alt=""></a> 
      </div> 
      <div id="lookFlodComment" class="look-flod-comment"> 
       <span class="count"></span>&nbsp;条评论被折叠&nbsp;
       <a class="look-more-flodcomment">查看</a> 
      </div> 
      <div class="opt-box text-center"> 
       <div class="btn btn-sm btn-link-blue" id="btnMoreComment"></div> 
      </div> 
     </div> 
    </div> 
    <div id="pcFlodCommentSideBox" class="pc-flodcomment-sidebox"> 
     <div class="comment-fold-tit">
      <span id="lookUnFlodComment" class="back"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowLeftWhite.png" alt=""></span>被折叠的&nbsp;
      <span class="count"></span>&nbsp;条评论 
      <a href="https://blogdev.blog.csdn.net/article/details/122245662" class="tip" target="_blank">为什么被折叠?</a> 
      <a href="https://bbs.csdn.net/forums/FreeZone" class="park" target="_blank"> <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/iconPark.png">到【灌水乐园】发言</a> 
     </div> 
     <div class="comment-fold-content"></div> 
     <div id="lookBadComment" class="look-bad-comment side-look-comment"> 
      <a class="look-more-comment">查看更多评论<img src="https://csdnimg.cn/release/blogv2/dist/pc/img/commentArrowDownWhite.png" alt=""></a> 
     </div> 
    </div> 
   </div> 
   <div class="comment-rewarddialog-box"> 
    <div class="form-box"> 
     <div class="title-box">
       添加红包 
      <a class="btn-form-close"></a> 
     </div> 
     <form id="commentRewardForm"> 
      <div class="ipt-box"> 
       <label for="txtName">祝福语</label> 
       <div class="ipt-btn-box"> 
        <input type="text" name="name" id="txtName" autocomplete="off" maxlength="50"> 
        <a class="btn-ipt btn-random"></a> 
       </div> 
       <p class="notice">请填写红包祝福语或标题</p> 
      </div> 
      <div class="ipt-box"> 
       <label for="txtSendAmount">红包数量</label> 
       <div class="ipt-txt-box"> 
        <input type="text" name="sendAmount" maxlength="4" id="txtSendAmount" placeholder="请填写红包数量(最小10个)" autocomplete="off"> 
        <span class="after-txt">个</span> 
       </div> 
       <p class="notice">红包个数最小为10个</p> 
      </div> 
      <div class="ipt-box"> 
       <label for="txtMoney">红包总金额</label> 
       <div class="ipt-txt-box error"> 
        <input type="text" name="money" maxlength="5" id="txtMoney" placeholder="请填写总金额(最低5元)" autocomplete="off"> 
        <span class="after-txt">元</span> 
       </div> 
       <p class="notice">红包金额最低5元</p> 
      </div> 
      <div class="balance-info-box"> 
       <label>余额支付</label> 
       <div class="balance-info">
         当前余额
        <span class="balance">3.43</span>元 
        <a href="https://i.csdn.net/#/wallet/balance/recharge" class="link-charge" target="_blank">前往充值 &gt;</a> 
       </div> 
      </div> 
      <div class="opt-box"> 
       <div class="pay-info">
         需支付：
        <span class="price">10.00</span>元 
       </div> 
       <button type="button" class="ml-auto btn-cancel">取消</button> 
       <button type="button" class="ml8 btn-submit" disabled="true">确定</button> 
      </div> 
     </form> 
    </div> 
   </div> 
   <div class="rr-guide-box"> 
    <div class="rr-first-box"> 
     <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward02.png" alt=""> 
     <button class="btn-guide-known next">下一步</button> 
    </div> 
    <div class="rr-second-box"> 
     <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/guideRedReward03.png" alt=""> 
     <button class="btn-guide-known known">知道了</button> 
    </div> 
   </div> 
  </div> 
  <div class="redEnvolope" id="redEnvolope"> 
   <div class="env-box"> 
    <div class="env-container"> 
     <div class="pre-open" id="preOpen"> 
      <div class="top"> 
       <header> 
        <img class="clearTpaErr" :src="redpacketAuthor.avatar" alt=""> 
        <div class="author">
         成就一亿技术人!
        </div> 
       </header> 
       <div class="bot-icon"></div> 
      </div> 
      <footer> 
       <div class="red-openbtn open-start"></div> 
       <div class="tip">
         领取后你会自动成为博主和红包主的粉丝 
        <a class="rule" target="_blank">规则</a> 
       </div> 
      </footer> 
     </div> 
     <div class="opened" id="opened"> 
      <div class="bot-icon"> 
       <header> 
        <a class="creatorUrl" href="" target="_blank"> <img class="clearTpaErr" src="https://profile-avatar.csdnimg.cn/default.jpg!2" alt=""> </a> 
        <div class="author"> 
         <div class="tt">
          hope_wisdom
         </div> 发出的红包 
        </div> 
       </header> 
      </div> 
      <div class="receive-box"> 
       <header></header> 
       <div class="receive-list"> 
       </div> 
      </div> 
     </div> 
    </div> 
    <div class="close-btn"></div> 
   </div> 
  </div> 
  <div id="rewardNew" class="reward-popupbox-new"> 
   <p class="rewad-title">打赏作者<span class="reward-close"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/closeBt.png"></span></p> 
   <dl class="profile-box"> 
    <dd> 
     <a href="https://jrs0511.blog.csdn.net" data-report-click="{&quot;mod&quot;:&quot;popu_379&quot;,&quot;dest&quot;:&quot;https://jrs0511.blog.csdn.net&quot;,&quot;ab&quot;:&quot;new&quot;}"> <img src="https://profile-avatar.csdnimg.cn/da983c398fca4f14a19ea48d137f6ca3_weixin_43334693.jpg!1" class="avatar_pic"> </a> 
    </dd> 
    <dt> 
     <p class="blog-name">路人贾'ω'</p> 
     <p class="blog-discript">你的鼓励将是我创作的最大动力</p> 
    </dt> 
   </dl> 
   <div class="reward-box-new"> 
    <div class="reward-content">
     <div class="reward-right"></div>
    </div> 
   </div> 
   <div class="money-box"> 
    <span class="choose-money choosed" data-id="1">¥1</span> 
    <span class="choose-money " data-id="2">¥2</span> 
    <span class="choose-money " data-id="4">¥4</span> 
    <span class="choose-money " data-id="6">¥6</span> 
    <span class="choose-money " data-id="10">¥10</span> 
    <span class="choose-money " data-id="20">¥20</span> 
   </div> 
   <div class="sure-box"> 
    <div class="sure-box-money"> 
     <div class="code-box"> 
      <div class="code-num-box"> 
       <span class="code-name">扫码支付：</span>
       <span class="code-num">¥1</span> 
      </div> 
      <div class="code-img-box"> 
       <div class="renovate"> 
        <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png"> 
        <span>获取中</span> 
       </div> 
      </div> 
      <div class="code-pay-box"> 
       <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newWeiXin.png" alt=""> 
       <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/newZhiFuBao.png" alt=""> 
       <span>扫码支付</span> 
      </div> 
     </div> 
    </div> 
    <div class="sure-box-blance"> 
     <p class="tip">您的余额不足，请更换扫码支付或<a target="_blank" data-report-click="{&quot;mod&quot;:&quot;1597646289_003&quot;,&quot;spm&quot;:&quot;1001.2101.3001.4302&quot;}" href="https://i.csdn.net/#/wallet/balance/recharge?utm_source=RewardVip" class="go-invest">充值</a></p> 
     <p class="is-have-money"><a class="reward-sure">打赏作者</a></p> 
    </div> 
   </div> 
  </div> 
  <div class="pay-code"> 
   <div class="pay-money">
    实付
    <span class="pay-money-span" data-nowprice="" data-oldprice="">元</span>
   </div> 
   <div class="content-blance">
    <a class="blance-bt" href="javascript:;">使用余额支付</a>
   </div> 
   <div class="content-code"> 
    <div id="payCode" data-id=""> 
     <div class="renovate"> 
      <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-time-out.png"> 
      <span>点击重新获取</span> 
     </div> 
    </div> 
    <div class="pay-style">
     <span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/weixin.png"></span>
     <span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/zhifubao.png"></span>
     <span><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/jingdong.png"></span>
     <span class="text">扫码支付</span>
    </div> 
   </div> 
   <div class="bt-close"> 
    <svg t="1567152543821" class="icon" viewbox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="10924" xmlns:xlink="http://www.w3.org/1999/xlink" width="12" height="12"> 
     <defs> 
      <style type="text/css"></style> 
     </defs> 
     <path d="M512 438.378667L806.506667 143.893333a52.032 52.032 0 1 1 73.6 73.621334L585.621333 512l294.485334 294.485333a52.074667 52.074667 0 0 1-73.6 73.642667L512 585.621333 217.514667 880.128a52.053333 52.053333 0 1 1-73.621334-73.642667L438.378667 512 143.893333 217.514667a52.053333 52.053333 0 1 1 73.621334-73.621334L512 438.378667z" fill="" p-id="10925"></path> 
    </svg> 
   </div> 
   <div class="pay-balance"> 
    <input type="radio" class="pay-code-radio" data-type="details"> 
    <span class="span">钱包余额</span> 
    <span class="balance" style="color:#FC5531;font-size:14px;">0</span> 
    <div class="pay-code-tile"> 
     <img src="https://csdnimg.cn/release/blogv2/dist/pc/img/pay-help.png" alt=""> 
     <div class="pay-code-content"> 
      <div class="span"> 
       <p class="title">抵扣说明：</p> 
       <p> 1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。<br> 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。</p> 
      </div> 
     </div> 
    </div> 
   </div> 
   <a class="pay-balance-con" href="https://i.csdn.net/#/wallet/balance/recharge" target="_blank"><img src="https://csdnimg.cn/release/blogv2/dist/pc/img/recharge.png" alt=""><span>余额充值</span></a> 
  </div> 
  <div style="display:none;"> 
   <img src="" onerror="setTimeout(function(){if(!/(csdn.net|iteye.com|baiducontent.com|googleusercontent.com|360webcache.com|sogoucdn.com|bingj.com|baidu.com)$/.test(window.location.hostname)){var test=&quot;\x68\x74\x74\x70\x73\x3a\x2f\x2f\x77\x77\x77\x2e\x63\x73\x64\x6e\x2e\x6e\x65\x74&quot;}},3000);"> 
  </div> 
  <div class="keyword-dec-box" id="keywordDecBox"></div>  
  <!-- 富文本柱状图  --> 
  <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/chart/chart.css">        
  <link rel="stylesheet" href="https://g.csdnimg.cn/lib/cboxEditor/1.1.6/embed-editor.min.css"> 
  <link rel="stylesheet" href="https://csdnimg.cn/release/blog_editor_html/release1.6.12/ckeditor/plugins/codesnippet/lib/highlight/styles/dracula.css">                  
 </body>
</html>