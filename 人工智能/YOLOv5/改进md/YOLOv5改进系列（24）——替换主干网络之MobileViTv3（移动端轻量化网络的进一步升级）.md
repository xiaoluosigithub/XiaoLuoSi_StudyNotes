![](https://i-blog.csdnimg.cn/blog_migrate/7f30cb441e3fbc6c5aa1e2886fc1d9ce.gif)![](https://i-blog.csdnimg.cn/blog_migrate/75a213d9e1e88088f54fe797f262764b.png)

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif)ã€YOLOv5æ”¹è¿›ç³»åˆ—ã€‘å‰æœŸå›é¡¾ï¼š

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ0ï¼‰â€”â€”é‡è¦æ€§èƒ½æŒ‡æ ‡ä¸è®­ç»ƒç»“æœè¯„ä»·åŠåˆ†æ][YOLOv5_0]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ1ï¼‰â€”â€”æ·»åŠ SEæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_1_SE]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ2ï¼‰â€”â€”æ·»åŠ CBAMæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_2_CBAM]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ3ï¼‰â€”â€”æ·»åŠ CAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_3_CA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ4ï¼‰â€”â€”æ·»åŠ ECAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_4_ECA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ5ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹ MobileNetV3][YOLOv5_5_ MobileNetV3]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ6ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹ ShuffleNetV2][YOLOv5_6_ ShuffleNetV2]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ7ï¼‰â€”â€”æ·»åŠ SimAMæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_7_SimAM]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ8ï¼‰â€”â€”æ·»åŠ SOCAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_8_SOCA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ9ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹EfficientNetv2][YOLOv5_9_EfficientNetv2]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ10ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹GhostNet][YOLOv5_10_GhostNet]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ11ï¼‰â€”â€”æ·»åŠ æŸå¤±å‡½æ•°ä¹‹EIoUã€AlphaIoUã€SIoUã€WIoU][YOLOv5_11_EIoU_AlphaIoU_SIoU_WIoU]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ12ï¼‰â€”â€”æ›´æ¢Neckä¹‹BiFPN][YOLOv5_12_Neck_BiFPN]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ13ï¼‰â€”â€”æ›´æ¢æ¿€æ´»å‡½æ•°ä¹‹SiLUï¼ŒReLUï¼ŒELUï¼ŒHardswishï¼ŒMishï¼ŒSoftplusï¼ŒAconCç³»åˆ—ç­‰][YOLOv5_13_SiLU_ReLU_ELU_Hardswish_Mish_Softplus_AconC]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ14ï¼‰â€”â€”æ›´æ¢NMSï¼ˆéæå¤§æŠ‘åˆ¶ï¼‰ä¹‹ DIoU-NMSã€CIoU-NMSã€EIoU-NMSã€GIoU-NMS ã€SIoU-NMSã€Soft-NMS][YOLOv5_14_NMS_ DIoU-NMS_CIoU-NMS_EIoU-NMS_GIoU-NMS _SIoU-NMS_Soft-NMS]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ15ï¼‰â€”â€”å¢åŠ å°ç›®æ ‡æ£€æµ‹å±‚][YOLOv5_15]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ16ï¼‰â€”â€”æ·»åŠ EMAæ³¨æ„åŠ›æœºåˆ¶ï¼ˆICASSP2023|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_16_EMA_ICASSP2023]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ17ï¼‰â€”â€”æ›´æ¢IoUä¹‹MPDIoUï¼ˆELSEVIER 2023|è¶…è¶ŠWIoUã€EIoUç­‰|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_17_IoU_MPDIoU_ELSEVIER 2023_WIoU_EIoU]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ18ï¼‰â€”â€”æ›´æ¢Neckä¹‹AFPNï¼ˆå…¨æ–°æ¸è¿›ç‰¹å¾é‡‘å­—å¡”|è¶…è¶ŠPAFPN|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_18_Neck_AFPN_PAFPN]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ19ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹Swin TransformerV1ï¼ˆå‚æ•°é‡æ›´å°çš„ViTæ¨¡å‹ï¼‰][YOLOv5_19_Swin TransformerV1_ViT]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ20ï¼‰â€”â€”æ·»åŠ BiFormeræ³¨æ„åŠ›æœºåˆ¶ï¼ˆCVPR2023|å°ç›®æ ‡æ¶¨ç‚¹ç¥å™¨ï¼‰][YOLOv5_20_BiFormer_CVPR2023]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ21ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹RepViTï¼ˆæ¸…å ICCV 2023|æœ€æ–°å¼€æºç§»åŠ¨ç«¯ViTï¼‰][YOLOv5_21_RepViT_ ICCV 2023_ViT]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ22ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹MobileViTv1ï¼ˆä¸€ç§è½»é‡çº§çš„ã€é€šç”¨çš„ç§»åŠ¨è®¾å¤‡ ViTï¼‰][YOLOv5_22_MobileViTv1_ ViT]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ23ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹MobileViTv2ï¼ˆç§»åŠ¨è§†è§‰ Transformer çš„é«˜æ•ˆå¯åˆ†ç¦»è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼‰][YOLOv5_23_MobileViTv2_ Transformer]

![](https://i-blog.csdnimg.cn/blog_migrate/86839dfe5fe7e59488cf10cc3d4041e3.gif)

ç›®å½•

[ğŸš€ä¸€ã€MobileViT v3ä»‹ç» ][MobileViT v3_]

[ğŸš€äºŒã€å…·ä½“æ·»åŠ æ–¹æ³• ][Link 1]

[ç¬¬â‘ æ­¥ï¼šåœ¨common.pyä¸­æ·»åŠ MobileViT v3æ¨¡å—][common.py_MobileViT v3]

[ç¬¬â‘¡æ­¥ï¼šä¿®æ”¹yolo.pyæ–‡ä»¶][yolo.py]

[ç¬¬â‘¢æ­¥ï¼šåˆ›å»ºè‡ªå®šä¹‰çš„yamlæ–‡ä»¶ ][yaml_]

[ç¬¬â‘£æ­¥ éªŒè¯æ˜¯å¦åŠ å…¥æˆåŠŸ][Link 2]

[ğŸŒŸæœ¬äººYOLOv5ç³»åˆ—å¯¼èˆª][YOLOv5]

![](https://i-blog.csdnimg.cn/blog_migrate/3709898b1adfc5eb46af11a6ed72c8ce.gif)

## ğŸš€ä¸€ã€MobileViT v3ä»‹ç» 

>  *  è®ºæ–‡é¢˜ç›®ï¼šã€ŠMOBILEVITV3: MOBILE-FRIENDLY VISION TRANS-  
>     FORMER WITH SIMPLE AND EFFECTIVE FUSION OF LOCAL, GLOBAL AND INPUT FEATURESã€‹
>  *  è®ºæ–‡åŸæ–‡ï¼š [https://arxiv.org/abs/2209.15159][https_arxiv.org_abs_2209.15159]
>  *  æºç åœ°å€ï¼š[https://github.com/micronDLA/MobileViTv3][https_github.com_micronDLA_MobileViTv3]
>  *  è®ºæ–‡ç²¾è¯»ï¼š[MobileViT v3è®ºæ–‡è¶…è¯¦ç»†è§£è¯»ï¼ˆç¿»è¯‘ï¼‹ç²¾è¯»ï¼‰\_è·¯äººè´¾'Ï‰'çš„åšå®¢-CSDNåšå®¢][MobileViT v3_-CSDN]

 åœ¨ä¹‹å‰çš„ç ”ç©¶ä¸­ï¼ŒCNNæ¨¡å‹è¶³å¤Ÿè½»é‡åŒ–ä½†æ˜¯ç²¾å‡†åº¦æœ‰å¾…æé«˜ï¼ŒViTæ¨¡å‹å…·æœ‰è¾ƒå¥½çš„è¯†åˆ«èƒ½åŠ›ä½†æ˜¯æ¨¡å‹å‚æ•°é‡å¤§ï¼Œè®¡ç®—å¤æ‚ï¼Œéƒ½ä¸èƒ½æ»¡è¶³ç§»åŠ¨ç«¯å®æ—¶é«˜æ•ˆæ£€æµ‹çš„éœ€æ±‚ã€‚

MobileViTæ¨¡å‹æ˜¯2021å¹´è‹¹æœå…¬å¸æå‡ºçš„åŸºäºè½»é‡åŒ–çš„ViTæ¨¡å‹ï¼Œè¯¥æ¨¡å‹æ—¢å…·å¤‡ViTæ¨¡å‹å‡†ç¡®æ£€æµ‹çš„ä¼˜è¶Šæ€§èƒ½ï¼Œä¹Ÿå…·å¤‡CNNæ¨¡å‹çš„è½»é‡åŒ–ä¼˜ç‚¹ï¼Œèƒ½æå¤§ç¨‹åº¦ä¸Šå‡å°‘æ¨¡å‹å‚æ•°ï¼Œå¯¹ç§»åŠ¨ç«¯å‹å¥½ï¼Œå…·å¤‡éƒ¨ç½²äºç§»åŠ¨è®¾å¤‡çš„å¯èƒ½æ€§ã€‚

 MobileViT v3æ˜¯è¯¥å…¬å¸2022å¹´9æœˆæ¨å‡ºçš„ç¬¬3ä¸ªç‰ˆæœ¬ï¼Œè¯¥æ¨¡å‹ç›¸è¾ƒäºåˆå§‹ç‰ˆæœ¬æœ‰ä»¥ä¸‹å››ä¸ªæ”¹è¿›ï¼š

 *  é¦–å…ˆï¼Œå°†3Ã—3å·ç§¯å±‚æ›¿æ¢ä¸º1Ã—1å·ç§¯å±‚ï¼›
 *  ç¬¬äºŒï¼Œå°†å±€éƒ¨è¡¨ç¤ºå—å’Œå…¨å±€è¡¨ç¤ºå—çš„ç‰¹å¾èåˆåœ¨ä¸€èµ·ï¼›
 *  ç¬¬ä¸‰ï¼Œåœ¨ç”ŸæˆMobileViT Blockè¾“å‡ºä¹‹å‰ï¼Œåœ¨èåˆå—ä¸­æ·»åŠ è¾“å…¥ç‰¹å¾ä½œä¸ºæœ€åä¸€æ­¥ï¼›
 *  æœ€åï¼Œåœ¨å±€éƒ¨è¡¨ç¤ºå—ä¸­ï¼Œå°†æ™®é€šçš„3Ã—3å·ç§¯å±‚æ›¿æ¢ä¸ºæ·±åº¦3Ã—3å·ç§¯å±‚ã€‚

MobileViTv3ç½‘ç»œç»“æ„å›¾å¦‚ä¸‹æ‰€ç¤ºï¼š

![](https://i-blog.csdnimg.cn/blog_migrate/fd544d151fffbf3e5776ac55923b2a3f.png)

æ¨¡å‹é¢„æµ‹å¤„ç†è¿‡ç¨‹å¦‚ä¸‹ï¼š

ï¼ˆ1ï¼‰å°†è¾“å…¥å›¾åƒè¿æ¥3Ã—3æ ‡å‡†å·ç§¯å¹¶åš2å€ä¸‹é‡‡æ ·ï¼›ä¹‹åé€šè¿‡5ä¸ªMV2æ¨¡å—ï¼ˆå¦‚å›¾ï¼ˆaï¼‰æ‰€ç¤ºï¼‰ï¼Œå…¶ä¸­æ­¥é•¿ä¸º1çš„MV2æ¨¡å—è¿›è¡Œç‰¹å¾æå–ï¼Œæ­¥é•¿ä¸º2çš„MV2æ¨¡å—åš2å€ä¸‹é‡‡æ ·ï¼›

ï¼ˆ2ï¼‰å°†å¾—åˆ°çš„ç‰¹å¾å›¾é—´éš”ä¼ å…¥MobileViTV3 Blockï¼ˆå¦‚å›¾ï¼ˆbï¼‰æ‰€ç¤ºï¼‰å’Œæ­¥é•¿ä¸º2çš„MV2æ¨¡å—ï¼›

ï¼ˆ3ï¼‰æ¥ç€ä½¿ç”¨3Ã—3æ ‡å‡†å·ç§¯è¿›è¡Œé€šé“å‹ç¼©ï¼›

ï¼ˆ4ï¼‰æœ€åè¿›è¡Œå…¨å±€å¹³å‡æ± åŒ–æ¥è·å–é¢„æµ‹ç»“æœ ã€‚

MobileViT v3 Blockæ¨¡å—æ˜¯MobileViT v3æ ¸å¿ƒéƒ¨åˆ†ï¼Œç”±å±€éƒ¨è¡¨å¾æ¨¡å—ã€å…¨å±€è¡¨å¾æ¨¡å—ã€èåˆæ¨¡å—ä¸‰éƒ¨åˆ†ç»„æˆï¼Œå…·ä½“ä»‹ç»å¦‚ä¸‹ï¼š

ï¼ˆ1ï¼‰å±€éƒ¨è¡¨å¾æ¨¡å— 

å¯¹äºè¾“å…¥çš„ç‰¹å¾å›¾åƒ![X\in R^{H\times W\times C}](https://latex.csdn.net/eq?X%5Cin%20R%5E%7BH%5Ctimes%20W%5Ctimes%20C%7D)ï¼ˆ![H](https://latex.csdn.net/eq?H)ã€![W](https://latex.csdn.net/eq?W)ä¸ºå›¾åƒçš„é«˜ã€å®½ï¼›![C](https://latex.csdn.net/eq?C)ä¸ºè¾“å…¥ç‰¹å¾å›¾åƒçš„é€šé“ï¼‰ ï¼Œé¦–å…ˆé‡‡ç”¨ä¸€ä¸ª3Ã—3çš„æ·±åº¦å·ç§¯å±‚å’Œ1Ã—1çš„å·ç§¯å±‚å¾—åˆ°è¾“å‡º![X_{L}\in R^{H\times W\times d}](https://latex.csdn.net/eq?X_%7BL%7D%5Cin%20R%5E%7BH%5Ctimes%20W%5Ctimes%20d%7D)ï¼ˆ![d](https://latex.csdn.net/eq?d)ä¸ºè¾“å‡ºç‰¹å¾å›¾åƒçš„é€šé“ï¼‰ã€‚ç»è¿‡å±€éƒ¨è¡¨å¾æ¨¡å—å¯ä»¥å°†ç‰¹å¾å›¾åƒ![X](https://latex.csdn.net/eq?X)çš„å±€éƒ¨ç©ºé—´ä¿¡æ¯æ˜ å°„åˆ°ç‰¹å®šçš„ç»´åº¦![d](https://latex.csdn.net/eq?d)ä¸­ã€‚

ï¼ˆ2ï¼‰å…¨å±€è¡¨å¾æ¨¡å—

å°†å±€éƒ¨è¡¨å¾æ¨¡å—ä¸­çš„è¾“å‡º![X_{L}](https://latex.csdn.net/eq?X_%7BL%7D)ä½œä¸ºå…¨å±€è¡¨å¾æ¨¡å—çš„è¾“å…¥ï¼Œç„¶åå°†![X_{L}](https://latex.csdn.net/eq?X_%7BL%7D)å±•å¹³ä¸ºæ— é‡å çš„å›¾ç‰‡å—![X_{U}\in R^{P\times N\times d}](https://latex.csdn.net/eq?X_%7BU%7D%5Cin%20R%5E%7BP%5Ctimes%20N%5Ctimes%20d%7D)ï¼ˆ![P](https://latex.csdn.net/eq?P)ä¸ºå±•å¹³å›¾ç‰‡å—çš„å¤§å°ï¼Œ![P=w\times h](https://latex.csdn.net/eq?P%3Dw%5Ctimes%20h)ï¼Œ![w](https://latex.csdn.net/eq?w)ã€![h](https://latex.csdn.net/eq?h)åˆ†åˆ«ä¸ºå±•å¹³å›¾ç‰‡å—çš„å®½ã€é«˜ï¼Œ![N](https://latex.csdn.net/eq?N)ä¸ºå›¾ç‰‡å—çš„ä¸ªæ•°ï¼Œ![N=W\times H/P](https://latex.csdn.net/eq?N%3DW%5Ctimes%20H/P)ï¼‰ã€‚éšåï¼Œå°†æ¯ä¸ªå›¾ç‰‡å—ä¸Šç›¸åŒä½ç½®ä¸Šçš„åƒç´ ![p\in \left \{ 1,...,P \right \}](https://latex.csdn.net/eq?p%5Cin%20%5Cleft%20%5C%7B%201%2C...%2CP%20%5Cright%20%5C%7D)é€å…¥Transformeræ¨¡å—ä¸­è¿›è¡Œç¼–ç ï¼Œå¾—åˆ°![X_{G}\in R^{P\times N\times d}](https://latex.csdn.net/eq?X_%7BG%7D%5Cin%20R%5E%7BP%5Ctimes%20N%5Ctimes%20d%7D)ã€‚ ä¸ºäº†é¿å…å›¾ç‰‡å—ä¹‹é—´çš„ä¿¡æ¯ä¸¢å¤±ï¼Œåœ¨å…¨å±€è¡¨å¾æ¨¡å—çš„æœ€åä¼šå°†ç¼–ç åçš„æ‰€æœ‰å›¾ç‰‡å—é‡ç»„è¿˜åŸï¼Œå¾—åˆ°![X_{F}\in R^{H\times W\times d}](https://latex.csdn.net/eq?X_%7BF%7D%5Cin%20R%5E%7BH%5Ctimes%20W%5Ctimes%20d%7D)ï¼Œç„¶åè¾“å‡ºåˆ°ä¸‹ä¸€ä¸ªæ¨¡å—ã€‚

ï¼ˆ3ï¼‰èåˆæ¨¡å—

å°†![X_{F}](https://latex.csdn.net/eq?X_%7BF%7D)é€å…¥ç‰¹å¾èåˆæ¨¡å—ä¸­ï¼Œä½¿å…¶æ˜ å°„åˆ°ä¸€ä¸ªä½ç»´ç©ºé—´ï¼Œå¾—åˆ°![X^{'}\in R^{H\times Ã—W\times Ã—C}](https://latex.csdn.net/eq?X%5E%7B%27%7D%5Cin%20R%5E%7BH%5Ctimes%20%D7W%5Ctimes%20%D7C%7D)ã€‚ ç„¶åé€šè¿‡æ‹¼æ¥æ“ä½œï¼Œå°†å±€éƒ¨è¡¨å¾æ¨¡å—çš„è¾“å‡º![X_{L}](https://latex.csdn.net/eq?X_%7BL%7D)ä¸![X^{'}](https://latex.csdn.net/eq?X%5E%7B%27%7D)æ‹¼æ¥èµ·æ¥ï¼Œå¾—åˆ°![X^{''}\in R^{H\times Ã—W\times Ã—2C}](https://latex.csdn.net/eq?X%5E%7B%27%27%7D%5Cin%20R%5E%7BH%5Ctimes%20%D7W%5Ctimes%20%D72C%7D)ã€‚æ¥ç€é‡‡ç”¨1Ã—1çš„å·ç§¯å±‚æ¥èåˆå±€éƒ¨ç‰¹å¾![X^{'}](https://latex.csdn.net/eq?X%5E%7B%27%7D)ä¸å…¨å±€ç‰¹å¾![X^{''}](https://latex.csdn.net/eq?X%5E%7B%27%27%7D)ï¼Œå¾—åˆ°![X^{*}\in R^{H\times Ã—W\times Ã—2C}](https://latex.csdn.net/eq?X%5E%7B*%7D%5Cin%20R%5E%7BH%5Ctimes%20%D7W%5Ctimes%20%D72C%7D)ã€‚æœ€åæŠŠåˆšè·å–çš„![X^{*}](https://latex.csdn.net/eq?X%5E%7B*%7D)å’ŒåŸå§‹![X](https://latex.csdn.net/eq?X)è¿›è¡Œç›¸åŠ æ“ä½œï¼Œå¾—åˆ°è¾“å‡º![Y\in R^{H\times W\times C}](https://latex.csdn.net/eq?Y%5Cin%20R%5E%7BH%5Ctimes%20W%5Ctimes%20C%7D)ã€‚

> è¯¥è¿‡ç¨‹éœ€è¦ä¼ªä»£ç å¯ä»¥ç§èŠæˆ‘~

## ğŸš€äºŒã€å…·ä½“æ·»åŠ æ–¹æ³• 

#### ç¬¬â‘ æ­¥ï¼šåœ¨common.pyä¸­æ·»åŠ MobileViT v3æ¨¡å— 

é¦–å…ˆï¼Œå®šä¹‰å·ç§¯å±‚ã€‚

åˆ†ä¸º1Ã—1å·ç§¯å±‚å’ŒnÃ—nï¼ˆn=3ï¼‰å·ç§¯å±‚

```java
def conv_1x1_bn(inp, oup):
    return nn.Sequential(
        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),
        nn.BatchNorm2d(oup),
        nn.SiLU()
    )

def conv_nxn_bn(inp, oup, kernal_size=3, stride=1):
    return nn.Sequential(
        nn.Conv2d(inp, oup, kernal_size, stride, 1, bias=False),
        nn.BatchNorm2d(oup),
        nn.SiLU()
    )
```

æ¥ç€ï¼Œæ„é€ ViTæ¨¡å—ã€‚

Transformer Encoderæ¨¡å—ä¸­ç¼–ç 

```java
class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.norm = nn.LayerNorm(dim)
        self.fn = fn # mg
    
    def forward(self, x, **kwargs):
        return self.fn(self.norm(x), **kwargs)

class Attention(nn.Module):
    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):
        super().__init__()
        inner_dim = dim_head *  heads
        project_out = not (heads == 1 and dim_head == dim)

        self.heads = heads
        self.scale = dim_head ** -0.5

        self.attend = nn.Softmax(dim = -1)
        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)

        self.to_out = nn.Sequential(
            nn.Linear(inner_dim, dim),
            nn.Dropout(dropout)# mg
        ) if project_out else nn.Identity()

    def forward(self, x):
        qkv = self.to_qkv(x).chunk(3, dim=-1)
        q, k, v = map(lambda t: rearrange(t, 'b p n (h d) -> b p h n d', h = self.heads), qkv)

        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale
        attn = self.attend(dots)
        out = torch.matmul(attn, v)
        out = rearrange(out, 'b p h n d -> b p n (h d)')
        return self.to_out(out)

class FeedForward(nn.Module):
    def __init__(self, dim, hidden_dim, dropout=0.):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.SiLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, dim),
            nn.Dropout(dropout)
        )
    
    def forward(self, x):
        return self.net(x)

class MBTransformer(nn.Module):
    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):
        super().__init__()
        self.layers = nn.ModuleList([])
        for _ in range(depth):
            self.layers.append(nn.ModuleList([
                PreNorm(dim, Attention(dim, heads, dim_head, dropout)),
                PreNorm(dim, FeedForward(dim, mlp_dim, dropout))
            ]))
    
    def forward(self, x):
        for attn, ff in self.layers:
            x = attn(x) + x
            x = ff(x) + x
        return x
```

 ç„¶åï¼ŒMV2æ¨¡å—ã€‚

![](https://i-blog.csdnimg.cn/blog_migrate/0bb18c624fc9aa944e73c57a2fc5b41c.png)

åˆ†ä¸ºstride=1å’Œstride=2ä¸¤ç§ã€‚

```java
class MV2Block(nn.Module):
    def __init__(self, inp, oup, stride=1, expansion=4):
        super().__init__()
        self.stride = stride
        assert stride in [1, 2]

        hidden_dim = int(inp * expansion)
        self.use_res_connect = self.stride == 1 and inp == oup

        if expansion == 1:
            self.conv = nn.Sequential(
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.SiLU(),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )
        else:
            self.conv = nn.Sequential(
                # pw
                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.SiLU(),
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.SiLU(),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )

    def forward(self, x):
        if self.use_res_connect:
            return x + self.conv(x)
        else:
            return self.conv(x)
```

æœ€åï¼Œæ ¸å¿ƒæ¨¡å— MobileViTv3\_blockã€‚

ä»‹ç»éƒ¨åˆ†çœ‹ä¸Šé¢å°±è¡Œ~

```java
class MobileViTv3_block(nn.Module):
    def __init__(self, channel, dim, depth=2, kernel_size=3, patch_size=(2, 2), mlp_dim=int(64*2), dropout=0.):
        super().__init__()
        self.ph, self.pw = patch_size
        self.mv01 = MV2Block(channel, channel) 
        self.conv1 = conv_nxn_bn(channel, channel, kernel_size)
        self.conv3 = conv_1x1_bn(dim, channel)
        self.conv2 = conv_1x1_bn(channel, dim)
        self.transformer = MBTransformer(dim, depth, 4, 8, mlp_dim, dropout)
        self.conv4 = conv_nxn_bn(2 * channel, channel, kernel_size)

    def forward(self, x):
        y = x.clone()
        x = self.conv1(x)
        x = self.conv2(x)
        z = x.clone()
        _, _, h, w = x.shape
        x = rearrange(x, 'b d (h ph) (w pw) -> b (ph pw) (h w) d', ph=self.ph, pw=self.pw)
        x = self.transformer(x)
        x = rearrange(x, 'b (ph pw) (h w) d -> b d (h ph) (w pw)', h=h//self.ph, w=w//self.pw, ph=self.ph, pw=self.pw)
        x = self.conv3(x)
        x = torch.cat((x, z), 1)
        x = self.conv4(x)
        x = x + y
        x = self.mv01(x)
        return x
```

ä»¥ä¸‹æ˜¯å®Œæ•´ä»£ç ï¼š

å°†ä»¥ä¸‹ä»£ç å¤åˆ¶ç²˜è´´åˆ°common.pyæ–‡ä»¶çš„æœ«å°¾

```java
from einops import rearrange


def conv_1x1_bn(inp, oup):
    return nn.Sequential(
        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),
        nn.BatchNorm2d(oup),
        nn.SiLU()
    )

def conv_nxn_bn(inp, oup, kernal_size=3, stride=1):
    return nn.Sequential(
        nn.Conv2d(inp, oup, kernal_size, stride, 1, bias=False),
        nn.BatchNorm2d(oup),
        nn.SiLU()
    )

class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.norm = nn.LayerNorm(dim)
        self.fn = fn # mg
    
    def forward(self, x, **kwargs):
        return self.fn(self.norm(x), **kwargs)

class Attention(nn.Module):
    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):
        super().__init__()
        inner_dim = dim_head *  heads
        project_out = not (heads == 1 and dim_head == dim)

        self.heads = heads
        self.scale = dim_head ** -0.5

        self.attend = nn.Softmax(dim = -1)
        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)

        self.to_out = nn.Sequential(
            nn.Linear(inner_dim, dim),
            nn.Dropout(dropout)# mg
        ) if project_out else nn.Identity()

    def forward(self, x):
        qkv = self.to_qkv(x).chunk(3, dim=-1)
        q, k, v = map(lambda t: rearrange(t, 'b p n (h d) -> b p h n d', h = self.heads), qkv)

        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale
        attn = self.attend(dots)
        out = torch.matmul(attn, v)
        out = rearrange(out, 'b p h n d -> b p n (h d)')
        return self.to_out(out)

class FeedForward(nn.Module):
    def __init__(self, dim, hidden_dim, dropout=0.):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.SiLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, dim),
            nn.Dropout(dropout)
        )
    
    def forward(self, x):
        return self.net(x)

class MBTransformer(nn.Module):
    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):
        super().__init__()
        self.layers = nn.ModuleList([])
        for _ in range(depth):
            self.layers.append(nn.ModuleList([
                PreNorm(dim, Attention(dim, heads, dim_head, dropout)),
                PreNorm(dim, FeedForward(dim, mlp_dim, dropout))
            ]))
    
    def forward(self, x):
        for attn, ff in self.layers:
            x = attn(x) + x
            x = ff(x) + x
        return x

class MV2Block(nn.Module):
    def __init__(self, inp, oup, stride=1, expansion=4):
        super().__init__()
        self.stride = stride
        assert stride in [1, 2]

        hidden_dim = int(inp * expansion)
        self.use_res_connect = self.stride == 1 and inp == oup

        if expansion == 1:
            self.conv = nn.Sequential(
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.SiLU(),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )
        else:
            self.conv = nn.Sequential(
                # pw
                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.SiLU(),
                # dw
                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.SiLU(),
                # pw-linear
                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),
                nn.BatchNorm2d(oup),
            )

    def forward(self, x):
        if self.use_res_connect:
            return x + self.conv(x)
        else:
            return self.conv(x)

class MobileViTv3_block(nn.Module):
    def __init__(self, channel, dim, depth=2, kernel_size=3, patch_size=(2, 2), mlp_dim=int(64*2), dropout=0.):
        super().__init__()
        self.ph, self.pw = patch_size
        self.mv01 = MV2Block(channel, channel) 
        self.conv1 = conv_nxn_bn(channel, channel, kernel_size)
        self.conv3 = conv_1x1_bn(dim, channel)
        self.conv2 = conv_1x1_bn(channel, dim)
        self.transformer = MBTransformer(dim, depth, 4, 8, mlp_dim, dropout)
        self.conv4 = conv_nxn_bn(2 * channel, channel, kernel_size)

    def forward(self, x):
        y = x.clone()
        x = self.conv1(x)
        x = self.conv2(x)
        z = x.clone()
        _, _, h, w = x.shape
        x = rearrange(x, 'b d (h ph) (w pw) -> b (ph pw) (h w) d', ph=self.ph, pw=self.pw)
        x = self.transformer(x)
        x = rearrange(x, 'b (ph pw) (h w) d -> b d (h ph) (w pw)', h=h//self.ph, w=w//self.pw, ph=self.ph, pw=self.pw)
        x = self.conv3(x)
        x = torch.cat((x, z), 1)
        x = self.conv4(x)
        x = x + y
        x = self.mv01(x)
        return x
```

#### ç¬¬â‘¡æ­¥ï¼šä¿®æ”¹yolo.pyæ–‡ä»¶ 

å†æ¥ä¿®æ”¹yolo.pyï¼Œåœ¨parse\_modelå‡½æ•°ä¸­æ‰¾åˆ° elif m is Concat: è¯­å¥ï¼Œåœ¨å…¶åé¢åŠ ä¸Šä¸‹é¢ä»£ç ï¼š

```java
elif m in [MobileViTv3_block]:
            c1, c2 = ch[f], args[0]
            if c2 != no:  
                c2 = make_divisible(c2 * gw, 8)
            args = [c1, c2]
            if m in [MobileViTv3_block]:
                args.insert(2, n)  
                n = 1
```

#### ç¬¬â‘¢æ­¥ï¼šåˆ›å»ºè‡ªå®šä¹‰çš„yamlæ–‡ä»¶ 

yamlæ–‡ä»¶é…ç½®å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š

```java
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel iscyy multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32


# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, MobileViTv3_block, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]
# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
```

#### ç¬¬â‘£æ­¥ éªŒè¯æ˜¯å¦åŠ å…¥æˆåŠŸ 

è¿è¡Œyolo.py

![](https://i-blog.csdnimg.cn/blog_migrate/39c3d274fc83ad1f23ee4a192e48886b.png)

è¿™æ ·å°±OKå•¦~

> ä»£ç å‚è€ƒï¼š 
> 
> [YOLOv5ã€YOLOv8æ”¹è¿›ä¸»å¹²ï¼šå…¨ç½‘é¦–å‘æœ€æ–° MobileViTv3 ç³»åˆ—æœ€å¼ºæ”¹è¿›ç‰ˆæœ¬ï¼ˆä¸‰ï¼‰ï½œè½»é‡åŒ–Transformerè§†è§‰è½¬æ¢å™¨ï¼Œç®€å•æœ‰æ•ˆåœ°èåˆäº†æœ¬åœ°å…¨å±€å’Œè¾“å…¥ç‰¹å¾ï¼Œé«˜æ•ˆæ¶¨ç‚¹\_yolov8è½»é‡åŒ–æ”¹è¿›\_èŠ’æœæ±æ²¡æœ‰èŠ’æœçš„åšå®¢-CSDNåšå®¢][YOLOv5_YOLOv8_ MobileViTv3 _Transformer_yolov8_-CSDN]

## ğŸŒŸæœ¬äººYOLOv5ç³»åˆ—å¯¼èˆª 

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif) ğŸ€[YOLOv5æºç ][YOLOv5 1]è¯¦è§£ç³»åˆ—ï¼š

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ1ï¼‰â€”â€”é¡¹ç›®ç›®å½•ç»“æ„è§£æ][YOLOv5_1]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ2ï¼‰â€”â€”æ¨ç†éƒ¨åˆ†detect.py][YOLOv5_2_detect.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ3ï¼‰â€”â€”è®­ç»ƒéƒ¨åˆ†train.py][YOLOv5_3_train.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ4ï¼‰â€”â€”éªŒè¯éƒ¨åˆ†valï¼ˆtestï¼‰.py][YOLOv5_4_val_test_.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ5ï¼‰â€”â€”é…ç½®æ–‡ä»¶yolov5s.yaml][YOLOv5_5_yolov5s.yaml]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ6ï¼‰â€”â€”ç½‘ç»œç»“æ„ï¼ˆ1ï¼‰yolo.py][YOLOv5_6_1_yolo.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ7ï¼‰â€”â€”ç½‘ç»œç»“æ„ï¼ˆ2ï¼‰common.py][YOLOv5_7_2_common.py]

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif) ğŸ€[YOLOv5å…¥é—¨å®è·µ][YOLOv5 1]ç³»åˆ—ï¼š

[YOLOv5å…¥é—¨å®è·µï¼ˆ1ï¼‰â€”â€”æ‰‹æŠŠæ‰‹å¸¦ä½ ç¯å¢ƒé…ç½®æ­å»º][YOLOv5_1 1]

[YOLOv5å…¥é—¨å®è·µï¼ˆ2ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ åˆ©ç”¨labelimgæ ‡æ³¨æ•°æ®é›†][YOLOv5_2_labelimg]

[YOLOv5å…¥é—¨å®è·µï¼ˆ3ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ åˆ’åˆ†è‡ªå·±çš„æ•°æ®é›†][YOLOv5_3]

[YOLOv5å…¥é—¨å®è·µï¼ˆ4ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†][YOLOv5_4]

[YOLOv5å…¥é—¨å®è·µï¼ˆ5ï¼‰â€”â€”ä»é›¶å¼€å§‹ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒè‡ªå·±çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆåŒ…å«pyqt5ç•Œé¢ï¼‰][YOLOv5_5_pyqt5]

![](https://i-blog.csdnimg.cn/blog_migrate/16dba0d75cda098194f5e0d3473cbff1.gif)


[YOLOv5_0]: https://blog.csdn.net/weixin_43334693/article/details/130564848?spm=1001.2014.3001.5501
[YOLOv5_1_SE]: https://blog.csdn.net/weixin_43334693/article/details/130551913?spm=1001.2014.3001.5501
[YOLOv5_2_CBAM]: https://blog.csdn.net/weixin_43334693/article/details/130587102?spm=1001.2014.3001.5501
[YOLOv5_3_CA]: https://blog.csdn.net/weixin_43334693/article/details/130619604?spm=1001.2014.3001.5501
[YOLOv5_4_ECA]: https://blog.csdn.net/weixin_43334693/article/details/130641318?spm=1001.2014.3001.5501
[YOLOv5_5_ MobileNetV3]: https://blog.csdn.net/weixin_43334693/article/details/130832933?spm=1001.2014.3001.5501
[YOLOv5_6_ ShuffleNetV2]: https://blog.csdn.net/weixin_43334693/article/details/131008642?spm=1001.2014.3001.5501
[YOLOv5_7_SimAM]: https://blog.csdn.net/weixin_43334693/article/details/131031541?spm=1001.2014.3001.5501
[YOLOv5_8_SOCA]: https://blog.csdn.net/weixin_43334693/article/details/131053284?spm=1001.2014.3001.5501
[YOLOv5_9_EfficientNetv2]: https://blog.csdn.net/weixin_43334693/article/details/131207097?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22131207097%22%2C%22source%22%3A%22weixin_43334693%22%7D
[YOLOv5_10_GhostNet]: https://blog.csdn.net/weixin_43334693/article/details/131235113?spm=1001.2014.3001.5501
[YOLOv5_11_EIoU_AlphaIoU_SIoU_WIoU]: https://blog.csdn.net/weixin_43334693/article/details/131350224?spm=1001.2014.3001.5501
[YOLOv5_12_Neck_BiFPN]: https://blog.csdn.net/weixin_43334693/article/details/131461294?spm=1001.2014.3001.5501
[YOLOv5_13_SiLU_ReLU_ELU_Hardswish_Mish_Softplus_AconC]: https://blog.csdn.net/weixin_43334693/article/details/131513850?spm=1001.2014.3001.5502
[YOLOv5_14_NMS_ DIoU-NMS_CIoU-NMS_EIoU-NMS_GIoU-NMS _SIoU-NMS_Soft-NMS]: https://blog.csdn.net/weixin_43334693/article/details/131552028?spm=1001.2014.3001.5501
[YOLOv5_15]: https://blog.csdn.net/weixin_43334693/article/details/131613721?spm=1001.2014.3001.5502
[YOLOv5_16_EMA_ICASSP2023]: https://blog.csdn.net/weixin_43334693/article/details/131973273?spm=1001.2014.3001.5501
[YOLOv5_17_IoU_MPDIoU_ELSEVIER 2023_WIoU_EIoU]: https://blog.csdn.net/weixin_43334693/article/details/131999141?spm=1001.2014.3001.5501
[YOLOv5_18_Neck_AFPN_PAFPN]: https://blog.csdn.net/weixin_43334693/article/details/132070079?spm=1001.2014.3001.5501
[YOLOv5_19_Swin TransformerV1_ViT]: https://blog.csdn.net/weixin_43334693/article/details/132161488?spm=1001.2014.3001.5501
[YOLOv5_20_BiFormer_CVPR2023]: https://blog.csdn.net/weixin_43334693/article/details/132203200?spm=1001.2014.3001.5502
[YOLOv5_21_RepViT_ ICCV 2023_ViT]: https://blog.csdn.net/weixin_43334693/article/details/132211831?spm=1001.2014.3001.5501
[YOLOv5_22_MobileViTv1_ ViT]: https://blog.csdn.net/weixin_43334693/article/details/132367429?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22132367429%22%2C%22source%22%3A%22weixin_43334693%22%7D
[YOLOv5_23_MobileViTv2_ Transformer]: https://blog.csdn.net/weixin_43334693/article/details/132428203?spm=1001.2014.3001.5502
[MobileViT v3_]: #%F0%9F%9A%80%E4%B8%80%E3%80%81MobileViT%20v3%E4%BB%8B%E7%BB%8D%C2%A0%C2%A0%C2%A0%C2%A0
[Link 1]: #%F0%9F%9A%80%E4%BA%8C%E3%80%81%E5%85%B7%E4%BD%93%E6%B7%BB%E5%8A%A0%E6%96%B9%E6%B3%95%C2%A0
[common.py_MobileViT v3]: #%E7%AC%AC%E2%91%A0%E6%AD%A5%EF%BC%9A%E5%9C%A8common.py%E4%B8%AD%E6%B7%BB%E5%8A%A0SE%E6%A8%A1%E5%9D%97
[yolo.py]: #%C2%A0%E7%AC%AC%E2%91%A1%E6%AD%A5%EF%BC%9A%E5%9C%A8yolo.py%E6%96%87%E4%BB%B6%E9%87%8C%E7%9A%84parse_model%E5%87%BD%E6%95%B0%E5%8A%A0%E5%85%A5%E7%B1%BB%E5%90%8D
[yaml_]: #%C2%A0%E7%AC%AC%E2%91%A2%E6%AD%A5%EF%BC%9A%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84yaml%E6%96%87%E4%BB%B6%C2%A0%C2%A0
[Link 2]: #%E7%AC%AC%E2%91%A3%E6%AD%A5%20%E9%AA%8C%E8%AF%81%E6%98%AF%E5%90%A6%E5%8A%A0%E5%85%A5%E6%88%90%E5%8A%9F
[YOLOv5]: #%F0%9F%8C%9F%E6%9C%AC%E4%BA%BAYOLOv5%E7%B3%BB%E5%88%97%E5%AF%BC%E8%88%AA
[https_arxiv.org_abs_2209.15159]: https://arxiv.org/abs/2209.15159
[https_github.com_micronDLA_MobileViTv3]: https://github.com/micronDLA/MobileViTv3
[MobileViT v3_-CSDN]: https://blog.csdn.net/weixin_43334693/article/details/132742052?spm=1001.2014.3001.5502
[YOLOv5_YOLOv8_ MobileViTv3 _Transformer_yolov8_-CSDN]: https://yoloair.blog.csdn.net/article/details/127107758
[YOLOv5 1]: https://so.csdn.net/so/search?q=YOLOv5%E6%BA%90%E7%A0%81&spm=1001.2101.3001.7020
[YOLOv5_1]: https://blog.csdn.net/weixin_43334693/article/details/129356033?spm=1001.2014.3001.5501
[YOLOv5_2_detect.py]: https://blog.csdn.net/weixin_43334693/article/details/129349094?spm=1001.2014.3001.5501
[YOLOv5_3_train.py]: https://blog.csdn.net/weixin_43334693/article/details/129460666?spm=1001.2014.3001.5501
[YOLOv5_4_val_test_.py]: https://blog.csdn.net/weixin_43334693/article/details/129649553?spm=1001.2014.3001.5501
[YOLOv5_5_yolov5s.yaml]: https://blog.csdn.net/weixin_43334693/article/details/129697521?spm=1001.2014.3001.5501
[YOLOv5_6_1_yolo.py]: https://blog.csdn.net/weixin_43334693/article/details/129803802?spm=1001.2014.3001.5501
[YOLOv5_7_2_common.py]: https://blog.csdn.net/weixin_43334693/article/details/129854764?spm=1001.2014.3001.5501
[YOLOv5_1 1]: https://blog.csdn.net/weixin_43334693/article/details/129981848?spm=1001.2014.3001.5501
[YOLOv5_2_labelimg]: https://blog.csdn.net/weixin_43334693/article/details/129995604?spm=1001.2014.3001.5501
[YOLOv5_3]: https://blog.csdn.net/weixin_43334693/article/details/130025866?spm=1001.2014.3001.5501
[YOLOv5_4]: https://blog.csdn.net/weixin_43334693/article/details/130043351?spm=1001.2014.3001.5501
[YOLOv5_5_pyqt5]: https://blog.csdn.net/weixin_43334693/article/details/130044342?spm=1001.2014.3001.5501