![](https://i-blog.csdnimg.cn/blog_migrate/ab833e167e45b1101669106e3d5b8b5d.gif)

![](https://i-blog.csdnimg.cn/blog_migrate/38dd9fc70e8e4ebe778145f36dde11d1.png)

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif)ã€YOLOv5æ”¹è¿›ç³»åˆ—ã€‘å‰æœŸå›é¡¾ï¼š

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ0ï¼‰â€”â€”é‡è¦æ€§èƒ½æŒ‡æ ‡ä¸è®­ç»ƒç»“æœè¯„ä»·åŠåˆ†æ][YOLOv5_0]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ1ï¼‰â€”â€”æ·»åŠ SEæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_1_SE]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ2ï¼‰â€”â€”æ·»åŠ CBAMæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_2_CBAM]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ3ï¼‰â€”â€”æ·»åŠ CAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_3_CA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ4ï¼‰â€”â€”æ·»åŠ ECAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_4_ECA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ5ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹ MobileNetV3][YOLOv5_5_ MobileNetV3]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ6ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹ ShuffleNetV2][YOLOv5_6_ ShuffleNetV2]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ7ï¼‰â€”â€”æ·»åŠ SimAMæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_7_SimAM]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ8ï¼‰â€”â€”æ·»åŠ SOCAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_8_SOCA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ9ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹EfficientNetv2][YOLOv5_9_EfficientNetv2]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ10ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹GhostNet][YOLOv5_10_GhostNet]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ11ï¼‰â€”â€”æ·»åŠ æŸå¤±å‡½æ•°ä¹‹EIoUã€AlphaIoUã€SIoUã€WIoU][YOLOv5_11_EIoU_AlphaIoU_SIoU_WIoU]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ12ï¼‰â€”â€”æ›´æ¢Neckä¹‹BiFPN][YOLOv5_12_Neck_BiFPN]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ13ï¼‰â€”â€”æ›´æ¢æ¿€æ´»å‡½æ•°ä¹‹SiLUï¼ŒReLUï¼ŒELUï¼ŒHardswishï¼ŒMishï¼ŒSoftplusï¼ŒAconCç³»åˆ—ç­‰][YOLOv5_13_SiLU_ReLU_ELU_Hardswish_Mish_Softplus_AconC][YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ14ï¼‰â€”â€”æ›´æ¢NMSï¼ˆéæå¤§æŠ‘åˆ¶ï¼‰ä¹‹ DIoU-NMSã€CIoU-NMSã€EIoU-NMSã€GIoU-NMS ã€SIoU-NMSã€Soft-NMS][YOLOv5_14_NMS_ DIoU-NMS_CIoU-NMS_EIoU-NMS_GIoU-NMS _SIoU-NMS_Soft-NMS]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ15ï¼‰â€”â€”å¢åŠ å°ç›®æ ‡æ£€æµ‹å±‚][YOLOv5_15]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ16ï¼‰â€”â€”æ·»åŠ EMAæ³¨æ„åŠ›æœºåˆ¶ï¼ˆICASSP2023|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_16_EMA_ICASSP2023]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ17ï¼‰â€”â€”æ›´æ¢IoUä¹‹MPDIoUï¼ˆELSEVIER 2023|è¶…è¶ŠWIoUã€EIoUç­‰|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_17_IoU_MPDIoU_ELSEVIER 2023_WIoU_EIoU]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ18ï¼‰â€”â€”æ›´æ¢Neckä¹‹AFPNï¼ˆå…¨æ–°æ¸è¿›ç‰¹å¾é‡‘å­—å¡”|è¶…è¶ŠPAFPN|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_18_Neck_AFPN_PAFPN]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ19ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹Swin TransformerV1ï¼ˆå‚æ•°é‡æ›´å°çš„ViTæ¨¡å‹ï¼‰][YOLOv5_19_Swin TransformerV1_ViT]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ21ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹RepViTï¼ˆæ¸…å ICCV 2023|æœ€æ–°å¼€æºç§»åŠ¨ç«¯ViTï¼‰][YOLOv5_21_RepViT_ ICCV 2023_ViT]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ22ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹MobileViTv1ï¼ˆä¸€ç§è½»é‡çº§çš„ã€é€šç”¨çš„ç§»åŠ¨è®¾å¤‡ ViTï¼‰][YOLOv5_22_MobileViTv1_ ViT]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ23ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹MobileViTv2ï¼ˆç§»åŠ¨è§†è§‰ Transformer çš„é«˜æ•ˆå¯åˆ†ç¦»è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼‰][YOLOv5_23_MobileViTv2_ Transformer]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ24ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹MobileViTv3ï¼ˆç§»åŠ¨ç«¯è½»é‡åŒ–ç½‘ç»œçš„è¿›ä¸€æ­¥å‡çº§ï¼‰][YOLOv5_24_MobileViTv3]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ25ï¼‰â€”â€”æ·»åŠ LSKNetæ³¨æ„åŠ›æœºåˆ¶ï¼ˆå¤§é€‰æ‹©æ€§å·ç§¯æ ¸çš„é¢†åŸŸé¦–æ¬¡æ¢ç´¢ï¼‰][YOLOv5_25_LSKNet]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ26ï¼‰â€”â€”æ·»åŠ RFAConvæ³¨æ„åŠ›å·ç§¯ï¼ˆæ„Ÿå—é‡æ³¨æ„åŠ›å·ç§¯è¿ç®—ï¼‰][YOLOv5_26_RFAConv]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ27ï¼‰â€”â€”æ·»åŠ SCConvæ³¨æ„åŠ›å·ç§¯ï¼ˆCVPR 2023|å³æ’å³ç”¨çš„é«˜æ•ˆå·ç§¯æ¨¡å—ï¼‰][YOLOv5_27_SCConv_CVPR 2023]

![](https://i-blog.csdnimg.cn/blog_migrate/87e1f45ae909f6c51cbb0ddb973a19b6.gif)

ç›®å½•

[ğŸš€ ä¸€ã€DSConvä»‹ç» ][_DSConv_]

[1.1 DSConvç®€ä»‹][1.1 DSConv]

[ 1.2 åŠ¨æ€è›‡å½¢å·ç§¯][1.2]

[1.3 å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥][1.3]

[ 1.4 è¿ç»­æ€§æ‹“æ‰‘çº¦æŸæŸå¤±][1.4]

[ğŸš€äºŒã€å…·ä½“æ·»åŠ æ–¹æ³•][Link 1]

[2.1 æ·»åŠ é¡ºåº ][2.1 _]

[2.2 å…·ä½“æ·»åŠ æ­¥éª¤ ][2.2 _]

[ç¬¬â‘ æ­¥ï¼šåœ¨common.pyä¸­æ·»åŠ DCConvæ¨¡å— ][common.py_DCConv_]

[ç¬¬â‘¡æ­¥ï¼šä¿®æ”¹yolo.pyæ–‡ä»¶ ][yolo.py_]

[ç¬¬â‘¢æ­¥ï¼šåˆ›å»ºè‡ªå®šä¹‰çš„yamlæ–‡ä»¶ ][yaml_]

[ç¬¬â‘£æ­¥ï¼šéªŒè¯æ˜¯å¦åŠ å…¥æˆåŠŸ][Link 2]

[ğŸŒŸæœ¬äººYOLOv5ç³»åˆ—å¯¼èˆª][YOLOv5]

![](https://i-blog.csdnimg.cn/blog_migrate/70c24b84eba53cad07e275ce219f0ac2.gif)

## ğŸš€ ä¸€ã€DSConvä»‹ç» 

> å­¦ä¹ èµ„æ–™ï¼š
> 
>  *  è®ºæ–‡é¢˜ç›®ï¼šã€ŠDynamic Snake Convolution based on Topological Geometric Constraints for Tubular Structure Segmentationã€‹
>  *  è®ºæ–‡åœ°å€ï¼š[https://arxiv.org/abs/2307.08388][https_arxiv.org_abs_2307.08388]
>  *  æºç åœ°å€ï¼š[https://github.com/YaoleiQi/DSCNet][https_github.com_YaoleiQi_DSCNet]

### 1.1 DSConvç®€ä»‹ 

èƒŒæ™¯

ç®¡çŠ¶ç»“æ„ï¼ˆä¾‹å¦‚è¡€ç®¡ã€é“è·¯ï¼‰æ˜¯ä¸´åºŠã€è‡ªç„¶ç•Œç­‰å„é¢†åŸŸåœºæ™¯ä¸­ååˆ†é‡è¦çš„ä¸€ç§ç»“æ„ï¼Œå…¶ç²¾ç¡®åˆ†å‰²å¯ä»¥ä¿è¯ä¸‹æ¸¸ä»»åŠ¡çš„å‡†ç¡®æ€§ä¸æ•ˆç‡ã€‚ä½†ç®¡çŠ¶ç»“æ„çš„ç²¾ç¡®æå–ä»ç„¶é¢ä¸´ç€ä¼—å¤šæŒ‘æˆ˜ï¼š

 *  ç»†é•¿ä¸”è„†å¼±çš„å±€éƒ¨ç»“æ„ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œç»†é•¿çš„ç»“æ„ä»…å æ•´ä¸ªå›¾åƒçš„ä¸€å°éƒ¨åˆ†ï¼Œåƒç´ çš„ç»„æˆæœ‰é™ã€‚æ­¤å¤–ï¼Œè¿™äº›ç»“æ„å®¹æ˜“å—åˆ°å¤æ‚èƒŒæ™¯çš„å¹²æ‰°ï¼Œå› æ­¤æ¨¡å‹å¾ˆéš¾ç²¾ç¡®åˆ†è¾¨ç›®æ ‡çš„ç»†å¾®å˜åŒ–ï¼Œä»è€Œå¯¼è‡´åˆ†å‰²å‡ºç°ç ´ç¢ä¸æ–­è£‚ã€‚
 *  å¤æ‚ä¸”å¤šå˜çš„å…¨å±€å½¢æ€ã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºç»†é•¿ç®¡çŠ¶ç»“æ„å¤æ‚å¤šå˜çš„å½¢æ€ï¼Œå³ä½¿åœ¨åŒä¸€å¼ å›¾åƒä¸­ä¹Ÿæ˜¯å¦‚æ­¤ã€‚ä½äºä¸åŒåŒºåŸŸçš„ç›®æ ‡çš„å½¢æ€å˜åŒ–å–å†³äºåˆ†æ”¯çš„æ•°é‡ã€åˆ†å‰çš„ä½ç½®ï¼Œè·¯å¾„é•¿åº¦ä»¥åŠå…¶åœ¨å›¾åƒä¸­çš„ä½ç½®ã€‚å› æ­¤å½“æ•°æ®è¡¨ç°å‡ºæœªæ›¾è§è¿‡çš„å½¢æ€ç‰¹å¾æ—¶ï¼Œæ¨¡å‹å€¾å‘äºè¿‡æ‹Ÿåˆåˆ°å·²è§è¿‡çš„ç‰¹å¾ï¼Œæ— æ³•è¯†åˆ«æœªè§è¿‡çš„ç‰¹å¾å½¢æ€ï¼Œä»è€Œå¯¼è‡´æ³›åŒ–æ€§è¾ƒå¼±ã€‚

![](https://i-blog.csdnimg.cn/blog_migrate/e3567b4edaab39eb9f6cd7afbdd68eb0.png)

æœ¬æ–‡ä¸»è¦å·¥ä½œ 

æœ¬æ–‡å…³æ³¨åˆ°ç®¡çŠ¶ç»“æ„ç»†é•¿è¿ç»­çš„ç‰¹ç‚¹ï¼Œå¹¶åˆ©ç”¨è¿™ä¸€ä¿¡æ¯åœ¨ç¥ç»ç½‘ç»œä»¥ä¸‹ä¸‰ä¸ªé˜¶æ®µåŒæ—¶å¢å¼ºæ„ŸçŸ¥ï¼šç‰¹å¾æå–ã€ç‰¹å¾èåˆå’ŒæŸå¤±çº¦æŸã€‚åˆ†åˆ«è®¾è®¡äº†åŠ¨æ€è›‡å½¢å·ç§¯ï¼ˆDynamic Snake Convolutionï¼‰ï¼Œå¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥ä¸è¿ç»­æ€§æ‹“æ‰‘çº¦æŸæŸå¤±ã€‚æˆ‘ä»¬åŒæ—¶ç»™å‡ºäº†åŸºäº 2D å’Œ 3D çš„æ–¹æ³•è®¾è®¡ï¼Œé€šè¿‡å®éªŒè¯æ˜äº†æœ¬æ–‡æ‰€æå‡ºçš„ DSCNet åœ¨ç®¡çŠ¶ç»“æ„åˆ†å‰²ä»»åŠ¡ä¸Šæä¾›äº†æ›´å¥½çš„ç²¾åº¦å’Œè¿ç»­æ€§ã€‚

### 1.2 åŠ¨æ€è›‡å½¢å·ç§¯ 

![](https://i-blog.csdnimg.cn/blog_migrate/f454d875df0ccb933c480fd7708d3910.png)

ç›®çš„ï¼š

 *  å¸Œæœ›å·ç§¯æ ¸ä¸€æ–¹é¢èƒ½å¤Ÿè‡ªç”±åœ°è´´åˆç»“æ„å­¦ä¹ ç‰¹å¾
 *  å¦ä¸€æ–¹é¢èƒ½å¤Ÿåœ¨çº¦æŸæ¡ä»¶ä¸‹ä¸åç¦»ç›®æ ‡ç»“æ„å¤ªè¿œ

å¯å˜å½¢å·ç§¯ï¼š

 *  æ“æ§å•ä¸ªå·ç§¯æ ¸å½¢å˜çš„æ‰€æœ‰åç½®(offset)ï¼Œæ˜¯åœ¨ç½‘ç»œä¸­ä¸€æ¬¡æ€§å…¨éƒ¨å­¦åˆ°çš„
 *  å¯¹äºè¿™ä¸€ä¸ªåç½®åªæœ‰ä¸€ä¸ªèŒƒå›´çš„çº¦æŸï¼Œå³æ„Ÿå—é‡èŒƒå›´(extend)
 *  æ§åˆ¶æ‰€æœ‰çš„å·ç§¯å‘ç”Ÿå½¢å˜ï¼Œæ˜¯ä¾èµ–äºæ•´ä¸ªç½‘ç»œæœ€ç»ˆçš„æŸå¤±çº¦æŸå›ä¼ ï¼Œè¿™ä¸ªå˜åŒ–è¿‡ç¨‹æ˜¯ç›¸å½“è‡ªç”±çš„ã€‚

### 1.3 å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥ 

![](https://i-blog.csdnimg.cn/blog_migrate/700cab0a073cdb4fbfd72f5e8c628043.png)

ç›®çš„ï¼š

 *  ç®¡çŠ¶ç»“æ„çš„èµ°å‘ä¸è§†è§’ä¸æ˜¯å•ä¸€çš„ï¼Œå› æ­¤åœ¨è®¾è®¡ä¸­èåˆå¤šè§†è§’ç‰¹å¾ä¹Ÿæ˜¯å¿…ç„¶çš„é€‰æ‹©ã€‚

æŒ‘æˆ˜ï¼š

 *  èåˆæ›´å¤šçš„ç‰¹å¾ä¼šå¯¼è‡´æ›´å¤§çš„ç½‘ç»œè´Ÿè½½ä»¥åŠå‡ºç°å†—ä½™ã€‚

æ–¹æ³•ï¼š

 *  åœ¨ç‰¹å¾èåˆçš„è®­ç»ƒè¿‡ç¨‹ä¸­åŠ å…¥äº†åˆ†ç»„ä¸dropoutçš„ç­–ç•¥ï¼Œä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†ç½‘ç»œå†…å†…å­˜çš„å‹åŠ›å¹¶é¿å…æ¨¡å‹é™·å…¥è¿‡æ‹Ÿåˆã€‚

### 1.4 è¿ç»­æ€§æ‹“æ‰‘çº¦æŸæŸå¤± 

![](https://i-blog.csdnimg.cn/blog_migrate/b3d0df27308f93b26e182819d6dabd4b.png)

ç›®çš„ï¼š

 *  æ„å»ºæ•°æ®çš„æ‹“æ‰‘ç»“æ„ï¼Œå¹¶æå–å¤æ‚ç®¡çŠ¶ç»“æ„ä¸­çš„é«˜ç»´å…³ç³»ï¼Œä¹Ÿå°±æ˜¯æŒç»­åŒæºæ€§ï¼ˆPersistence Homology, PHï¼‰ã€‚

å¯å‘ï¼š

 *  å‡è®¾ PO çš„ä¸Šç«¯å­˜åœ¨ç€ä¸€ä¸ªå¼‚å¸¸çš„ç¦»æ•£ç‚¹ï¼ˆæ¨ªåæ ‡è¡¨ç¤ºå‡ºç°çš„æ—¶é—´ï¼Œçºµåæ ‡è¡¨ç¤ºæ¶ˆå¤±çš„æ—¶é—´ï¼‰ï¼Œè¿™è¡¨æ˜å­˜åœ¨ä¸€ä¸ªæ„ä»¶ç›´åˆ°æœ€åæ‰ä¸å…¶ä»–æ„ä»¶è·å¾—è¿æ¥ä»è€Œæ¶ˆå¤±ã€‚

æ–¹æ³•ï¼š 

 *  æœ¬æ–‡ä¸­é‡‡ç”¨çš„æ˜¯è±ªæ–¯å¤šå¤«è·ç¦»ï¼ˆHausdorff Distance, HDï¼‰ï¼ŒHD ä¹Ÿæ˜¯ç”¨äºè¡¡é‡ç‚¹é›†ç›¸ä¼¼åº¦çš„ä¸€ä¸ªé‡è¦ç®—æ³•ï¼Œå¯¹ç¦»æ•£ç‚¹ä¹Ÿéå¸¸æ•æ„Ÿã€‚

```java
# -*- coding: utf-8 -*-

import torch

from torch import nn
from torch.nn.functional import max_pool3d


class crossentry(nn.Module):

    def __init__(self):
        super().__init__()

    def forward(self, y_true, y_pred):
        smooth = 1e-6
        return -torch.mean(y_true * torch.log(y_pred + smooth))


class cross_loss(nn.Module):

    def __init__(self):
        super().__init__()

    def forward(self, y_true, y_pred):
        smooth = 1e-6
        return -torch.mean(y_true * torch.log(y_pred + smooth) +
                           (1 - y_true) * torch.log(1 - y_pred + smooth))


'''
Another Loss Function proposed by us in IEEE transactions on Image Precessing:
Paper: https://ieeexplore.ieee.org/abstract/document/9611074
Code: https://github.com/YaoleiQi/Examinee-Examiner-Network
'''


class Dropoutput_Layer(nn.Module):

    def __init__(self):
        super().__init__()

    def forward(self, y_true, y_pred, alpha=0.4):
        smooth = 1e-6
        w = torch.abs(y_true - y_pred)
        w = torch.round(w + alpha)
        loss_ce = (
            -((torch.sum(w * y_true * torch.log(y_pred + smooth)) /
               torch.sum(w * y_true + smooth)) +
              (torch.sum(w * (1 - y_true) * torch.log(1 - y_pred + smooth)) /
               torch.sum(w * (1 - y_true) + smooth))) / 2)
        return loss_ce
```

## ğŸš€äºŒã€å…·ä½“æ·»åŠ æ–¹æ³• 

### 2.1 æ·»åŠ é¡ºåº 

ï¼ˆ1ï¼‰models/common.py --> åŠ å…¥æ–°å¢çš„ç½‘ç»œç»“æ„

ï¼ˆ2ï¼‰ models/yolo.py -->  è®¾å®šç½‘ç»œç»“æ„çš„ä¼ å‚ç»†èŠ‚ï¼Œå°†DSConvç±»ååŠ å…¥å…¶ä¸­ã€‚ï¼ˆå½“æ–°çš„è‡ªå®šä¹‰æ¨¡å—ä¸­å­˜åœ¨è¾“å…¥è¾“å‡ºç»´åº¦æ—¶ï¼Œè¦ä½¿ç”¨qwè°ƒæ•´è¾“å‡ºç»´åº¦ï¼‰  
ï¼ˆ3ï¼‰ models/yolov5\*.yaml -->  æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œå¦‚yolov5s\_DSConv.yamlï¼Œä¿®æ”¹ç°æœ‰æ¨¡å‹ç»“æ„é…ç½®æ–‡ä»¶ã€‚ï¼ˆå½“å¼•å…¥æ–°çš„å±‚æ—¶ï¼Œè¦ä¿®æ”¹åç»­çš„ç»“æ„ä¸­çš„fromå‚æ•°ï¼‰  
ï¼ˆ4ï¼‰ train.py -->  ä¿®æ”¹â€˜--cfgâ€™é»˜è®¤å‚æ•°ï¼Œè®­ç»ƒæ—¶æŒ‡å®šæ¨¡å‹ç»“æ„é…ç½®æ–‡ä»¶

### 2.2 å…·ä½“æ·»åŠ æ­¥éª¤ 

#### ç¬¬â‘ æ­¥ï¼šåœ¨common.pyä¸­æ·»åŠ DCConvæ¨¡å—  

å°†ä¸‹é¢çš„DSConvä»£ç å¤åˆ¶ç²˜è´´åˆ°common.pyæ–‡ä»¶çš„æœ«å°¾ã€‚

```java
# by:è¿ªè²èµ«å°”æ›¼
import warnings
import torch
from torch import nn

warnings.filterwarnings("ignore")

"""
This code is mainly the deformation process of our DSConv
"""

class DSConv(nn.Module):

    def __init__(self, in_ch, out_ch, kernel_size, extend_scope, morph,
                 if_offset):
        """
        åŠ¨æ€è›‡å½¢å·ç§¯
        :param in_ch: è¾“å…¥é€šé“
        :param out_ch: è¾“å‡ºé€šé“
        :param kernel_size: å·ç§¯æ ¸çš„å¤§å°
        :param extend_scope: æ‰©å±•èŒƒå›´ï¼ˆé»˜è®¤ä¸ºæ­¤æ–¹æ³•çš„1ï¼‰
        :param morph: å·ç§¯æ ¸çš„å½¢æ€ä¸»è¦åˆ†ä¸ºä¸¤ç§ç±»å‹ï¼Œæ²¿xè½´ï¼ˆ0ï¼‰å’Œæ²¿yè½´ï¼ˆ1ï¼‰ï¼ˆè¯¦ç»†ä¿¡æ¯è¯·å‚é˜…è®ºæ–‡ï¼‰
        :param if_offset: æ˜¯å¦éœ€è¦å˜å½¢ï¼Œå¦‚æœä¸ºFalseï¼Œåˆ™æ˜¯æ ‡å‡†å·ç§¯æ ¸
        """
        super(DSConv, self).__init__()
        # use the <offset_conv> to learn the deformable offset
        # offset_conv: å­¦ä¹ å¯å˜å½¢åç§»çš„å·ç§¯å±‚
        self.offset_conv = nn.Conv2d(in_ch, 2 * kernel_size, 3, padding=1)
        self.bn = nn.BatchNorm2d(2 * kernel_size)
        self.kernel_size = kernel_size

        # two types of the DSConv (along x-axis and y-axis)
        # dsc_conv_x å’Œ dsc_conv_yï¼šä¸¤ç§åŠ¨æ€è›‡å½¢å·ç§¯å±‚ï¼Œåˆ†åˆ«æ²¿xè½´å’Œyè½´ã€‚
        self.dsc_conv_x = nn.Conv2d(
            in_ch,
            out_ch,
            kernel_size=(kernel_size, 1),
            stride=(kernel_size, 1),
            padding=0,
        )
        self.dsc_conv_y = nn.Conv2d(
            in_ch,
            out_ch,
            kernel_size=(1, kernel_size),
            stride=(1, kernel_size),
            padding=0,
        )
        
        # gnï¼šç»„å½’ä¸€åŒ–å±‚
        self.gn = nn.GroupNorm(out_ch // 4, out_ch)
        self.relu = nn.ReLU(inplace=True)
        
        # extend_scopeï¼šæ‰©å±•èŒƒå›´
        self.extend_scope = extend_scope
        # morphï¼šå·ç§¯æ ¸å½¢æ€çš„ç±»å‹
        self.morph = morph
        # if_offsetï¼šæŒ‡ç¤ºæ˜¯å¦éœ€è¦å˜å½¢çš„å¸ƒå°”å€¼
        self.if_offset = if_offset

    def forward(self, f):
        offset = self.offset_conv(f)
        offset = self.bn(offset)
        # We need a range of deformation between -1 and 1 to mimic the snake's swing
        offset = torch.tanh(offset)
        input_shape = f.shape
        dsc = DSC(input_shape, self.kernel_size, self.extend_scope, self.morph)
        deformed_feature = dsc.deform_conv(f, offset, self.if_offset)
        if self.morph == 0:
            x = self.dsc_conv_x(deformed_feature.type(f.dtype))
            x = self.gn(x)
            x = self.relu(x)
            return x
        else:
            x = self.dsc_conv_y(deformed_feature.type(f.dtype))
            x = self.gn(x)
            x = self.relu(x)
            return x


# Core code, for ease of understanding, we mark the dimensions of input and output next to the code
class DSC(object):

    def __init__(self, input_shape, kernel_size, extend_scope, morph):
        self.num_points = kernel_size
        self.width = input_shape[2]
        self.height = input_shape[3]
        self.morph = morph
        self.extend_scope = extend_scope  # offset (-1 ~ 1) * extend_scope

        # define feature map shape
        """
        B: Batch size  C: Channel  W: Width  H: Height
        """
        self.num_batch = input_shape[0]
        self.num_channels = input_shape[1]

    """
    input: offset [B,2*K,W,H]  K: Kernel size (2*K: 2D image, deformation contains <x_offset> and <y_offset>)
    output_x: [B,1,W,K*H]   coordinate map
    output_y: [B,1,K*W,H]   coordinate map
    """

    def _coordinate_map_3D(self, offset, if_offset):
        """
        1.è¾“å…¥ä¸ºåç§» (offset) å’Œæ˜¯å¦éœ€è¦åç§» (if_offset)ã€‚
        2.æ ¹æ®è¾“å…¥ç‰¹å¾å›¾çš„å½¢çŠ¶ã€å·ç§¯æ ¸å¤§å°ã€æ‰©å±•èŒƒå›´ä»¥åŠå½¢æ€ç±»å‹ï¼Œç”ŸæˆäºŒç»´åæ ‡æ˜ å°„ã€‚
        3.å¦‚æœå½¢æ€ç±»å‹ä¸º0ï¼Œè¡¨ç¤ºæ²¿xè½´ï¼Œç”Ÿæˆyåæ ‡æ˜ å°„ï¼›å¦‚æœå½¢æ€ç±»å‹ä¸º1ï¼Œè¡¨ç¤ºæ²¿yè½´ï¼Œç”Ÿæˆxåæ ‡æ˜ å°„ã€‚
        4.æ ¹æ®åç§»å’Œæ‰©å±•èŒƒå›´è°ƒæ•´åæ ‡æ˜ å°„ã€‚
        5.è¿”å›ç”Ÿæˆçš„åæ ‡æ˜ å°„ã€‚
        """
        device = offset.device
        # offset
        y_offset, x_offset = torch.split(offset, self.num_points, dim=1)

        y_center = torch.arange(0, self.width).repeat([self.height])
        y_center = y_center.reshape(self.height, self.width)
        y_center = y_center.permute(1, 0)
        y_center = y_center.reshape([-1, self.width, self.height])
        y_center = y_center.repeat([self.num_points, 1, 1]).float()
        y_center = y_center.unsqueeze(0)

        x_center = torch.arange(0, self.height).repeat([self.width])
        x_center = x_center.reshape(self.width, self.height)
        x_center = x_center.permute(0, 1)
        x_center = x_center.reshape([-1, self.width, self.height])
        x_center = x_center.repeat([self.num_points, 1, 1]).float()
        x_center = x_center.unsqueeze(0)

        if self.morph == 0:
            """
            Initialize the kernel and flatten the kernel
                y: only need 0
                x: -num_points//2 ~ num_points//2 (Determined by the kernel size)
                !!! The related PPT will be submitted later, and the PPT will contain the whole changes of each step
            """
            y = torch.linspace(0, 0, 1)
            x = torch.linspace(
                -int(self.num_points // 2),
                int(self.num_points // 2),
                int(self.num_points),
            )

            y, x = torch.meshgrid(y, x)
            y_spread = y.reshape(-1, 1)
            x_spread = x.reshape(-1, 1)

            y_grid = y_spread.repeat([1, self.width * self.height])
            y_grid = y_grid.reshape([self.num_points, self.width, self.height])
            y_grid = y_grid.unsqueeze(0)  # [B*K*K, W,H]

            x_grid = x_spread.repeat([1, self.width * self.height])
            x_grid = x_grid.reshape([self.num_points, self.width, self.height])
            x_grid = x_grid.unsqueeze(0)  # [B*K*K, W,H]

            y_new = y_center + y_grid
            x_new = x_center + x_grid

            y_new = y_new.repeat(self.num_batch, 1, 1, 1).to(device)
            x_new = x_new.repeat(self.num_batch, 1, 1, 1).to(device)

            y_offset_new = y_offset.detach().clone()

            if if_offset:
                y_offset = y_offset.permute(1, 0, 2, 3)
                y_offset_new = y_offset_new.permute(1, 0, 2, 3)
                center = int(self.num_points // 2)

                # The center position remains unchanged and the rest of the positions begin to swing
                # This part is quite simple. The main idea is that "offset is an iterative process"
                y_offset_new[center] = 0
                for index in range(1, center):
                    y_offset_new[center + index] = (y_offset_new[center + index - 1] + y_offset[center + index])
                    y_offset_new[center - index] = (y_offset_new[center - index + 1] + y_offset[center - index])
                y_offset_new = y_offset_new.permute(1, 0, 2, 3).to(device)
                y_new = y_new.add(y_offset_new.mul(self.extend_scope))

            y_new = y_new.reshape(
                [self.num_batch, self.num_points, 1, self.width, self.height])
            y_new = y_new.permute(0, 3, 1, 4, 2)
            y_new = y_new.reshape([
                self.num_batch, self.num_points * self.width, 1 * self.height
            ])
            x_new = x_new.reshape(
                [self.num_batch, self.num_points, 1, self.width, self.height])
            x_new = x_new.permute(0, 3, 1, 4, 2)
            x_new = x_new.reshape([
                self.num_batch, self.num_points * self.width, 1 * self.height
            ])
            return y_new, x_new

        else:
            """
            Initialize the kernel and flatten the kernel
                y: -num_points//2 ~ num_points//2 (Determined by the kernel size)
                x: only need 0
            """
            y = torch.linspace(
                -int(self.num_points // 2),
                int(self.num_points // 2),
                int(self.num_points),
            )
            x = torch.linspace(0, 0, 1)

            y, x = torch.meshgrid(y, x)
            y_spread = y.reshape(-1, 1)
            x_spread = x.reshape(-1, 1)

            y_grid = y_spread.repeat([1, self.width * self.height])
            y_grid = y_grid.reshape([self.num_points, self.width, self.height])
            y_grid = y_grid.unsqueeze(0)

            x_grid = x_spread.repeat([1, self.width * self.height])
            x_grid = x_grid.reshape([self.num_points, self.width, self.height])
            x_grid = x_grid.unsqueeze(0)

            y_new = y_center + y_grid
            x_new = x_center + x_grid

            y_new = y_new.repeat(self.num_batch, 1, 1, 1)
            x_new = x_new.repeat(self.num_batch, 1, 1, 1)

            y_new = y_new.to(device)
            x_new = x_new.to(device)
            x_offset_new = x_offset.detach().clone()

            if if_offset:
                x_offset = x_offset.permute(1, 0, 2, 3)
                x_offset_new = x_offset_new.permute(1, 0, 2, 3)
                center = int(self.num_points // 2)
                x_offset_new[center] = 0
                for index in range(1, center):
                    x_offset_new[center + index] = (x_offset_new[center + index - 1] + x_offset[center + index])
                    x_offset_new[center - index] = (x_offset_new[center - index + 1] + x_offset[center - index])
                x_offset_new = x_offset_new.permute(1, 0, 2, 3).to(device)
                x_new = x_new.add(x_offset_new.mul(self.extend_scope))

            y_new = y_new.reshape(
                [self.num_batch, 1, self.num_points, self.width, self.height])
            y_new = y_new.permute(0, 3, 1, 4, 2)
            y_new = y_new.reshape([
                self.num_batch, 1 * self.width, self.num_points * self.height
            ])
            x_new = x_new.reshape(
                [self.num_batch, 1, self.num_points, self.width, self.height])
            x_new = x_new.permute(0, 3, 1, 4, 2)
            x_new = x_new.reshape([
                self.num_batch, 1 * self.width, self.num_points * self.height
            ])
            return y_new, x_new

    """
    input: input feature map [N,C,D,W,H]ï¼›coordinate map [N,K*D,K*W,K*H] 
    output: [N,1,K*D,K*W,K*H]  deformed feature map
    """

    def _bilinear_interpolate_3D(self, input_feature, y, x):
        """
         1.è¾“å…¥ä¸ºè¾“å…¥ç‰¹å¾å›¾ (input_feature)ã€yåæ ‡æ˜ å°„ (y) å’Œxåæ ‡æ˜ å°„ (x)ã€‚
         2.è¿›è¡Œä¸‰ç»´åŒçº¿æ€§æ’å€¼ï¼Œè·å–å˜å½¢åçš„ç‰¹å¾ã€‚
         3.è¿”å›æ’å€¼å¾—åˆ°çš„å˜å½¢ç‰¹å¾ã€‚
        """
        device = input_feature.device
        y = y.reshape([-1]).float()
        x = x.reshape([-1]).float()

        zero = torch.zeros([]).int()
        max_y = self.width - 1
        max_x = self.height - 1

        # find 8 grid locations
        y0 = torch.floor(y).int()
        y1 = y0 + 1
        x0 = torch.floor(x).int()
        x1 = x0 + 1

        # clip out coordinates exceeding feature map volume
        y0 = torch.clamp(y0, zero, max_y)
        y1 = torch.clamp(y1, zero, max_y)
        x0 = torch.clamp(x0, zero, max_x)
        x1 = torch.clamp(x1, zero, max_x)

        input_feature_flat = input_feature.flatten()
        input_feature_flat = input_feature_flat.reshape(
            self.num_batch, self.num_channels, self.width, self.height)
        input_feature_flat = input_feature_flat.permute(0, 2, 3, 1)
        input_feature_flat = input_feature_flat.reshape(-1, self.num_channels)
        dimension = self.height * self.width

        base = torch.arange(self.num_batch) * dimension
        base = base.reshape([-1, 1]).float()

        repeat = torch.ones([self.num_points * self.width * self.height
                             ]).unsqueeze(0)
        repeat = repeat.float()

        base = torch.matmul(base, repeat)
        base = base.reshape([-1])

        base = base.to(device)

        base_y0 = base + y0 * self.height
        base_y1 = base + y1 * self.height

        # top rectangle of the neighbourhood volume
        index_a0 = base_y0 - base + x0
        index_c0 = base_y0 - base + x1

        # bottom rectangle of the neighbourhood volume
        index_a1 = base_y1 - base + x0
        index_c1 = base_y1 - base + x1

        # get 8 grid values
        value_a0 = input_feature_flat[index_a0.type(torch.int64)].to(device)
        value_c0 = input_feature_flat[index_c0.type(torch.int64)].to(device)
        value_a1 = input_feature_flat[index_a1.type(torch.int64)].to(device)
        value_c1 = input_feature_flat[index_c1.type(torch.int64)].to(device)

        # find 8 grid locations
        y0 = torch.floor(y).int()
        y1 = y0 + 1
        x0 = torch.floor(x).int()
        x1 = x0 + 1

        # clip out coordinates exceeding feature map volume
        y0 = torch.clamp(y0, zero, max_y + 1)
        y1 = torch.clamp(y1, zero, max_y + 1)
        x0 = torch.clamp(x0, zero, max_x + 1)
        x1 = torch.clamp(x1, zero, max_x + 1)

        x0_float = x0.float()
        x1_float = x1.float()
        y0_float = y0.float()
        y1_float = y1.float()

        vol_a0 = ((y1_float - y) * (x1_float - x)).unsqueeze(-1).to(device)
        vol_c0 = ((y1_float - y) * (x - x0_float)).unsqueeze(-1).to(device)
        vol_a1 = ((y - y0_float) * (x1_float - x)).unsqueeze(-1).to(device)
        vol_c1 = ((y - y0_float) * (x - x0_float)).unsqueeze(-1).to(device)

        outputs = (value_a0 * vol_a0 + value_c0 * vol_c0 + value_a1 * vol_a1 +
                   value_c1 * vol_c1)

        if self.morph == 0:
            outputs = outputs.reshape([
                self.num_batch,
                self.num_points * self.width,
                1 * self.height,
                self.num_channels,
            ])
            outputs = outputs.permute(0, 3, 1, 2)
        else:
            outputs = outputs.reshape([
                self.num_batch,
                1 * self.width,
                self.num_points * self.height,
                self.num_channels,
            ])
            outputs = outputs.permute(0, 3, 1, 2)
        return outputs

    def deform_conv(self, input, offset, if_offset):
        """
        1.è¾“å…¥ä¸ºåŸå§‹ç‰¹å¾å›¾ (input)ã€åç§» (offset) å’Œæ˜¯å¦éœ€è¦åç§» (if_offset)ã€‚
        2.è°ƒç”¨ _coordinate_map_3D æ–¹æ³•è·å–åæ ‡æ˜ å°„ã€‚
        3.è°ƒç”¨ _bilinear_interpolate_3D æ–¹æ³•è¿›è¡ŒåŒçº¿æ€§æ’å€¼ï¼Œå¾—åˆ°å˜å½¢åçš„ç‰¹å¾ã€‚
        4.è¿”å›å˜å½¢åçš„ç‰¹å¾ã€‚
        """
        y, x = self._coordinate_map_3D(offset, if_offset)
        deformed_feature = self._bilinear_interpolate_3D(input, y, x)
        return deformed_feature

#---------------------------------YOLOv5 ä¸“ç”¨éƒ¨åˆ†â†“---------------------------------
class DSConv_Bottleneck(nn.Module):
    # DSConv bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2
        self.snc = DSConv(c2, c2, 3, 1, 1, True)

    def forward(self, x):
        return x + self.snc(self.cv2(self.cv1(x))) if self.add else self.snc(self.cv2(self.cv1(x)))


class DSConv_C3(nn.Module):
    # DSConv Bottleneck with 3 convolutions
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion

        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(*(DSConv_Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))

#---------------------------------YOLOv5 ä¸“ç”¨éƒ¨åˆ†â†‘---------------------------------
```

#### ç¬¬â‘¡æ­¥ï¼šä¿®æ”¹yolo.pyæ–‡ä»¶ 

å†æ¥ä¿®æ”¹yolo.pyï¼Œåœ¨parse\_modelå‡½æ•°ä¸­æ‰¾åˆ°elif m is nn.BatchNorm2d:è¯­å¥ï¼Œåœ¨å…¶åé¢åŠ ä¸Šä¸‹é¢ä»£ç ï¼š

```java
elif m in (DSConv, DSConv_C3):
            c1, c2 = ch[f], args[0]
            if c2 != nc:
                c2 = make_divisible(c2 * gw, 8)
            args = [c1, c2, *args[1:]]
            if m is DSConv_C3:
                args.insert(2, n)  # number of repeats
                n = 1
```

 å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](https://i-blog.csdnimg.cn/blog_migrate/c93b63a00ffc98d897e29f5d16cb3f2f.png)

#### ç¬¬â‘¢æ­¥ï¼šåˆ›å»ºè‡ªå®šä¹‰çš„yamlæ–‡ä»¶ 

ç¬¬1ç§ï¼Œæ›¿æ¢convç»“æ„

```java
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.5  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]
 
# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512]],  # 13
 
   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, DSConv, [256, 3,1,1,True]],  # 17 (P3/8-small)
 
   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, DSConv, [512, 3,1,1,True]],  # 20 (P4/16-medium)
 
   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, DSConv, [1024, 3,1,1,True]],  # 23 (P5/32-large)
 
   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
```

è¿™é‡Œè¦æ³¨æ„ä¸€ä¸ªé—®é¢˜ï¼Œæ›¿æ¢æ—¶DSConvå‚æ•°æ˜¯éœ€è¦åšå¯¹åº”ä¿®æ”¹ï¼š

![](https://i-blog.csdnimg.cn/blog_migrate/4f57b7fb0a0323428a9cd3675ebea643.png)

å¦‚ä¸‹å›¾æ —å­æ‰€ç¤ºï¼š

![](https://i-blog.csdnimg.cn/blog_migrate/8aeb522907fff4e8ffb2117828fe3ed5.png)

å¦‚æœç›´æ¥æ”¹æ¨¡å—åä¼šå‡ºç°ç¼ºå‚æŠ¥é”™ï¼š

```java
TypeError: __init__() missing 2 required positional arguments: 'morph' and 'if_offset'
```

![](https://i-blog.csdnimg.cn/blog_migrate/64366f3d8ee26b4ef75e0cedd64fd7b8.png)

ç¬¬2ç§ï¼Œæ›¿æ¢C3æ¨¡å—

```java
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.5  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, DSConv_C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, DSConv_C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, DSConv_C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, DSConv_C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]
 
# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512]],  # 13
 
   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)
 
   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)
 
   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)
 
   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
```

æ›¿æ¢C3æ¨¡å—ç›´æ¥æ”¹æ¨¡å—åå­—å°±è¡Œã€‚

> ä»£ç å‚è€ƒï¼š
> 
> [æ”¹è¿›YOLOç³»åˆ— | YOLOv5/v7 å¼•å…¥ Dynamic Snake Convolution | åŠ¨æ€è›‡å½¢å·ç§¯\_yolov7åŠ å…¥dynamic snake convolution-CSDNåšå®¢][YOLO_ _ YOLOv5_v7 _ Dynamic Snake Convolution _ _yolov7_dynamic snake convolution-CSDN]

#### ç¬¬â‘£æ­¥ï¼šéªŒè¯æ˜¯å¦åŠ å…¥æˆåŠŸ 

è¿è¡Œyolo.py

ç¬¬1ç§

![](https://i-blog.csdnimg.cn/blog_migrate/77a59ddd31bb07bab8174a56468cdfa6.png)

ç¬¬2ç§

![](https://i-blog.csdnimg.cn/blog_migrate/b9e5127627db98c4116f4fb5cf6042b2.png) è¿™æ ·å°±OKå•¦ï¼

## ğŸŒŸæœ¬äººYOLOv5ç³»åˆ—å¯¼èˆª 

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif) ğŸ€[YOLOv5æºç ][YOLOv5 1]è¯¦è§£ç³»åˆ—ï¼š

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ1ï¼‰â€”â€”é¡¹ç›®ç›®å½•ç»“æ„è§£æ][YOLOv5_1]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ2ï¼‰â€”â€”æ¨ç†éƒ¨åˆ†detect.py][YOLOv5_2_detect.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ3ï¼‰â€”â€”è®­ç»ƒéƒ¨åˆ†train.py][YOLOv5_3_train.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ4ï¼‰â€”â€”éªŒè¯éƒ¨åˆ†valï¼ˆtestï¼‰.py][YOLOv5_4_val_test_.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ5ï¼‰â€”â€”é…ç½®æ–‡ä»¶yolov5s.yaml][YOLOv5_5_yolov5s.yaml]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ6ï¼‰â€”â€”ç½‘ç»œç»“æ„ï¼ˆ1ï¼‰yolo.py][YOLOv5_6_1_yolo.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ7ï¼‰â€”â€”ç½‘ç»œç»“æ„ï¼ˆ2ï¼‰common.py][YOLOv5_7_2_common.py]

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif) ğŸ€[YOLOv5å…¥é—¨å®è·µ][YOLOv5 1]ç³»åˆ—ï¼š

[YOLOv5å…¥é—¨å®è·µï¼ˆ1ï¼‰â€”â€”æ‰‹æŠŠæ‰‹å¸¦ä½ ç¯å¢ƒé…ç½®æ­å»º][YOLOv5_1 1]

[YOLOv5å…¥é—¨å®è·µï¼ˆ2ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ åˆ©ç”¨labelimgæ ‡æ³¨æ•°æ®é›†][YOLOv5_2_labelimg]

[YOLOv5å…¥é—¨å®è·µï¼ˆ3ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ åˆ’åˆ†è‡ªå·±çš„æ•°æ®é›†][YOLOv5_3]

[YOLOv5å…¥é—¨å®è·µï¼ˆ4ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†][YOLOv5_4]

[YOLOv5å…¥é—¨å®è·µï¼ˆ5ï¼‰â€”â€”ä»é›¶å¼€å§‹ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒè‡ªå·±çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆåŒ…å«pyqt5ç•Œé¢ï¼‰][YOLOv5_5_pyqt5]

![](https://i-blog.csdnimg.cn/blog_migrate/2c2007740e861597f69f381c445a3199.gif)


[YOLOv5_0]: https://blog.csdn.net/weixin_43334693/article/details/130564848?spm=1001.2014.3001.5501
[YOLOv5_1_SE]: https://blog.csdn.net/weixin_43334693/article/details/130551913?spm=1001.2014.3001.5501
[YOLOv5_2_CBAM]: https://blog.csdn.net/weixin_43334693/article/details/130587102?spm=1001.2014.3001.5501
[YOLOv5_3_CA]: https://blog.csdn.net/weixin_43334693/article/details/130619604?spm=1001.2014.3001.5501
[YOLOv5_4_ECA]: https://blog.csdn.net/weixin_43334693/article/details/130641318?spm=1001.2014.3001.5501
[YOLOv5_5_ MobileNetV3]: https://blog.csdn.net/weixin_43334693/article/details/130832933?spm=1001.2014.3001.5501
[YOLOv5_6_ ShuffleNetV2]: https://blog.csdn.net/weixin_43334693/article/details/131008642?spm=1001.2014.3001.5501
[YOLOv5_7_SimAM]: https://blog.csdn.net/weixin_43334693/article/details/131031541?spm=1001.2014.3001.5501
[YOLOv5_8_SOCA]: https://blog.csdn.net/weixin_43334693/article/details/131053284?spm=1001.2014.3001.5501
[YOLOv5_9_EfficientNetv2]: https://blog.csdn.net/weixin_43334693/article/details/131207097?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22131207097%22%2C%22source%22%3A%22weixin_43334693%22%7D
[YOLOv5_10_GhostNet]: https://blog.csdn.net/weixin_43334693/article/details/131235113?spm=1001.2014.3001.5501
[YOLOv5_11_EIoU_AlphaIoU_SIoU_WIoU]: https://blog.csdn.net/weixin_43334693/article/details/131350224?spm=1001.2014.3001.5501
[YOLOv5_12_Neck_BiFPN]: https://blog.csdn.net/weixin_43334693/article/details/131461294?spm=1001.2014.3001.5501
[YOLOv5_13_SiLU_ReLU_ELU_Hardswish_Mish_Softplus_AconC]: https://blog.csdn.net/weixin_43334693/article/details/131513850?spm=1001.2014.3001.5502
[YOLOv5_14_NMS_ DIoU-NMS_CIoU-NMS_EIoU-NMS_GIoU-NMS _SIoU-NMS_Soft-NMS]: https://blog.csdn.net/weixin_43334693/article/details/131552028?spm=1001.2014.3001.5501
[YOLOv5_15]: https://blog.csdn.net/weixin_43334693/article/details/131613721?spm=1001.2014.3001.5502
[YOLOv5_16_EMA_ICASSP2023]: https://blog.csdn.net/weixin_43334693/article/details/131973273?spm=1001.2014.3001.5501
[YOLOv5_17_IoU_MPDIoU_ELSEVIER 2023_WIoU_EIoU]: https://blog.csdn.net/weixin_43334693/article/details/131999141?spm=1001.2014.3001.5501
[YOLOv5_18_Neck_AFPN_PAFPN]: https://blog.csdn.net/weixin_43334693/article/details/132070079?spm=1001.2014.3001.5501
[YOLOv5_19_Swin TransformerV1_ViT]: https://blog.csdn.net/weixin_43334693/article/details/132161488?spm=1001.2014.3001.5501
[YOLOv5_21_RepViT_ ICCV 2023_ViT]: https://blog.csdn.net/weixin_43334693/article/details/132211831?spm=1001.2014.3001.5501
[YOLOv5_22_MobileViTv1_ ViT]: https://blog.csdn.net/weixin_43334693/article/details/132367429?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22132367429%22%2C%22source%22%3A%22weixin_43334693%22%7D
[YOLOv5_23_MobileViTv2_ Transformer]: https://blog.csdn.net/weixin_43334693/article/details/132428203?spm=1001.2014.3001.5502
[YOLOv5_24_MobileViTv3]: https://blog.csdn.net/weixin_43334693/article/details/133199471?spm=1001.2014.3001.5502
[YOLOv5_25_LSKNet]: https://blog.csdn.net/weixin_43334693/article/details/135510571?spm=1001.2014.3001.5501
[YOLOv5_26_RFAConv]: https://blog.csdn.net/weixin_43334693/article/details/135562865?spm=1001.2014.3001.5501
[YOLOv5_27_SCConv_CVPR 2023]: https://blog.csdn.net/weixin_43334693/article/details/135610505?spm=1001.2014.3001.5502
[_DSConv_]: #%F0%9F%9A%80%C2%A0%E4%B8%80%E3%80%81DSConv%E4%BB%8B%E7%BB%8D%C2%A0
[1.1 DSConv]: #1.1%C2%A0DSConv%E7%AE%80%E4%BB%8B
[1.2]: #%C2%A01.2%C2%A0%E5%8A%A8%E6%80%81%E8%9B%87%E5%BD%A2%E5%8D%B7%E7%A7%AF
[1.3]: #1.3%C2%A0%C2%A0%E5%A4%9A%E8%A7%86%E8%A7%92%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%AD%96%E7%95%A5
[1.4]: #%C2%A01.4%C2%A0%E8%BF%9E%E7%BB%AD%E6%80%A7%E6%8B%93%E6%89%91%E7%BA%A6%E6%9D%9F%E6%8D%9F%E5%A4%B1
[Link 1]: #%F0%9F%9A%80%E4%BA%8C%E3%80%81%E5%85%B7%E4%BD%93%E6%B7%BB%E5%8A%A0%E6%96%B9%E6%B3%95
[2.1 _]: #2.1%20%E6%B7%BB%E5%8A%A0%E9%A1%BA%E5%BA%8F%C2%A0
[2.2 _]: #2.2%20%E5%85%B7%E4%BD%93%E6%B7%BB%E5%8A%A0%E6%AD%A5%E9%AA%A4%C2%A0
[common.py_DCConv_]: #%E7%AC%AC%E2%91%A0%E6%AD%A5%EF%BC%9A%E5%9C%A8common.py%E4%B8%AD%E6%B7%BB%E5%8A%A0LSK%E6%A8%A1%E5%9D%97%C2%A0
[yolo.py_]: #%E7%AC%AC%E2%91%A1%E6%AD%A5%EF%BC%9A%E4%BF%AE%E6%94%B9yolo.py%E6%96%87%E4%BB%B6%C2%A0%C2%A0
[yaml_]: #%C2%A0%E7%AC%AC%E2%91%A2%E6%AD%A5%EF%BC%9A%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84yaml%E6%96%87%E4%BB%B6%C2%A0%C2%A0
[Link 2]: #%C2%A0%E7%AC%AC%E2%91%A3%E6%AD%A5%EF%BC%9A%E9%AA%8C%E8%AF%81%E6%98%AF%E5%90%A6%E5%8A%A0%E5%85%A5%E6%88%90%E5%8A%9F
[YOLOv5]: #%F0%9F%8C%9F%E6%9C%AC%E4%BA%BAYOLOv5%E7%B3%BB%E5%88%97%E5%AF%BC%E8%88%AA
[https_arxiv.org_abs_2307.08388]: https://arxiv.org/abs/2307.08388
[https_github.com_YaoleiQi_DSCNet]: https://github.com/YaoleiQi/DSCNet
[YOLO_ _ YOLOv5_v7 _ Dynamic Snake Convolution _ _yolov7_dynamic snake convolution-CSDN]: https://yolov5.blog.csdn.net/article/details/133973402
[YOLOv5 1]: https://so.csdn.net/so/search?q=YOLOv5%E6%BA%90%E7%A0%81&spm=1001.2101.3001.7020
[YOLOv5_1]: https://blog.csdn.net/weixin_43334693/article/details/129356033?spm=1001.2014.3001.5501
[YOLOv5_2_detect.py]: https://blog.csdn.net/weixin_43334693/article/details/129349094?spm=1001.2014.3001.5501
[YOLOv5_3_train.py]: https://blog.csdn.net/weixin_43334693/article/details/129460666?spm=1001.2014.3001.5501
[YOLOv5_4_val_test_.py]: https://blog.csdn.net/weixin_43334693/article/details/129649553?spm=1001.2014.3001.5501
[YOLOv5_5_yolov5s.yaml]: https://blog.csdn.net/weixin_43334693/article/details/129697521?spm=1001.2014.3001.5501
[YOLOv5_6_1_yolo.py]: https://blog.csdn.net/weixin_43334693/article/details/129803802?spm=1001.2014.3001.5501
[YOLOv5_7_2_common.py]: https://blog.csdn.net/weixin_43334693/article/details/129854764?spm=1001.2014.3001.5501
[YOLOv5_1 1]: https://blog.csdn.net/weixin_43334693/article/details/129981848?spm=1001.2014.3001.5501
[YOLOv5_2_labelimg]: https://blog.csdn.net/weixin_43334693/article/details/129995604?spm=1001.2014.3001.5501
[YOLOv5_3]: https://blog.csdn.net/weixin_43334693/article/details/130025866?spm=1001.2014.3001.5501
[YOLOv5_4]: https://blog.csdn.net/weixin_43334693/article/details/130043351?spm=1001.2014.3001.5501
[YOLOv5_5_pyqt5]: https://blog.csdn.net/weixin_43334693/article/details/130044342?spm=1001.2014.3001.5501