![](https://i-blog.csdnimg.cn/blog_migrate/93b7db7192bee60708f194c5ce8de9d8.gif)

![](https://i-blog.csdnimg.cn/blog_migrate/6c2ede5e9c9047fefaf9370db26b7789.png)

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif)ã€YOLOv5æ”¹è¿›ç³»åˆ—ã€‘å‰æœŸå›é¡¾ï¼š

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ0ï¼‰â€”â€”é‡è¦æ€§èƒ½æŒ‡æ ‡ä¸è®­ç»ƒç»“æœè¯„ä»·åŠåˆ†æ][YOLOv5_0]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ1ï¼‰â€”â€”æ·»åŠ SEæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_1_SE]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ2ï¼‰â€”â€”æ·»åŠ CBAMæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_2_CBAM]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ3ï¼‰â€”â€”æ·»åŠ CAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_3_CA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ4ï¼‰â€”â€”æ·»åŠ ECAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_4_ECA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ5ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹ MobileNetV3][YOLOv5_5_ MobileNetV3]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ6ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹ ShuffleNetV2][YOLOv5_6_ ShuffleNetV2]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ7ï¼‰â€”â€”æ·»åŠ SimAMæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_7_SimAM]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ8ï¼‰â€”â€”æ·»åŠ SOCAæ³¨æ„åŠ›æœºåˆ¶][YOLOv5_8_SOCA]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ9ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹EfficientNetv2][YOLOv5_9_EfficientNetv2]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ10ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹GhostNet][YOLOv5_10_GhostNet]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ11ï¼‰â€”â€”æ·»åŠ æŸå¤±å‡½æ•°ä¹‹EIoUã€AlphaIoUã€SIoUã€WIoU][YOLOv5_11_EIoU_AlphaIoU_SIoU_WIoU]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ12ï¼‰â€”â€”æ›´æ¢Neckä¹‹BiFPN][YOLOv5_12_Neck_BiFPN]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ13ï¼‰â€”â€”æ›´æ¢æ¿€æ´»å‡½æ•°ä¹‹SiLUï¼ŒReLUï¼ŒELUï¼ŒHardswishï¼ŒMishï¼ŒSoftplusï¼ŒAconCç³»åˆ—ç­‰][YOLOv5_13_SiLU_ReLU_ELU_Hardswish_Mish_Softplus_AconC]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ14ï¼‰â€”â€”æ›´æ¢NMSï¼ˆéæå¤§æŠ‘åˆ¶ï¼‰ä¹‹ DIoU-NMSã€CIoU-NMSã€EIoU-NMSã€GIoU-NMS ã€SIoU-NMSã€Soft-NMS][YOLOv5_14_NMS_ DIoU-NMS_CIoU-NMS_EIoU-NMS_GIoU-NMS _SIoU-NMS_Soft-NMS]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ15ï¼‰â€”â€”å¢åŠ å°ç›®æ ‡æ£€æµ‹å±‚][YOLOv5_15]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ16ï¼‰â€”â€”æ·»åŠ EMAæ³¨æ„åŠ›æœºåˆ¶ï¼ˆICASSP2023|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_16_EMA_ICASSP2023]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ17ï¼‰â€”â€”æ›´æ¢IoUä¹‹MPDIoUï¼ˆELSEVIER 2023|è¶…è¶ŠWIoUã€EIoUç­‰|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_17_IoU_MPDIoU_ELSEVIER 2023_WIoU_EIoU]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ18ï¼‰â€”â€”æ›´æ¢Neckä¹‹AFPNï¼ˆå…¨æ–°æ¸è¿›ç‰¹å¾é‡‘å­—å¡”|è¶…è¶ŠPAFPN|å®æµ‹æ¶¨ç‚¹ï¼‰][YOLOv5_18_Neck_AFPN_PAFPN]

[YOLOv5æ”¹è¿›ç³»åˆ—ï¼ˆ19ï¼‰â€”â€”æ›¿æ¢ä¸»å¹²ç½‘ç»œä¹‹Swin TransformerV1ï¼ˆå‚æ•°é‡æ›´å°çš„ViTæ¨¡å‹ï¼‰][YOLOv5_19_Swin TransformerV1_ViT]

![](https://i-blog.csdnimg.cn/blog_migrate/129a58cc4a258e59e511dd0fbc38b8b4.gif)

ç›®å½•

[ğŸš€ä¸€ã€BiFormerä»‹ç» ][BiFormer_]

[ 1.1 ç®€ä»‹][1.1]

[1.2 æ¨¡å‹ç»“æ„][1.2]

[ğŸš€äºŒã€å…·ä½“æ·»åŠ æ–¹æ³•][Link 1]

[ç¬¬â‘ æ­¥ï¼šåœ¨common.pyä¸­æ·»åŠ BiFormeræ¨¡å—][common.py_BiFormer]

[ç¬¬â‘¡æ­¥ï¼šä¿®æ”¹yolo.pyæ–‡ä»¶][yolo.py]

[ç¬¬â‘¢æ­¥ï¼šåˆ›å»ºè‡ªå®šä¹‰çš„yamlæ–‡ä»¶ ][yaml_]

[ç¬¬â‘£æ­¥ï¼šéªŒè¯æ˜¯å¦åŠ å…¥æˆåŠŸ][Link 2]

[ğŸŒŸæœ¬äººYOLOv5ç³»åˆ—å¯¼èˆª][YOLOv5]

![](https://i-blog.csdnimg.cn/blog_migrate/862cda269aa91f45a0e743dd766c45f6.gif)

## ğŸš€ä¸€ã€BiFormerä»‹ç» 

>  *  è®ºæ–‡é¢˜ç›®ï¼šã€ŠBiFormer: Vision Transformer with Bi-Level Routing Attentionã€‹
>  *  è®ºæ–‡åœ°å€ï¼š[https://arxiv.org/pdf/2303.08810.pdf][https_arxiv.org_pdf_2303.08810.pdf]
>  *  æºç åœ°å€ï¼š[https://github.com/rayleizhu/BiFormer][https_github.com_rayleizhu_BiFormer]

## 1.1 ç®€ä»‹ 

BiFomeræ¨¡å— æå‡ºäº† ä¸€ç§åŠ¨æ€çš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ ã€‚é¦–å…ˆåœ¨å®è§‚ä¸Š è¿‡æ»¤æ‰å¤§éƒ¨åˆ†ä¸ç›¸å…³çš„ key ä¸ value ï¼Œåªä¿ç•™ä¸‹ä¸€å°éƒ¨åˆ†ç›¸å…³çš„ key å’Œ valueã€‚ç„¶å åœ¨è¿™ä¸€å°éƒ¨åˆ†ç›¸å…³ key ä¸ value ä¸­ä½¿ç”¨ token -to-token æ³¨æ„åŠ› ã€‚

### 1.2 æ¨¡å‹ç»“æ„ 

![](https://i-blog.csdnimg.cn/blog_migrate/fde60d40358b081e946476a539a4ba81.png)

å…·ä½“ç»“æ„ï¼š

1.  ç¬¬ä¸€é˜¶æ®µä½¿ç”¨é‡å çš„patch embeddingï¼ˆi=1æ—¶ï¼‰åµŒå…¥ï¼ˆé™ä½è¾“å…¥ç©ºé—´åˆ†è¾¨ç‡ï¼‰
2.  ç¬¬äºŒåˆ°ç¬¬å››é˜¶æ®µä½¿ç”¨patch mergingï¼ˆi=2,3,4æ—¶ï¼‰æ¨¡å—ï¼ˆå¢åŠ é€šé“æ•°é‡ï¼‰
3.  ç„¶åä½¿ç”¨Niä¸ªç›¸è¿çš„BiFormerå—æ¥å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œtransformeræ“ä½œ

## ğŸš€äºŒã€å…·ä½“æ·»åŠ æ–¹æ³• 

#### ç¬¬â‘ æ­¥ï¼šåœ¨common.pyä¸­æ·»åŠ BiFormeræ¨¡å— 

å°†ä»¥ä¸‹ä»£ç å¤åˆ¶ç²˜è´´åˆ°common.pyæ–‡ä»¶çš„æœ«å°¾

```java
# ------------------ä»£ç è½¬è‡ª@è¿ªè²èµ«å°”æ›¼------------------------------
from torch import Tensor
from typing import Tuple
import torch.nn.functional as F
from einops import rearrange


class TopkRouting(nn.Module):
    """
    differentiable topk routing with scaling
    Args:
        qk_dim: int, feature dimension of query and key
        topk: int, the 'topk'
        qk_scale: int or None, temperature (multiply) of softmax activation
        with_param: bool, wether inorporate learnable params in routing unit
        diff_routing: bool, wether make routing differentiable
        soft_routing: bool, wether make output value multiplied by routing weights
    """

    def __init__(self, qk_dim, topk=4, qk_scale=None, param_routing=False, diff_routing=False):
        super().__init__()
        self.topk = topk
        self.qk_dim = qk_dim
        self.scale = qk_scale or qk_dim ** -0.5
        self.diff_routing = diff_routing
        self.emb = nn.Linear(qk_dim, qk_dim) if param_routing else nn.Identity()
        self.routing_act = nn.Softmax(dim=-1)

    def forward(self, query: Tensor, key: Tensor) -> Tuple[Tensor]:
        if not self.diff_routing:
            query, key = query.detach(), key.detach()
        query_hat, key_hat = self.emb(query), self.emb(key)
        attn_logit = (query_hat * self.scale) @ key_hat.transpose(-2, -1)
        topk_attn_logit, topk_index = torch.topk(attn_logit, k=self.topk, dim=-1)
        r_weight = self.routing_act(topk_attn_logit)

        return r_weight, topk_index


class KVGather(nn.Module):
    def __init__(self, mul_weight='none'):
        super().__init__()
        assert mul_weight in ['none', 'soft', 'hard']
        self.mul_weight = mul_weight

    def forward(self, r_idx: Tensor, r_weight: Tensor, kv: Tensor):
        n, p2, w2, c_kv = kv.size()
        topk = r_idx.size(-1)
        topk_kv = torch.gather(kv.view(n, 1, p2, w2, c_kv).expand(-1, p2, -1, -1, -1),
                               dim=2,
                               index=r_idx.view(n, p2, topk, 1, 1).expand(-1, -1, -1, w2, c_kv)
                               )

        if self.mul_weight == 'soft':
            topk_kv = r_weight.view(n, p2, topk, 1, 1) * topk_kv
        elif self.mul_weight == 'hard':
            raise NotImplementedError('differentiable hard routing TBA')

        return topk_kv


class QKVLinear(nn.Module):
    def __init__(self, dim, qk_dim, bias=True):
        super().__init__()
        self.dim = dim
        self.qk_dim = qk_dim
        self.qkv = nn.Linear(dim, qk_dim + qk_dim + dim, bias=bias)

    def forward(self, x):
        q, kv = self.qkv(x).split([self.qk_dim, self.qk_dim + self.dim], dim=-1)

        return q, kv


class BiLevelRoutingAttention(nn.Module):
    """
    n_win: number of windows in one side (so the actual number of windows is n_win*n_win)
    kv_per_win: for kv_downsample_mode='ada_xxxpool' only, number of key/values per window. Similar to n_win, the actual number is kv_per_win*kv_per_win.
    topk: topk for window filtering
    param_attention: 'qkvo'-linear for q,k,v and o, 'none': param free attention
    param_routing: extra linear for routing
    diff_routing: wether to set routing differentiable
    soft_routing: wether to multiply soft routing weights
    """

    def __init__(self, dim, n_win=7, num_heads=8, qk_dim=None, qk_scale=None,
                 kv_per_win=4, kv_downsample_ratio=4, kv_downsample_kernel=None, kv_downsample_mode='identity',
                 topk=4, param_attention="qkvo", param_routing=False, diff_routing=False, soft_routing=False,
                 side_dwconv=3,
                 auto_pad=True):
        super().__init__()
        self.dim = dim
        self.n_win = n_win  # Wh, Ww
        self.num_heads = num_heads
        self.qk_dim = qk_dim or dim
        assert self.qk_dim % num_heads == 0 and self.dim % num_heads == 0, 'qk_dim and dim must be divisible by num_heads!'
        self.scale = qk_scale or self.qk_dim ** -0.5
        self.lepe = nn.Conv2d(dim, dim, kernel_size=side_dwconv, stride=1, padding=side_dwconv // 2,
                              groups=dim) if side_dwconv > 0 else \
            lambda x: torch.zeros_like(x)
        self.topk = topk
        self.param_routing = param_routing
        self.diff_routing = diff_routing
        self.soft_routing = soft_routing
        # router
        assert not (self.param_routing and not self.diff_routing)
        self.router = TopkRouting(qk_dim=self.qk_dim,
                                  qk_scale=self.scale,
                                  topk=self.topk,
                                  diff_routing=self.diff_routing,
                                  param_routing=self.param_routing)
        if self.soft_routing:  # soft routing, always diffrentiable (if no detach)
            mul_weight = 'soft'
        elif self.diff_routing:  # hard differentiable routing
            mul_weight = 'hard'
        else:  # hard non-differentiable routing
            mul_weight = 'none'
        self.kv_gather = KVGather(mul_weight=mul_weight)

        # qkv mapping (shared by both global routing and local attention)
        self.param_attention = param_attention
        if self.param_attention == 'qkvo':
            self.qkv = QKVLinear(self.dim, self.qk_dim)
            self.wo = nn.Linear(dim, dim)
        elif self.param_attention == 'qkv':
            self.qkv = QKVLinear(self.dim, self.qk_dim)
            self.wo = nn.Identity()
        else:
            raise ValueError(f'param_attention mode {self.param_attention} is not surpported!')

        self.kv_downsample_mode = kv_downsample_mode
        self.kv_per_win = kv_per_win
        self.kv_downsample_ratio = kv_downsample_ratio
        self.kv_downsample_kenel = kv_downsample_kernel
        if self.kv_downsample_mode == 'ada_avgpool':
            assert self.kv_per_win is not None
            self.kv_down = nn.AdaptiveAvgPool2d(self.kv_per_win)
        elif self.kv_downsample_mode == 'ada_maxpool':
            assert self.kv_per_win is not None
            self.kv_down = nn.AdaptiveMaxPool2d(self.kv_per_win)
        elif self.kv_downsample_mode == 'maxpool':
            assert self.kv_downsample_ratio is not None
            self.kv_down = nn.MaxPool2d(self.kv_downsample_ratio) if self.kv_downsample_ratio > 1 else nn.Identity()
        elif self.kv_downsample_mode == 'avgpool':
            assert self.kv_downsample_ratio is not None
            self.kv_down = nn.AvgPool2d(self.kv_downsample_ratio) if self.kv_downsample_ratio > 1 else nn.Identity()
        elif self.kv_downsample_mode == 'identity':  # no kv downsampling
            self.kv_down = nn.Identity()
        elif self.kv_downsample_mode == 'fracpool':
            raise NotImplementedError('fracpool policy is not implemented yet!')
        elif kv_downsample_mode == 'conv':
            raise NotImplementedError('conv policy is not implemented yet!')
        else:
            raise ValueError(f'kv_down_sample_mode {self.kv_downsaple_mode} is not surpported!')

        self.attn_act = nn.Softmax(dim=-1)

        self.auto_pad = auto_pad

    def forward(self, x, ret_attn_mask=False):
        """
        x: NHWC tensor
        Return:
            NHWC tensor
        """
        x = rearrange(x, "n c h w -> n h w c")
        if self.auto_pad:
            N, H_in, W_in, C = x.size()

            pad_l = pad_t = 0
            pad_r = (self.n_win - W_in % self.n_win) % self.n_win
            pad_b = (self.n_win - H_in % self.n_win) % self.n_win
            x = F.pad(x, (0, 0,  # dim=-1
                          pad_l, pad_r,  # dim=-2
                          pad_t, pad_b))  # dim=-3
            _, H, W, _ = x.size()  # padded size
        else:
            N, H, W, C = x.size()
            assert H % self.n_win == 0 and W % self.n_win == 0  #
        x = rearrange(x, "n (j h) (i w) c -> n (j i) h w c", j=self.n_win, i=self.n_win)
        q, kv = self.qkv(x)
        q_pix = rearrange(q, 'n p2 h w c -> n p2 (h w) c')
        kv_pix = self.kv_down(rearrange(kv, 'n p2 h w c -> (n p2) c h w'))
        kv_pix = rearrange(kv_pix, '(n j i) c h w -> n (j i) (h w) c', j=self.n_win, i=self.n_win)

        q_win, k_win = q.mean([2, 3]), kv[..., 0:self.qk_dim].mean(
            [2, 3])  # window-wise qk, (n, p^2, c_qk), (n, p^2, c_qk)
        lepe = self.lepe(rearrange(kv[..., self.qk_dim:], 'n (j i) h w c -> n c (j h) (i w)', j=self.n_win,
                                   i=self.n_win).contiguous())
        lepe = rearrange(lepe, 'n c (j h) (i w) -> n (j h) (i w) c', j=self.n_win, i=self.n_win)
        r_weight, r_idx = self.router(q_win, k_win)  # both are (n, p^2, topk) tensors
        kv_pix_sel = self.kv_gather(r_idx=r_idx, r_weight=r_weight, kv=kv_pix)  # (n, p^2, topk, h_kv*w_kv, c_qk+c_v)
        k_pix_sel, v_pix_sel = kv_pix_sel.split([self.qk_dim, self.dim], dim=-1)
        k_pix_sel = rearrange(k_pix_sel, 'n p2 k w2 (m c) -> (n p2) m c (k w2)',
                              m=self.num_heads)  # flatten to BMLC, (n*p^2, m, topk*h_kv*w_kv, c_kq//m) transpose here?
        v_pix_sel = rearrange(v_pix_sel, 'n p2 k w2 (m c) -> (n p2) m (k w2) c',
                              m=self.num_heads)  # flatten to BMLC, (n*p^2, m, topk*h_kv*w_kv, c_v//m)
        q_pix = rearrange(q_pix, 'n p2 w2 (m c) -> (n p2) m w2 c',
                          m=self.num_heads)  # to BMLC tensor (n*p^2, m, w^2, c_qk//m)
        attn_weight = (
                                  q_pix * self.scale) @ k_pix_sel  # (n*p^2, m, w^2, c) @ (n*p^2, m, c, topk*h_kv*w_kv) -> (n*p^2, m, w^2, topk*h_kv*w_kv)
        attn_weight = self.attn_act(attn_weight)
        out = attn_weight @ v_pix_sel  # (n*p^2, m, w^2, topk*h_kv*w_kv) @ (n*p^2, m, topk*h_kv*w_kv, c) -> (n*p^2, m, w^2, c)
        out = rearrange(out, '(n j i) m (h w) c -> n (j h) (i w) (m c)', j=self.n_win, i=self.n_win,
                        h=H // self.n_win, w=W // self.n_win)
        out = out + lepe
        out = self.wo(out)
        if self.auto_pad and (pad_r > 0 or pad_b > 0):
            out = out[:, :H_in, :W_in, :].contiguous()

        if ret_attn_mask:
            return out, r_weight, r_idx, attn_weight
        else:
            return rearrange(out, "n h w c -> n c h w")
```

> ä¹‹å‰æ²¡æœ‰å¯¼å…¥einopsåŒ…çš„çœ‹è¿™ç¯‡â†’[ã€ViTç³»åˆ—ï¼ˆ2ï¼‰ã€‘ViTï¼ˆVision Transformerï¼‰ä»£ç è¶…è¯¦ç»†è§£è¯»ï¼ˆPytorchï¼‰][ViT_2_ViT_Vision Transformer_Pytorch]

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](https://i-blog.csdnimg.cn/blog_migrate/c69803a6a6e53d203c7e3b0d555ccbe5.png)

#### ç¬¬â‘¡æ­¥ï¼šä¿®æ”¹yolo.pyæ–‡ä»¶ 

å†æ¥ä¿®æ”¹yolo.pyï¼Œåœ¨parse\_modelå‡½æ•°ä¸­æ‰¾åˆ° elif m is Concat: è¯­å¥ï¼Œåœ¨å…¶åé¢åŠ ä¸Šä¸‹é¢ä»£ç ï¼š

```java
elif m in [BiLevelRoutingAttention]:  
            c2 = ch[f]
            args = [c2, *args[0:]]
```

å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](https://i-blog.csdnimg.cn/blog_migrate/bfdb754eec6f906d561ebde888715b31.png)

#### ç¬¬â‘¢æ­¥ï¼šåˆ›å»ºè‡ªå®šä¹‰çš„yamlæ–‡ä»¶ 

yamlæ–‡ä»¶é…ç½®å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š

```java
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)
   [-1, 1, BiLevelRoutingAttention, []],

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 21, 24], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
```

#### ç¬¬â‘£æ­¥ï¼šéªŒè¯æ˜¯å¦åŠ å…¥æˆåŠŸ 

è¿è¡Œyolo.py

![](https://i-blog.csdnimg.cn/blog_migrate/d62848be276a6f1bf931d1767a6e283e.png)

è¿™æ ·å°±OKå•¦ï¼

> ä»£ç å‚è€ƒï¼š
> 
> [æ”¹è¿›YOLOç³»åˆ— | CVPR2023æœ€æ–°æ³¨æ„åŠ› | BiFormerï¼šè§†è§‰å˜æ¢å™¨ä¸åŒå±‚è·¯ç”±æ³¨æ„åŠ›\_è¿ªè²èµ«å°”æ›¼çš„åšå®¢-CSDNåšå®¢][YOLO_ _ CVPR2023_ _ BiFormer_-CSDN]

PSï¼š

ï¼ˆ1ï¼‰è¿™ä¸ªæ³¨æ„åŠ›æœºåˆ¶åœ¨æˆ‘åŒå­¦çš„æ•°æ®é›†ä¸Šé«˜æ•ˆæ¶¨ç‚¹ï¼Œæˆ‘åŠ å…¥åè¯•äº†ä¸åŒçš„ä½ç½®ï¼Œåœ¨å°ç›®æ ‡å±‚ç›¸æ¯”åŸå§‹yolov5sæ¶¨äº†0.2ï¼Œå…¶ä½™ä½ç½®éƒ½æ‰ç‚¹äº†ã€‚å¯ä»¥è¯æ˜çš„ç¡®æ˜¯å¯¹å°ç›®æ ‡æ£€æµ‹æ›´åŠ å‹å¥½ã€‚

> å¼•ç”¨åŸæ–‡ä¸€å¥è¯ï¼š
> 
> â€œç”±äº BiFormer ä»¥æŸ¥è¯¢è‡ªé€‚åº”çš„æ–¹å¼å…³æ³¨ä¸€å°éƒ¨åˆ†ç›¸å…³æ ‡è®°ï¼Œè€Œä¸ä¼šåˆ†æ•£å…¶ä»–ä¸ç›¸å…³æ ‡è®°çš„æ³¨æ„åŠ›ï¼Œå› æ­¤å®ƒå…·æœ‰è‰¯å¥½çš„æ€§èƒ½å’Œé«˜è®¡ç®—æ•ˆç‡ã€‚â€

ï¼ˆ2ï¼‰é€šè¿‡ä¸æ­¢ä¸€ä¸ªäººçš„å®éªŒå‘ç°ï¼ŒåŠ å…¥è¿™ä¸ªæ¨¡å—åæ²¡æœ‰å¢åŠ å¤ªå¤šå‚æ•°ï¼Œä½†ç”µè„‘å°±è«åå…¶å¦™è·‘ä¸åŠ¨äº†ã€‚åœ¨äº‘ç«¯è·‘è¿˜æ˜¯OKçš„ã€‚

## ğŸŒŸæœ¬äººYOLOv5ç³»åˆ—å¯¼èˆª 

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif) ğŸ€[YOLOv5æºç ][YOLOv5 1]è¯¦è§£ç³»åˆ—ï¼š

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ1ï¼‰â€”â€”é¡¹ç›®ç›®å½•ç»“æ„è§£æ][YOLOv5_1]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ2ï¼‰â€”â€”æ¨ç†éƒ¨åˆ†detect.py][YOLOv5_2_detect.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ3ï¼‰â€”â€”è®­ç»ƒéƒ¨åˆ†train.py][YOLOv5_3_train.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ4ï¼‰â€”â€”éªŒè¯éƒ¨åˆ†valï¼ˆtestï¼‰.py][YOLOv5_4_val_test_.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ5ï¼‰â€”â€”é…ç½®æ–‡ä»¶yolov5s.yaml][YOLOv5_5_yolov5s.yaml]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ6ï¼‰â€”â€”ç½‘ç»œç»“æ„ï¼ˆ1ï¼‰yolo.py][YOLOv5_6_1_yolo.py]

[YOLOv5æºç é€è¡Œè¶…è¯¦ç»†æ³¨é‡Šä¸è§£è¯»ï¼ˆ7ï¼‰â€”â€”ç½‘ç»œç»“æ„ï¼ˆ2ï¼‰common.py][YOLOv5_7_2_common.py]

![962f7cb1b48f44e29d9beb1d499d0530.gif](https://i-blog.csdnimg.cn/blog_migrate/ac3c5d6bfbcbf982e8e9e3632d7f20d1.gif) ğŸ€[YOLOv5å…¥é—¨å®è·µ][YOLOv5 1]ç³»åˆ—ï¼š

[YOLOv5å…¥é—¨å®è·µï¼ˆ1ï¼‰â€”â€”æ‰‹æŠŠæ‰‹å¸¦ä½ ç¯å¢ƒé…ç½®æ­å»º][YOLOv5_1 1]

[YOLOv5å…¥é—¨å®è·µï¼ˆ2ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ åˆ©ç”¨labelimgæ ‡æ³¨æ•°æ®é›†][YOLOv5_2_labelimg]

[YOLOv5å…¥é—¨å®è·µï¼ˆ3ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ åˆ’åˆ†è‡ªå·±çš„æ•°æ®é›†][YOLOv5_3]

[YOLOv5å…¥é—¨å®è·µï¼ˆ4ï¼‰â€”â€”æ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒè‡ªå·±çš„æ•°æ®é›†][YOLOv5_4]

[YOLOv5å…¥é—¨å®è·µï¼ˆ5ï¼‰â€”â€”ä»é›¶å¼€å§‹ï¼Œæ‰‹æŠŠæ‰‹æ•™ä½ è®­ç»ƒè‡ªå·±çš„ç›®æ ‡æ£€æµ‹æ¨¡å‹ï¼ˆåŒ…å«pyqt5ç•Œé¢ï¼‰][YOLOv5_5_pyqt5]

![](https://i-blog.csdnimg.cn/blog_migrate/6bbe1359529aa85d32810d4c62b41197.gif)


[YOLOv5_0]: https://blog.csdn.net/weixin_43334693/article/details/130564848?spm=1001.2014.3001.5501
[YOLOv5_1_SE]: https://blog.csdn.net/weixin_43334693/article/details/130551913?spm=1001.2014.3001.5501
[YOLOv5_2_CBAM]: https://blog.csdn.net/weixin_43334693/article/details/130587102?spm=1001.2014.3001.5501
[YOLOv5_3_CA]: https://blog.csdn.net/weixin_43334693/article/details/130619604?spm=1001.2014.3001.5501
[YOLOv5_4_ECA]: https://blog.csdn.net/weixin_43334693/article/details/130641318?spm=1001.2014.3001.5501
[YOLOv5_5_ MobileNetV3]: https://blog.csdn.net/weixin_43334693/article/details/130832933?spm=1001.2014.3001.5501
[YOLOv5_6_ ShuffleNetV2]: https://blog.csdn.net/weixin_43334693/article/details/131008642?spm=1001.2014.3001.5501
[YOLOv5_7_SimAM]: https://blog.csdn.net/weixin_43334693/article/details/131031541?spm=1001.2014.3001.5501
[YOLOv5_8_SOCA]: https://blog.csdn.net/weixin_43334693/article/details/131053284?spm=1001.2014.3001.5501
[YOLOv5_9_EfficientNetv2]: https://blog.csdn.net/weixin_43334693/article/details/131207097?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22131207097%22%2C%22source%22%3A%22weixin_43334693%22%7D
[YOLOv5_10_GhostNet]: https://blog.csdn.net/weixin_43334693/article/details/131235113?spm=1001.2014.3001.5501
[YOLOv5_11_EIoU_AlphaIoU_SIoU_WIoU]: https://blog.csdn.net/weixin_43334693/article/details/131350224?spm=1001.2014.3001.5501
[YOLOv5_12_Neck_BiFPN]: https://blog.csdn.net/weixin_43334693/article/details/131461294?spm=1001.2014.3001.5501
[YOLOv5_13_SiLU_ReLU_ELU_Hardswish_Mish_Softplus_AconC]: https://blog.csdn.net/weixin_43334693/article/details/131513850?spm=1001.2014.3001.5502
[YOLOv5_14_NMS_ DIoU-NMS_CIoU-NMS_EIoU-NMS_GIoU-NMS _SIoU-NMS_Soft-NMS]: https://blog.csdn.net/weixin_43334693/article/details/131552028?spm=1001.2014.3001.5501
[YOLOv5_15]: https://blog.csdn.net/weixin_43334693/article/details/131613721?spm=1001.2014.3001.5502
[YOLOv5_16_EMA_ICASSP2023]: https://blog.csdn.net/weixin_43334693/article/details/131973273?spm=1001.2014.3001.5501
[YOLOv5_17_IoU_MPDIoU_ELSEVIER 2023_WIoU_EIoU]: https://blog.csdn.net/weixin_43334693/article/details/131999141?spm=1001.2014.3001.5501
[YOLOv5_18_Neck_AFPN_PAFPN]: https://blog.csdn.net/weixin_43334693/article/details/132070079?spm=1001.2014.3001.5501
[YOLOv5_19_Swin TransformerV1_ViT]: https://blog.csdn.net/weixin_43334693/article/details/132161488?spm=1001.2014.3001.5501
[BiFormer_]: #%F0%9F%9A%80%E4%B8%80%E3%80%81BiFormer%E4%BB%8B%E7%BB%8D%C2%A0%C2%A0%C2%A0%C2%A0
[1.1]: #%C2%A01.1%20%E7%AE%80%E4%BB%8B
[1.2]: #1.2%20%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84
[Link 1]: #%F0%9F%9A%80%E4%BA%8C%E3%80%81%E5%85%B7%E4%BD%93%E6%B7%BB%E5%8A%A0%E6%96%B9%E6%B3%95
[common.py_BiFormer]: #%E7%AC%AC%E2%91%A0%E6%AD%A5%EF%BC%9A%E5%9C%A8common.py%E4%B8%AD%E6%B7%BB%E5%8A%A0SE%E6%A8%A1%E5%9D%97
[yolo.py]: #%C2%A0%E7%AC%AC%E2%91%A1%E6%AD%A5%EF%BC%9A%E5%9C%A8yolo.py%E6%96%87%E4%BB%B6%E9%87%8C%E7%9A%84parse_model%E5%87%BD%E6%95%B0%E5%8A%A0%E5%85%A5%E7%B1%BB%E5%90%8D
[yaml_]: #%C2%A0%E7%AC%AC%E2%91%A2%E6%AD%A5%EF%BC%9A%E5%88%9B%E5%BB%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84yaml%E6%96%87%E4%BB%B6%C2%A0%C2%A0
[Link 2]: #%C2%A0%E7%AC%AC%E2%91%A3%E6%AD%A5%EF%BC%9A%E9%AA%8C%E8%AF%81%E6%98%AF%E5%90%A6%E5%8A%A0%E5%85%A5%E6%88%90%E5%8A%9F
[YOLOv5]: #%F0%9F%8C%9F%E6%9C%AC%E4%BA%BAYOLOv5%E7%B3%BB%E5%88%97%E5%AF%BC%E8%88%AA
[https_arxiv.org_pdf_2303.08810.pdf]: https://arxiv.org/pdf/2303.08810.pdf
[https_github.com_rayleizhu_BiFormer]: https://github.com/rayleizhu/BiFormer
[ViT_2_ViT_Vision Transformer_Pytorch]: https://blog.csdn.net/weixin_43334693/article/details/131836233?spm=1001.2014.3001.5501
[YOLO_ _ CVPR2023_ _ BiFormer_-CSDN]: https://blog.csdn.net/weixin_43694096/article/details/130352480?spm=1001.2014.3001.5501
[YOLOv5 1]: https://so.csdn.net/so/search?q=YOLOv5%E6%BA%90%E7%A0%81&spm=1001.2101.3001.7020
[YOLOv5_1]: https://blog.csdn.net/weixin_43334693/article/details/129356033?spm=1001.2014.3001.5501
[YOLOv5_2_detect.py]: https://blog.csdn.net/weixin_43334693/article/details/129349094?spm=1001.2014.3001.5501
[YOLOv5_3_train.py]: https://blog.csdn.net/weixin_43334693/article/details/129460666?spm=1001.2014.3001.5501
[YOLOv5_4_val_test_.py]: https://blog.csdn.net/weixin_43334693/article/details/129649553?spm=1001.2014.3001.5501
[YOLOv5_5_yolov5s.yaml]: https://blog.csdn.net/weixin_43334693/article/details/129697521?spm=1001.2014.3001.5501
[YOLOv5_6_1_yolo.py]: https://blog.csdn.net/weixin_43334693/article/details/129803802?spm=1001.2014.3001.5501
[YOLOv5_7_2_common.py]: https://blog.csdn.net/weixin_43334693/article/details/129854764?spm=1001.2014.3001.5501
[YOLOv5_1 1]: https://blog.csdn.net/weixin_43334693/article/details/129981848?spm=1001.2014.3001.5501
[YOLOv5_2_labelimg]: https://blog.csdn.net/weixin_43334693/article/details/129995604?spm=1001.2014.3001.5501
[YOLOv5_3]: https://blog.csdn.net/weixin_43334693/article/details/130025866?spm=1001.2014.3001.5501
[YOLOv5_4]: https://blog.csdn.net/weixin_43334693/article/details/130043351?spm=1001.2014.3001.5501
[YOLOv5_5_pyqt5]: https://blog.csdn.net/weixin_43334693/article/details/130044342?spm=1001.2014.3001.5501